{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c29a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b28dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import easydict\n",
    "\n",
    "from meta_neural_network_architectures import VGGReLUNormNetwork, ResNet12, extract_top_level_dict, MetaBatchNormLayer, MetaLinearLayer\n",
    "from inner_loop_optimizers import LSLRGradientDescentLearningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79927d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "{\n",
    "  \"batch_size\":2,\n",
    "  \"image_height\":84,\n",
    "  \"image_width\":84,\n",
    "  \"image_channels\":3,\n",
    "  \"gpu_to_use\":0,\n",
    "  \"num_dataprovider_workers\":4,\n",
    "  \"max_models_to_save\":5,\n",
    "  \"dataset_name\":\"mini_imagenet_full_size\",\n",
    "  \"dataset_path\":\"mini_imagenet_full_size\",\n",
    "  \"reset_stored_paths\":False,\n",
    "  \"experiment_name\":\"alfa+maml\",\n",
    "  \"train_seed\": 0, \"val_seed\": 0,\n",
    "  \"indexes_of_folders_indicating_class\": [-3, -2],\n",
    "  \"sets_are_pre_split\": True,\n",
    "  \"train_val_test_split\": [0.64, 0.16, 0.20],\n",
    "  \"evaluate_on_test_set_only\": False,\n",
    "\n",
    "  \"total_epochs\": 100,\n",
    "  \"total_iter_per_epoch\":500, \"continue_from_epoch\": -2,\n",
    "  \"num_evaluation_tasks\":600,\n",
    "  \"multi_step_loss_num_epochs\": 15,\n",
    "  \"minimum_per_task_contribution\": 0.01,\n",
    "  \"learnable_per_layer_per_step_inner_loop_learning_rate\": False,\n",
    "  \"enable_inner_loop_optimizable_bn_params\": False,\n",
    "  \"evalute_on_test_set_only\": False,\n",
    "\n",
    "  \"max_pooling\": True,\n",
    "  \"per_step_bn_statistics\": False,\n",
    "  \"learnable_batch_norm_momentum\": False,\n",
    "  \"load_into_memory\": False,\n",
    "  \"init_inner_loop_learning_rate\": 0.01,\n",
    "  \"init_inner_loop_weight_decay\": 0.0005,\n",
    "  \"learnable_bn_gamma\": True,\n",
    "  \"learnable_bn_beta\": True,\n",
    "\n",
    "  \"dropout_rate_value\":0.0,\n",
    "  \"min_learning_rate\":0.001,\n",
    "  \"meta_learning_rate\":0.001,   \"total_epochs_before_pause\": 100,\n",
    "  \"first_order_to_second_order_epoch\":-1,\n",
    "  \"weight_decay\": 0.0,\n",
    "\n",
    "  \"norm_layer\":\"batch_norm\",\n",
    "  \"cnn_num_filters\":48,\n",
    "  \"num_stages\":4,\n",
    "  \"conv_padding\": True,\n",
    "  \"number_of_training_steps_per_iter\":5,\n",
    "  \"number_of_evaluation_steps_per_iter\":5,\n",
    "  \"cnn_blocks_per_stage\":1,\n",
    "  \"num_classes_per_set\":5,\n",
    "  \"num_samples_per_class\":5,\n",
    "  \"num_target_samples\": 15,\n",
    "\n",
    "  \"second_order\": True,\n",
    "  \"use_multi_step_loss_optimization\":False,\n",
    "  \"attenuate\": False,\n",
    "  \"alfa\": True,\n",
    "  \"random_init\": False,\n",
    "  \"backbone\": \"4-CONV\"\n",
    "}\n",
    ")\n",
    "\n",
    "device = torch.cuda.current_device()\n",
    "im_shape = (2, 3, args.image_height, args.image_width)\n",
    "\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "args.seed = 104\n",
    "args.reverse_channels=False\n",
    "args.labels_as_int=False\n",
    "args.reset_stored_filepaths=False\n",
    "args.num_of_gpus=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5efae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max pooling\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 84, 84])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 42, 42])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 21, 21])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 10, 10])\n",
      "No inner loop params\n",
      "VGGNetwork self.layer_dict ===  ModuleDict(\n",
      "  (conv0): MetaConvNormLayerReLU(\n",
      "    (layer_dict): ModuleDict()\n",
      "    (conv): MetaConv2dLayer()\n",
      "    (norm_layer): MetaBatchNormLayer(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1): MetaConvNormLayerReLU(\n",
      "    (layer_dict): ModuleDict()\n",
      "    (conv): MetaConv2dLayer()\n",
      "    (norm_layer): MetaBatchNormLayer(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2): MetaConvNormLayerReLU(\n",
      "    (layer_dict): ModuleDict()\n",
      "    (conv): MetaConv2dLayer()\n",
      "    (norm_layer): MetaBatchNormLayer(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): MetaConvNormLayerReLU(\n",
      "    (layer_dict): ModuleDict()\n",
      "    (conv): MetaConv2dLayer()\n",
      "    (norm_layer): MetaBatchNormLayer(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear): MetaLinearLayer()\n",
      ")\n",
      "VGGNetwork build out.shape ===  torch.Size([2, 5])\n",
      "VGGNetwork build out ===  tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], grad_fn=<AddmmBackward0>)\n",
      "(VGGReLUNormNetwork) meta network params\n",
      "layer_dict.conv0.conv.weight torch.Size([48, 3, 3, 3])\n",
      "layer_dict.conv0.conv.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv1.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv1.conv.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv2.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv2.conv.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv3.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv3.conv.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.weight torch.Size([48])\n",
      "layer_dict.linear.weights torch.Size([5, 1200])\n",
      "layer_dict.linear.bias torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.current_device()\n",
    "im_shape=(2, 3, 84, 84)\n",
    "\n",
    "classifier = VGGReLUNormNetwork(im_shape=im_shape, \n",
    "                      num_output_classes=args.\n",
    "                      num_classes_per_set,\n",
    "                      args=args, \n",
    "                      device=device, \n",
    "                      meta_classifier=True).to(device=device)\n",
    "\n",
    "# (layer_dict): ModuleDict()\n",
    "# 코드가 동작하는데 전혀 필요없는 부분으로 보여짐. 이것 때문에 헷갈려하지말자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04c4062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연산 전 torch.Size([10, 1, 20, 20])\n",
      "conv1 연산 후 torch.Size([10, 3, 16, 16])\n",
      "conv2 연산 후 torch.Size([10, 10, 12, 12])\n",
      "차원 감소 후 torch.Size([10, 1440])\n",
      "fc1 연산 후 torch.Size([10, 50])\n",
      "fc2 연산 후 torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5, stride=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5, stride=1)\n",
    "    self.fc1 = nn.Linear(10 * 12 * 12, 50)\n",
    "    self.fc2 = nn.Linear(50, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    print(\"연산 전\", x.size())\n",
    "    x = F.relu(self.conv1(x))\n",
    "    print(\"conv1 연산 후\", x.size())\n",
    "    x = F.relu(self.conv2(x))\n",
    "    print(\"conv2 연산 후\",x.size())\n",
    "    x = x.view(-1, 10 * 12 * 12)\n",
    "    print(\"차원 감소 후\", x.size())\n",
    "    x = F.relu(self.fc1(x))\n",
    "    print(\"fc1 연산 후\", x.size())\n",
    "    x = self.fc2(x)\n",
    "    print(\"fc2 연산 후\", x.size())\n",
    "    return x\n",
    "\n",
    "cnn = CNN()\n",
    "output = cnn(torch.randn(10, 1, 20, 20))  # Input Size: (10, 1, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c017bc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
