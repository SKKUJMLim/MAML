{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c29a4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b28dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from meta_neural_network_architectures_selfDistill import VGGReLUNormNetwork, ResNet12\n",
    "from utils.parser_utils import get_args\n",
    "from data import MetaLearningSystemDataLoader\n",
    "from experiment_builder import ExperimentBuilder\n",
    "\n",
    "from few_shot_learning_system import MAMLFewShotClassifier\n",
    "from utils import loss_landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79927d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.environ['DATASET_DIR'] ===  C:/Users/JM/PycharmProjects/MAML/datasets\n"
     ]
    }
   ],
   "source": [
    "os.environ['DATASET_DIR'] = 'C:/Users/JM/PycharmProjects/MAML/datasets'\n",
    "print(\"os.environ['DATASET_DIR'] === \", os.environ['DATASET_DIR'])\n",
    "\n",
    "args = easydict.EasyDict(\n",
    "{\n",
    "  \"batch_size\":2,\n",
    "  \"image_height\":84,\n",
    "  \"image_width\":84,\n",
    "  \"image_channels\":3,\n",
    "  \"gpu_to_use\":0,\n",
    "  \"num_dataprovider_workers\":4,\n",
    "  \"max_models_to_save\":5,\n",
    "  \"dataset_name\":\"mini_imagenet_full_size\",\n",
    "  \"dataset_path\":\"mini_imagenet_full_size\",\n",
    "  \"reset_stored_paths\":False,\n",
    "  \"experiment_name\":\"../MAML_JM\",\n",
    "  \"train_seed\": 0, \"val_seed\": 0,\n",
    "  \"indexes_of_folders_indicating_class\": [-3, -2],\n",
    "  \"sets_are_pre_split\": True,\n",
    "  \"train_val_test_split\": [0.64, 0.16, 0.20],\n",
    "  \"evaluate_on_test_set_only\": False,\n",
    "\n",
    "  \"total_epochs\": 100,\n",
    "  \"total_iter_per_epoch\":500, \"continue_from_epoch\": -2,\n",
    "  \"num_evaluation_tasks\":600,\n",
    "  \"multi_step_loss_num_epochs\": 15,\n",
    "  \"minimum_per_task_contribution\": 0.01,\n",
    "  \"learnable_per_layer_per_step_inner_loop_learning_rate\": False,\n",
    "  \"enable_inner_loop_optimizable_bn_params\": False,\n",
    "  \"evalute_on_test_set_only\": False,\n",
    "\n",
    "  \"max_pooling\": True,\n",
    "  \"per_step_bn_statistics\": False,\n",
    "  \"learnable_batch_norm_momentum\": False,\n",
    "  \"load_into_memory\": False,\n",
    "  \"init_inner_loop_learning_rate\": 0.01,\n",
    "  \"init_inner_loop_weight_decay\": 0.0005,\n",
    "  \"learnable_bn_gamma\": True,\n",
    "  \"learnable_bn_beta\": True,\n",
    "\n",
    "  \"dropout_rate_value\":0.0,\n",
    "  \"min_learning_rate\":0.001,\n",
    "  \"meta_learning_rate\":0.001,   \"total_epochs_before_pause\": 100,\n",
    "  \"first_order_to_second_order_epoch\":-1,\n",
    "  \"weight_decay\": 0.0,\n",
    "\n",
    "  \"norm_layer\":\"batch_norm\",\n",
    "  \"cnn_num_filters\":48,\n",
    "  \"num_stages\":4,\n",
    "  \"conv_padding\": True,\n",
    "  \"number_of_training_steps_per_iter\":5,\n",
    "  \"number_of_evaluation_steps_per_iter\":5,\n",
    "  \"cnn_blocks_per_stage\":1,\n",
    "  \"num_classes_per_set\":5,\n",
    "  \"num_samples_per_class\":5,\n",
    "  \"num_target_samples\": 15,\n",
    "  \"samples_per_iter\" : 1,\n",
    "\n",
    "  \"second_order\": True,\n",
    "  \"use_multi_step_loss_optimization\":False,\n",
    "  \"backbone\": \"4-CONV\",\n",
    "  \"arbiter\": True,\n",
    "  \"use_bias\": True,\n",
    "  \"smoothing\": False,\n",
    "  \"knowledge_distillation\": False\n",
    "}\n",
    ")\n",
    "\n",
    "device = torch.cuda.current_device()\n",
    "args.im_shape = (2, 3, args.image_height, args.image_width)\n",
    "\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "args.seed = 104\n",
    "args.reverse_channels=False\n",
    "args.labels_as_int=False\n",
    "args.reset_stored_filepaths=False\n",
    "args.num_of_gpus=1\n",
    "\n",
    "# args.continue_from_epoch='latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5efae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max pooling\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 84, 84])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 42, 42])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 21, 21])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 10, 10])\n",
      "No inner loop params\n",
      "(VGGReLUNormNetwork) meta network params\n",
      "layer_dict.conv0.conv.weight torch.Size([48, 3, 3, 3])\n",
      "layer_dict.conv0.conv.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv1.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv1.conv.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv2.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv2.conv.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv3.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv3.conv.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.weight torch.Size([48])\n",
      "layer_dict.linear.weights torch.Size([5, 1200])\n",
      "layer_dict.linear.bias torch.Size([5])\n",
      "Inner Loop parameters\n",
      "Outer Loop parameters\n",
      "classifier.layer_dict.conv0.conv.weight torch.Size([48, 3, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv0.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv0.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv0.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv1.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv2.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv3.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.linear.weights torch.Size([5, 1200]) cuda:0 True\n",
      "classifier.layer_dict.linear.bias torch.Size([5]) cuda:0 True\n",
      "arbiter.0.weight torch.Size([20, 20]) cuda:0 True\n",
      "arbiter.0.bias torch.Size([20]) cuda:0 True\n",
      "arbiter.2.weight torch.Size([10, 20]) cuda:0 True\n",
      "arbiter.2.bias torch.Size([10]) cuda:0 True\n",
      "log_dir ===  C:\\Users\\JM\\PycharmProjects\\MAML\\MAML_JM\n",
      "dataset_splits ==  dict_keys(['test', 'train', 'val'])\n",
      "data {'test': 12000, 'train': 38400, 'val': 9600}\n",
      "train_seed 985773, val_seed: 985773, at start time\n",
      "0 50000\n"
     ]
    }
   ],
   "source": [
    "# 모델을 구성한다\n",
    "model = MAMLFewShotClassifier(args=args, device=device,\n",
    "                              im_shape=(2, 3,\n",
    "                                        args.image_height, args.image_width))\n",
    "\n",
    "data = MetaLearningSystemDataLoader\n",
    "\n",
    "maml_system = ExperimentBuilder(model=model, data=data, args=args, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c017bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5, stride=1)\n",
    "    \n",
    "    self.dropout1 = nn.Dropout(0.5)\n",
    "    \n",
    "    self.conv2 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5, stride=1)\n",
    "    \n",
    "    self.dropout2 = nn.Dropout(0.5)\n",
    "    \n",
    "    self.fc1 = nn.Linear(10 * 12 * 12, 50)\n",
    "    self.fc2 = nn.Linear(50, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    print(\"연산 전\", x.size())\n",
    "    \n",
    "    x = self.conv1(x)    \n",
    "    print(\"conv1 연산 후\", x.size())\n",
    "    \n",
    "    x = self.dropout1(x)\n",
    "    \n",
    "    x = self.conv2(x)\n",
    "    print(\"conv2 연산 후\",x.size())\n",
    "    x = self.dropout2(x)\n",
    "    \n",
    "    x = x.view(-1, 10 * 12 * 12)\n",
    "    print(\"차원 감소 후\", x.size())\n",
    "    x = F.relu(self.fc1(x))\n",
    "    print(\"fc1 연산 후\", x.size())\n",
    "    x = self.fc2(x)\n",
    "    print(\"fc2 연산 후\", x.size())\n",
    "    return x\n",
    "\n",
    "cnn = CNN()\n",
    "output = cnn(torch.randn(10, 1, 20, 20))  # Input Size: (10, 1, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25341c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
