{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda16bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from meta_neural_network_architectures import VGGReLUNormNetwork, ResNet12\n",
    "from prompters import padding\n",
    "from utils.parser_utils import get_args\n",
    "\n",
    "import easydict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869f1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DATASET_DIR'] = os.path.join(os.getcwd(), \"datasets\")\n",
    "\n",
    "args = easydict.EasyDict(\n",
    "{\n",
    "  \"batch_size\":2,\n",
    "  \"image_height\":84,\n",
    "  \"image_width\":84,\n",
    "  \"image_channels\":3,\n",
    "  \"gpu_to_use\":0,\n",
    "  \"num_dataprovider_workers\":4,\n",
    "  \"max_models_to_save\":5,\n",
    "  \"dataset_name\":\"mini_imagenet_full_size\",\n",
    "  \"dataset_path\":\"mini_imagenet_full_size\",\n",
    "  \"reset_stored_paths\":False,\n",
    "  \"experiment_name\":\"alfa+maml\",\n",
    "  \"train_seed\": 0, \"val_seed\": 0,\n",
    "  \"indexes_of_folders_indicating_class\": [-3, -2],\n",
    "  \"sets_are_pre_split\": True,\n",
    "  \"train_val_test_split\": [0.64, 0.16, 0.20],\n",
    "  \"evaluate_on_test_set_only\": False,\n",
    "\n",
    "  \"total_epochs\": 100,\n",
    "  \"total_iter_per_epoch\":500, \"continue_from_epoch\": -2,\n",
    "  \"num_evaluation_tasks\":600,\n",
    "  \"multi_step_loss_num_epochs\": 15,\n",
    "  \"minimum_per_task_contribution\": 0.01,\n",
    "  \"learnable_per_layer_per_step_inner_loop_learning_rate\": False,\n",
    "  \"enable_inner_loop_optimizable_bn_params\": False,\n",
    "  \"evalute_on_test_set_only\": False,\n",
    "\n",
    "  \"max_pooling\": True,\n",
    "  \"per_step_bn_statistics\": False,\n",
    "  \"learnable_batch_norm_momentum\": False,\n",
    "  \"load_into_memory\": False,\n",
    "  \"init_inner_loop_learning_rate\": 0.01,\n",
    "  \"init_inner_loop_weight_decay\": 0.0005,\n",
    "  \"learnable_bn_gamma\": True,\n",
    "  \"learnable_bn_beta\": True,\n",
    "\n",
    "  \"dropout_rate_value\":0.0,\n",
    "  \"min_learning_rate\":0.001,\n",
    "  \"meta_learning_rate\":0.001,   \"total_epochs_before_pause\": 100,\n",
    "  \"first_order_to_second_order_epoch\":-1,\n",
    "  \"weight_decay\": 0.0,\n",
    "\n",
    "  \"norm_layer\":\"batch_norm\",\n",
    "  \"cnn_num_filters\":48,\n",
    "  \"num_stages\":4,\n",
    "  \"conv_padding\": True,\n",
    "  \"number_of_training_steps_per_iter\":5,\n",
    "  \"number_of_evaluation_steps_per_iter\":5,\n",
    "  \"cnn_blocks_per_stage\":1,\n",
    "  \"num_classes_per_set\":5,\n",
    "  \"num_samples_per_class\":5,\n",
    "  \"num_target_samples\": 15,\n",
    "    \"samples_per_iter\" : 1,\n",
    "\n",
    "  \"second_order\": True,\n",
    "  \"use_multi_step_loss_optimization\":False,\n",
    "  \"attenuate\": False,\n",
    "  \"alfa\": True,\n",
    "  \"random_init\": False,\n",
    "  \"backbone\": \"4-CONV\",\n",
    "   \"loss_function\": \"Softmax\",\n",
    "  \"ole\": True,\n",
    "  \"arbiter\": False\n",
    "}\n",
    ")\n",
    "\n",
    "device = torch.cuda.current_device()\n",
    "args.im_shape = (2, 3, args.image_height, args.image_width)\n",
    "\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "args.seed = 104\n",
    "args.reverse_channels=False\n",
    "args.labels_as_int=False\n",
    "args.reset_stored_filepaths=False\n",
    "args.num_of_gpus=1\n",
    "\n",
    "def get_inner_loop_parameter_dict(params):\n",
    "\n",
    "    param_dict = dict()\n",
    "    for name, param in params:\n",
    "        if param.requires_grad:\n",
    "            param_dict[name] = param.to(device=device)\n",
    "\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbba0c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a795ab431bf4120ba8e161dff45e9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169001437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "torch.Size([25, 3, 84, 84])\n",
      "tensor([92, 69, 75, 36, 32, 44, 48, 38, 45, 13, 74, 53, 60, 21, 69,  1, 93, 92,\n",
      "        95, 99,  0, 82, 19, 59, 94])\n"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(84),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100(\"./data\", transform=preprocess,\n",
    "                          download=True, train=True)\n",
    "\n",
    "val_dataset = CIFAR100(\"./data\", transform=preprocess,\n",
    "                        download=True, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=25, pin_memory=True,\n",
    "                          num_workers=16, shuffle=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "images, targets = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "print(images.shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be2fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 무작위 이미지 데이터 생성 (배치 크기, 채널, 높이, 너비)\n",
    "# batch_size = 25\n",
    "# channels = 3  # RGB 이미지이므로 3개의 채널\n",
    "# height, width = 84, 84  # 높이와 너비\n",
    "\n",
    "# # 무작위 이미지 데이터 생성 (0과 1 사이의 무작위 값)\n",
    "# images = torch.rand(batch_size, channels, height, width)\n",
    "\n",
    "# # 무작위 레이블 데이터 생성 (예시를 위해 10개의 클래스)\n",
    "# num_classes = 25\n",
    "# targets = torch.randint(0, num_classes, (batch_size,))\n",
    "\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60b8e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 84, 84])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "targets = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4])\n",
    "targets = torch.Tensor(targets)\n",
    "targets = targets.type(torch.LongTensor)\n",
    "targets = targets.to(device)\n",
    "\n",
    "print(images.shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0123c723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max pooling\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 84, 84])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 42, 42])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 21, 21])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 10, 10])\n",
      "No inner loop params\n",
      "(VGGReLUNormNetwork) meta network params\n",
      "layer_dict.conv0.conv.weight torch.Size([48, 3, 3, 3])\n",
      "layer_dict.conv0.conv.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv1.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv1.conv.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv2.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv2.conv.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv3.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv3.conv.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.weight torch.Size([48])\n",
      "layer_dict.linear.weights torch.Size([5, 1200])\n",
      "layer_dict.linear.bias torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "class MAMLFewShotClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, im_shape, device, args):\n",
    "        \n",
    "        super(MAMLFewShotClassifier, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.batch_size = args.batch_size\n",
    "        self.use_cuda = args.use_cuda\n",
    "        self.im_shape = im_shape\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "        self.classifier = VGGReLUNormNetwork(im_shape=self.im_shape, num_output_classes=self.args.\n",
    "                                                 num_classes_per_set,\n",
    "                                                 args=args, device=device, meta_classifier=True).to(device=self.device)        \n",
    "        \n",
    "        self.optimizer = optim.Adam(self.trainable_parameters(), lr=args.meta_learning_rate, amsgrad=False)\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=self.optimizer, T_max=self.args.total_epochs,\n",
    "                                                              eta_min=self.args.min_learning_rate)\n",
    "        \n",
    "    def trainable_parameters(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad:\n",
    "                yield param\n",
    "                \n",
    "    def get_inner_loop_parameter_dict(self, params):\n",
    "        \n",
    "        param_dict = dict()\n",
    "        for name, param in params:\n",
    "            if param.requires_grad:\n",
    "                param_dict[name] = param.to(device=device)\n",
    "\n",
    "        return param_dict\n",
    "                \n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        names_weights_copy = self.get_inner_loop_parameter_dict(self.classifier.named_parameters())\n",
    "        \n",
    "        names_weights_copy = {\n",
    "                        name.replace('module.', ''): value.unsqueeze(0).repeat(\n",
    "                            [1] + [1 for i in range(len(value.shape))]) for\n",
    "                        name, value in names_weights_copy.items()}\n",
    "        \n",
    "        loss, preds = self.net_forward(x, y, names_weights_copy)\n",
    "        \n",
    "        return loss, preds\n",
    "    \n",
    "    \n",
    "    def net_forward(self, x, y, names_weights_copy):\n",
    "        \n",
    "    \n",
    "        preds = self.classifier.forward(x, params=names_weights_copy,num_step=4)\n",
    "        \n",
    "        loss = F.cross_entropy(input=preds, target=y)        \n",
    "        \n",
    "        return loss, preds\n",
    "    \n",
    "    \n",
    "\n",
    "model = MAMLFewShotClassifier(args=args, device=device, im_shape=(2, 3, args.image_height, args.image_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26061063",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, preds = model.forward(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dec087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: classifier.layer_dict.conv0.conv.weight\n",
      "original shape: torch.Size([48, 3, 3, 3])\n",
      "U matrix shape: torch.Size([48, 3, 3, 3])\n",
      "Singular values shape: torch.Size([48, 3, 3])\n",
      "V transpose matrix shape: torch.Size([48, 3, 3, 3])\n",
      "restored matrix shape: torch.Size([48, 3, 3, 3])\n",
      "원본 텐서와 복원된 텐서 간의 차이:\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "------------------------------------\n",
      "Layer: classifier.layer_dict.conv1.conv.weight\n",
      "original shape: torch.Size([48, 48, 3, 3])\n",
      "U matrix shape: torch.Size([48, 48, 3, 3])\n",
      "Singular values shape: torch.Size([48, 48, 3])\n",
      "V transpose matrix shape: torch.Size([48, 48, 3, 3])\n",
      "restored matrix shape: torch.Size([48, 48, 3, 3])\n",
      "원본 텐서와 복원된 텐서 간의 차이:\n",
      "tensor(0.2088, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "------------------------------------\n",
      "Layer: classifier.layer_dict.conv2.conv.weight\n",
      "original shape: torch.Size([48, 48, 3, 3])\n",
      "U matrix shape: torch.Size([48, 48, 3, 3])\n",
      "Singular values shape: torch.Size([48, 48, 3])\n",
      "V transpose matrix shape: torch.Size([48, 48, 3, 3])\n",
      "restored matrix shape: torch.Size([48, 48, 3, 3])\n",
      "원본 텐서와 복원된 텐서 간의 차이:\n",
      "tensor(0.1990, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "------------------------------------\n",
      "Layer: classifier.layer_dict.conv3.conv.weight\n",
      "original shape: torch.Size([48, 48, 3, 3])\n",
      "U matrix shape: torch.Size([48, 48, 3, 3])\n",
      "Singular values shape: torch.Size([48, 48, 3])\n",
      "V transpose matrix shape: torch.Size([48, 48, 3, 3])\n",
      "restored matrix shape: torch.Size([48, 48, 3, 3])\n",
      "원본 텐서와 복원된 텐서 간의 차이:\n",
      "tensor(0.2045, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "svd = 0\n",
    "\n",
    "# 각 레이어의 가중치에 대한 SVD를 수행합니다\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:  # weight에 대해서만 SVD를 수행합니다\n",
    "        if \"norm_layer\" not in name:\n",
    "            if \"linear\" not in name:\n",
    "                print(f'Layer: {name}')\n",
    "                original_shape = param.shape\n",
    "                u, s, v = torch.svd(param, some=False)  # SVD 수행\n",
    "                svd = s\n",
    "                print(f'original shape: {original_shape}')\n",
    "                print(f'U matrix shape: {u.shape}')\n",
    "                print(f'Singular values shape: {s.shape}')\n",
    "                print(f'V transpose matrix shape: {v.shape}')\n",
    "\n",
    "                # 복원된 가중치 계산\n",
    "                restored_weight = torch.matmul(torch.matmul(u, torch.diag_embed(s)), v)\n",
    "                print(f'restored matrix shape: {restored_weight.shape}')\n",
    "                \n",
    "                # 복원된 텐서와 원본 텐서 간의 차이 계산\n",
    "                difference = torch.abs(param - restored_weight)\n",
    "                print(\"원본 텐서와 복원된 텐서 간의 차이:\")\n",
    "                print(difference.max())  # 차이의 최댓값 출력\n",
    "\n",
    "                print('------------------------------------')\n",
    "                \n",
    "#print(svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2263e5e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: classifier.layer_dict.conv0.conv.weight\n",
      "특이값 : \n",
      "tensor([[[1.8645e-01, 1.1424e-01, 4.5836e-02],\n",
      "         [1.6148e-01, 1.0831e-01, 5.5056e-02],\n",
      "         [1.5197e-01, 1.1769e-01, 2.8346e-04]],\n",
      "\n",
      "        [[1.4095e-01, 8.9464e-02, 3.0050e-02],\n",
      "         [1.6758e-01, 4.5281e-02, 4.8122e-03],\n",
      "         [1.2398e-01, 4.6948e-02, 8.1954e-03]],\n",
      "\n",
      "        [[1.7795e-01, 1.1046e-01, 9.6690e-04],\n",
      "         [1.8365e-01, 1.6181e-01, 2.5865e-02],\n",
      "         [1.3515e-01, 8.3414e-02, 1.3090e-02]],\n",
      "\n",
      "        [[2.1720e-01, 1.7138e-01, 1.9442e-02],\n",
      "         [1.6984e-01, 8.6493e-02, 4.8346e-02],\n",
      "         [1.7417e-01, 7.5125e-02, 6.4866e-03]],\n",
      "\n",
      "        [[1.8409e-01, 1.0885e-01, 9.2223e-02],\n",
      "         [1.8851e-01, 1.3501e-01, 2.4906e-02],\n",
      "         [1.3111e-01, 1.0178e-01, 4.0641e-02]],\n",
      "\n",
      "        [[1.1999e-01, 5.6477e-02, 2.5711e-03],\n",
      "         [9.7125e-02, 7.4967e-02, 1.3108e-02],\n",
      "         [1.4483e-01, 1.2553e-01, 9.2544e-02]],\n",
      "\n",
      "        [[1.6042e-01, 1.0844e-01, 5.0374e-02],\n",
      "         [1.7318e-01, 1.0052e-01, 1.0911e-02],\n",
      "         [1.5486e-01, 8.9640e-02, 6.6676e-02]],\n",
      "\n",
      "        [[1.7275e-01, 8.4818e-02, 5.1690e-02],\n",
      "         [1.9420e-01, 1.0835e-01, 2.9547e-02],\n",
      "         [2.1013e-01, 8.2685e-02, 9.1195e-03]],\n",
      "\n",
      "        [[1.8396e-01, 1.0563e-01, 9.7838e-04],\n",
      "         [1.6027e-01, 1.2312e-01, 2.1963e-02],\n",
      "         [1.3232e-01, 1.0485e-01, 1.5795e-02]],\n",
      "\n",
      "        [[1.9141e-01, 6.9299e-02, 1.2400e-02],\n",
      "         [1.7492e-01, 1.2855e-01, 6.2368e-02],\n",
      "         [1.3856e-01, 1.1284e-01, 5.2102e-02]],\n",
      "\n",
      "        [[2.0517e-01, 6.5040e-02, 1.6463e-02],\n",
      "         [2.4086e-01, 6.9577e-02, 5.6761e-03],\n",
      "         [1.3340e-01, 1.1959e-01, 7.2223e-02]],\n",
      "\n",
      "        [[2.1102e-01, 7.1102e-02, 8.4443e-03],\n",
      "         [1.4374e-01, 7.7980e-02, 2.6231e-02],\n",
      "         [1.5892e-01, 1.1218e-01, 3.9242e-02]],\n",
      "\n",
      "        [[1.4509e-01, 1.0660e-01, 2.9259e-02],\n",
      "         [1.5330e-01, 6.6883e-02, 2.5115e-02],\n",
      "         [1.7454e-01, 8.5273e-02, 1.5645e-03]],\n",
      "\n",
      "        [[2.5970e-01, 1.0821e-01, 1.1455e-02],\n",
      "         [1.6600e-01, 1.2263e-01, 3.5416e-02],\n",
      "         [2.5424e-01, 5.1567e-02, 2.7801e-02]],\n",
      "\n",
      "        [[1.7251e-01, 5.6632e-02, 3.0183e-02],\n",
      "         [1.8976e-01, 5.2806e-02, 6.8649e-03],\n",
      "         [1.4333e-01, 1.1506e-01, 7.4754e-03]],\n",
      "\n",
      "        [[1.3569e-01, 7.9374e-02, 5.3352e-03],\n",
      "         [1.3527e-01, 6.2300e-02, 1.6743e-02],\n",
      "         [1.8749e-01, 1.0875e-01, 2.1936e-02]],\n",
      "\n",
      "        [[1.5713e-01, 1.4209e-01, 2.7724e-02],\n",
      "         [1.6271e-01, 1.3075e-01, 8.8351e-03],\n",
      "         [1.3432e-01, 1.0172e-01, 4.3280e-02]],\n",
      "\n",
      "        [[1.5475e-01, 3.6773e-02, 1.2563e-02],\n",
      "         [1.2120e-01, 7.3799e-02, 9.5630e-03],\n",
      "         [1.5756e-01, 9.9533e-02, 8.6364e-02]],\n",
      "\n",
      "        [[2.1018e-01, 1.1259e-01, 3.1800e-02],\n",
      "         [1.3225e-01, 9.5949e-02, 2.3543e-02],\n",
      "         [1.7449e-01, 8.0950e-02, 1.0416e-04]],\n",
      "\n",
      "        [[1.3312e-01, 7.0883e-02, 5.6936e-02],\n",
      "         [1.9967e-01, 1.0509e-01, 4.8308e-02],\n",
      "         [1.5586e-01, 6.9222e-02, 8.8183e-03]],\n",
      "\n",
      "        [[1.7976e-01, 1.2116e-01, 1.0886e-02],\n",
      "         [1.7038e-01, 1.1997e-01, 3.5365e-03],\n",
      "         [1.3446e-01, 8.9817e-02, 6.7128e-02]],\n",
      "\n",
      "        [[1.4342e-01, 6.2335e-02, 3.6894e-02],\n",
      "         [1.9637e-01, 1.2409e-01, 3.8512e-02],\n",
      "         [1.6422e-01, 1.4762e-01, 2.9368e-02]],\n",
      "\n",
      "        [[1.6968e-01, 7.6412e-02, 5.4295e-02],\n",
      "         [2.0175e-01, 8.2195e-02, 3.0348e-02],\n",
      "         [1.5996e-01, 4.2247e-02, 3.9751e-03]],\n",
      "\n",
      "        [[1.5009e-01, 6.6624e-02, 3.6757e-02],\n",
      "         [1.3210e-01, 7.5145e-02, 4.3598e-02],\n",
      "         [1.1807e-01, 5.9901e-02, 1.5733e-02]],\n",
      "\n",
      "        [[1.7911e-01, 1.4677e-01, 5.4484e-02],\n",
      "         [1.4067e-01, 9.2048e-02, 1.0854e-02],\n",
      "         [1.6731e-01, 6.9222e-02, 2.6135e-02]],\n",
      "\n",
      "        [[1.2434e-01, 7.9719e-02, 1.9141e-02],\n",
      "         [1.7229e-01, 1.4013e-01, 6.9735e-02],\n",
      "         [1.2641e-01, 8.8162e-02, 1.7783e-02]],\n",
      "\n",
      "        [[1.1869e-01, 9.4164e-02, 1.8277e-02],\n",
      "         [1.5383e-01, 1.2753e-01, 2.8178e-02],\n",
      "         [1.5513e-01, 1.1185e-01, 9.1350e-02]],\n",
      "\n",
      "        [[1.7034e-01, 1.4195e-01, 5.8493e-02],\n",
      "         [1.8332e-01, 9.7152e-02, 5.7588e-04],\n",
      "         [1.5994e-01, 5.4891e-02, 1.7583e-02]],\n",
      "\n",
      "        [[1.2091e-01, 8.4333e-02, 2.6188e-02],\n",
      "         [1.2613e-01, 8.2718e-02, 1.6631e-02],\n",
      "         [1.6420e-01, 1.3389e-01, 2.9126e-02]],\n",
      "\n",
      "        [[1.5586e-01, 9.1538e-02, 2.2566e-02],\n",
      "         [1.5737e-01, 1.3508e-01, 5.1062e-02],\n",
      "         [1.6496e-01, 1.2363e-01, 3.4601e-02]],\n",
      "\n",
      "        [[9.7000e-02, 5.4270e-02, 7.8163e-03],\n",
      "         [1.5256e-01, 5.8455e-02, 5.6517e-03],\n",
      "         [1.9866e-01, 1.2073e-01, 2.3572e-03]],\n",
      "\n",
      "        [[1.9230e-01, 9.4701e-02, 3.4197e-02],\n",
      "         [1.3368e-01, 9.6289e-02, 2.4400e-02],\n",
      "         [1.7477e-01, 1.3531e-01, 2.7254e-02]],\n",
      "\n",
      "        [[1.8814e-01, 7.8917e-02, 7.0304e-02],\n",
      "         [1.9462e-01, 7.7420e-02, 8.6774e-03],\n",
      "         [1.5747e-01, 6.6092e-02, 2.1816e-02]],\n",
      "\n",
      "        [[1.5067e-01, 1.1480e-01, 4.6673e-02],\n",
      "         [1.2075e-01, 7.6235e-02, 1.0842e-03],\n",
      "         [1.7457e-01, 1.3675e-01, 4.8666e-02]],\n",
      "\n",
      "        [[1.3757e-01, 1.0015e-01, 5.8406e-02],\n",
      "         [1.5111e-01, 1.0041e-01, 2.4353e-02],\n",
      "         [1.6812e-01, 1.4346e-01, 4.6227e-03]],\n",
      "\n",
      "        [[2.1464e-01, 4.7958e-02, 3.3884e-03],\n",
      "         [1.6538e-01, 1.1954e-01, 5.1477e-02],\n",
      "         [1.2678e-01, 1.0010e-01, 4.1493e-02]],\n",
      "\n",
      "        [[2.0796e-01, 9.9218e-02, 2.8522e-02],\n",
      "         [1.5668e-01, 9.1815e-02, 7.9098e-03],\n",
      "         [1.6080e-01, 7.8861e-02, 3.8526e-03]],\n",
      "\n",
      "        [[1.7292e-01, 1.2506e-01, 1.4964e-02],\n",
      "         [1.3505e-01, 1.0566e-01, 3.1671e-02],\n",
      "         [1.9597e-01, 1.4703e-01, 4.8548e-02]],\n",
      "\n",
      "        [[1.9287e-01, 7.8551e-02, 2.2734e-02],\n",
      "         [2.0331e-01, 8.9747e-02, 3.7152e-02],\n",
      "         [2.0027e-01, 1.4757e-01, 1.2719e-02]],\n",
      "\n",
      "        [[1.5507e-01, 7.7213e-02, 4.4184e-03],\n",
      "         [1.1136e-01, 9.7182e-02, 3.8642e-03],\n",
      "         [1.7617e-01, 1.0482e-01, 1.1140e-02]],\n",
      "\n",
      "        [[1.5759e-01, 2.0307e-02, 7.2455e-03],\n",
      "         [1.3563e-01, 4.8604e-02, 1.3628e-02],\n",
      "         [1.9841e-01, 1.0500e-01, 2.2711e-02]],\n",
      "\n",
      "        [[1.5779e-01, 9.3354e-02, 4.9393e-02],\n",
      "         [1.5535e-01, 9.0206e-02, 1.6175e-02],\n",
      "         [1.7376e-01, 1.0899e-01, 3.8438e-02]],\n",
      "\n",
      "        [[1.9075e-01, 7.5198e-02, 2.3356e-02],\n",
      "         [2.2691e-01, 8.8377e-02, 3.0530e-02],\n",
      "         [1.2395e-01, 7.8740e-02, 5.8226e-02]],\n",
      "\n",
      "        [[8.0961e-02, 7.1485e-02, 2.8712e-03],\n",
      "         [1.2351e-01, 1.0105e-01, 1.7183e-03],\n",
      "         [1.1883e-01, 5.1943e-02, 1.0617e-02]],\n",
      "\n",
      "        [[1.5183e-01, 8.7826e-02, 3.3328e-02],\n",
      "         [1.1393e-01, 9.7868e-02, 3.4937e-03],\n",
      "         [1.8646e-01, 1.3418e-01, 4.2909e-02]],\n",
      "\n",
      "        [[1.5364e-01, 6.2704e-02, 2.8759e-02],\n",
      "         [1.5243e-01, 7.5759e-02, 9.7038e-03],\n",
      "         [1.6656e-01, 1.2756e-01, 6.0636e-02]],\n",
      "\n",
      "        [[1.2388e-01, 6.7446e-02, 1.1683e-02],\n",
      "         [1.9281e-01, 1.2845e-01, 5.6811e-02],\n",
      "         [1.9079e-01, 1.2672e-01, 7.2858e-02]],\n",
      "\n",
      "        [[2.0725e-01, 9.1332e-02, 2.6992e-02],\n",
      "         [1.7688e-01, 1.0128e-01, 3.2299e-02],\n",
      "         [1.7163e-01, 1.3451e-01, 1.8330e-03]]], device='cuda:0',\n",
      "       grad_fn=<LinalgSvdBackward0>)\n",
      "특이값 곱하기: \n",
      "tensor([[[3.7290e-01, 2.2847e-01, 9.1672e-02],\n",
      "         [3.2296e-01, 2.1662e-01, 1.1011e-01],\n",
      "         [3.0395e-01, 2.3539e-01, 5.6691e-04]],\n",
      "\n",
      "        [[2.8190e-01, 1.7893e-01, 6.0101e-02],\n",
      "         [3.3516e-01, 9.0562e-02, 9.6245e-03],\n",
      "         [2.4797e-01, 9.3895e-02, 1.6391e-02]],\n",
      "\n",
      "        [[3.5589e-01, 2.2091e-01, 1.9338e-03],\n",
      "         [3.6730e-01, 3.2361e-01, 5.1730e-02],\n",
      "         [2.7031e-01, 1.6683e-01, 2.6179e-02]],\n",
      "\n",
      "        [[4.3441e-01, 3.4275e-01, 3.8885e-02],\n",
      "         [3.3969e-01, 1.7299e-01, 9.6691e-02],\n",
      "         [3.4834e-01, 1.5025e-01, 1.2973e-02]],\n",
      "\n",
      "        [[3.6817e-01, 2.1771e-01, 1.8445e-01],\n",
      "         [3.7701e-01, 2.7003e-01, 4.9813e-02],\n",
      "         [2.6221e-01, 2.0357e-01, 8.1281e-02]],\n",
      "\n",
      "        [[2.3997e-01, 1.1295e-01, 5.1423e-03],\n",
      "         [1.9425e-01, 1.4993e-01, 2.6215e-02],\n",
      "         [2.8966e-01, 2.5105e-01, 1.8509e-01]],\n",
      "\n",
      "        [[3.2085e-01, 2.1688e-01, 1.0075e-01],\n",
      "         [3.4636e-01, 2.0104e-01, 2.1823e-02],\n",
      "         [3.0973e-01, 1.7928e-01, 1.3335e-01]],\n",
      "\n",
      "        [[3.4550e-01, 1.6964e-01, 1.0338e-01],\n",
      "         [3.8840e-01, 2.1670e-01, 5.9094e-02],\n",
      "         [4.2026e-01, 1.6537e-01, 1.8239e-02]],\n",
      "\n",
      "        [[3.6791e-01, 2.1126e-01, 1.9568e-03],\n",
      "         [3.2054e-01, 2.4625e-01, 4.3926e-02],\n",
      "         [2.6465e-01, 2.0970e-01, 3.1590e-02]],\n",
      "\n",
      "        [[3.8282e-01, 1.3860e-01, 2.4799e-02],\n",
      "         [3.4984e-01, 2.5711e-01, 1.2474e-01],\n",
      "         [2.7713e-01, 2.2568e-01, 1.0420e-01]],\n",
      "\n",
      "        [[4.1035e-01, 1.3008e-01, 3.2926e-02],\n",
      "         [4.8173e-01, 1.3915e-01, 1.1352e-02],\n",
      "         [2.6679e-01, 2.3919e-01, 1.4445e-01]],\n",
      "\n",
      "        [[4.2203e-01, 1.4220e-01, 1.6889e-02],\n",
      "         [2.8748e-01, 1.5596e-01, 5.2462e-02],\n",
      "         [3.1784e-01, 2.2435e-01, 7.8484e-02]],\n",
      "\n",
      "        [[2.9019e-01, 2.1319e-01, 5.8518e-02],\n",
      "         [3.0660e-01, 1.3377e-01, 5.0230e-02],\n",
      "         [3.4908e-01, 1.7055e-01, 3.1290e-03]],\n",
      "\n",
      "        [[5.1941e-01, 2.1643e-01, 2.2910e-02],\n",
      "         [3.3199e-01, 2.4527e-01, 7.0832e-02],\n",
      "         [5.0848e-01, 1.0313e-01, 5.5603e-02]],\n",
      "\n",
      "        [[3.4503e-01, 1.1326e-01, 6.0365e-02],\n",
      "         [3.7952e-01, 1.0561e-01, 1.3730e-02],\n",
      "         [2.8667e-01, 2.3011e-01, 1.4951e-02]],\n",
      "\n",
      "        [[2.7138e-01, 1.5875e-01, 1.0670e-02],\n",
      "         [2.7054e-01, 1.2460e-01, 3.3487e-02],\n",
      "         [3.7498e-01, 2.1751e-01, 4.3873e-02]],\n",
      "\n",
      "        [[3.1426e-01, 2.8418e-01, 5.5448e-02],\n",
      "         [3.2542e-01, 2.6150e-01, 1.7670e-02],\n",
      "         [2.6864e-01, 2.0343e-01, 8.6560e-02]],\n",
      "\n",
      "        [[3.0950e-01, 7.3546e-02, 2.5126e-02],\n",
      "         [2.4241e-01, 1.4760e-01, 1.9126e-02],\n",
      "         [3.1512e-01, 1.9907e-01, 1.7273e-01]],\n",
      "\n",
      "        [[4.2037e-01, 2.2517e-01, 6.3601e-02],\n",
      "         [2.6451e-01, 1.9190e-01, 4.7087e-02],\n",
      "         [3.4897e-01, 1.6190e-01, 2.0831e-04]],\n",
      "\n",
      "        [[2.6623e-01, 1.4177e-01, 1.1387e-01],\n",
      "         [3.9934e-01, 2.1019e-01, 9.6616e-02],\n",
      "         [3.1173e-01, 1.3844e-01, 1.7637e-02]],\n",
      "\n",
      "        [[3.5951e-01, 2.4231e-01, 2.1773e-02],\n",
      "         [3.4076e-01, 2.3995e-01, 7.0730e-03],\n",
      "         [2.6891e-01, 1.7963e-01, 1.3426e-01]],\n",
      "\n",
      "        [[2.8684e-01, 1.2467e-01, 7.3787e-02],\n",
      "         [3.9273e-01, 2.4818e-01, 7.7025e-02],\n",
      "         [3.2843e-01, 2.9524e-01, 5.8736e-02]],\n",
      "\n",
      "        [[3.3936e-01, 1.5282e-01, 1.0859e-01],\n",
      "         [4.0350e-01, 1.6439e-01, 6.0696e-02],\n",
      "         [3.1993e-01, 8.4493e-02, 7.9503e-03]],\n",
      "\n",
      "        [[3.0017e-01, 1.3325e-01, 7.3514e-02],\n",
      "         [2.6420e-01, 1.5029e-01, 8.7195e-02],\n",
      "         [2.3614e-01, 1.1980e-01, 3.1466e-02]],\n",
      "\n",
      "        [[3.5821e-01, 2.9353e-01, 1.0897e-01],\n",
      "         [2.8135e-01, 1.8410e-01, 2.1708e-02],\n",
      "         [3.3461e-01, 1.3844e-01, 5.2270e-02]],\n",
      "\n",
      "        [[2.4867e-01, 1.5944e-01, 3.8282e-02],\n",
      "         [3.4459e-01, 2.8025e-01, 1.3947e-01],\n",
      "         [2.5283e-01, 1.7632e-01, 3.5566e-02]],\n",
      "\n",
      "        [[2.3738e-01, 1.8833e-01, 3.6553e-02],\n",
      "         [3.0766e-01, 2.5507e-01, 5.6357e-02],\n",
      "         [3.1027e-01, 2.2371e-01, 1.8270e-01]],\n",
      "\n",
      "        [[3.4068e-01, 2.8391e-01, 1.1699e-01],\n",
      "         [3.6665e-01, 1.9430e-01, 1.1518e-03],\n",
      "         [3.1987e-01, 1.0978e-01, 3.5167e-02]],\n",
      "\n",
      "        [[2.4181e-01, 1.6867e-01, 5.2376e-02],\n",
      "         [2.5227e-01, 1.6544e-01, 3.3263e-02],\n",
      "         [3.2839e-01, 2.6778e-01, 5.8253e-02]],\n",
      "\n",
      "        [[3.1172e-01, 1.8308e-01, 4.5131e-02],\n",
      "         [3.1475e-01, 2.7016e-01, 1.0212e-01],\n",
      "         [3.2992e-01, 2.4726e-01, 6.9203e-02]],\n",
      "\n",
      "        [[1.9400e-01, 1.0854e-01, 1.5633e-02],\n",
      "         [3.0511e-01, 1.1691e-01, 1.1303e-02],\n",
      "         [3.9733e-01, 2.4145e-01, 4.7145e-03]],\n",
      "\n",
      "        [[3.8461e-01, 1.8940e-01, 6.8393e-02],\n",
      "         [2.6737e-01, 1.9258e-01, 4.8800e-02],\n",
      "         [3.4955e-01, 2.7061e-01, 5.4508e-02]],\n",
      "\n",
      "        [[3.7628e-01, 1.5783e-01, 1.4061e-01],\n",
      "         [3.8925e-01, 1.5484e-01, 1.7355e-02],\n",
      "         [3.1493e-01, 1.3218e-01, 4.3632e-02]],\n",
      "\n",
      "        [[3.0133e-01, 2.2961e-01, 9.3347e-02],\n",
      "         [2.4150e-01, 1.5247e-01, 2.1684e-03],\n",
      "         [3.4914e-01, 2.7351e-01, 9.7332e-02]],\n",
      "\n",
      "        [[2.7514e-01, 2.0031e-01, 1.1681e-01],\n",
      "         [3.0223e-01, 2.0082e-01, 4.8706e-02],\n",
      "         [3.3624e-01, 2.8691e-01, 9.2454e-03]],\n",
      "\n",
      "        [[4.2927e-01, 9.5915e-02, 6.7768e-03],\n",
      "         [3.3076e-01, 2.3909e-01, 1.0295e-01],\n",
      "         [2.5356e-01, 2.0019e-01, 8.2987e-02]],\n",
      "\n",
      "        [[4.1592e-01, 1.9844e-01, 5.7044e-02],\n",
      "         [3.1337e-01, 1.8363e-01, 1.5820e-02],\n",
      "         [3.2159e-01, 1.5772e-01, 7.7052e-03]],\n",
      "\n",
      "        [[3.4585e-01, 2.5013e-01, 2.9927e-02],\n",
      "         [2.7011e-01, 2.1133e-01, 6.3342e-02],\n",
      "         [3.9194e-01, 2.9407e-01, 9.7095e-02]],\n",
      "\n",
      "        [[3.8575e-01, 1.5710e-01, 4.5469e-02],\n",
      "         [4.0661e-01, 1.7949e-01, 7.4304e-02],\n",
      "         [4.0053e-01, 2.9514e-01, 2.5438e-02]],\n",
      "\n",
      "        [[3.1014e-01, 1.5443e-01, 8.8368e-03],\n",
      "         [2.2271e-01, 1.9436e-01, 7.7285e-03],\n",
      "         [3.5234e-01, 2.0963e-01, 2.2280e-02]],\n",
      "\n",
      "        [[3.1518e-01, 4.0614e-02, 1.4491e-02],\n",
      "         [2.7127e-01, 9.7208e-02, 2.7256e-02],\n",
      "         [3.9681e-01, 2.1000e-01, 4.5422e-02]],\n",
      "\n",
      "        [[3.1559e-01, 1.8671e-01, 9.8786e-02],\n",
      "         [3.1070e-01, 1.8041e-01, 3.2349e-02],\n",
      "         [3.4752e-01, 2.1799e-01, 7.6877e-02]],\n",
      "\n",
      "        [[3.8150e-01, 1.5040e-01, 4.6713e-02],\n",
      "         [4.5382e-01, 1.7675e-01, 6.1060e-02],\n",
      "         [2.4790e-01, 1.5748e-01, 1.1645e-01]],\n",
      "\n",
      "        [[1.6192e-01, 1.4297e-01, 5.7425e-03],\n",
      "         [2.4701e-01, 2.0210e-01, 3.4367e-03],\n",
      "         [2.3765e-01, 1.0389e-01, 2.1233e-02]],\n",
      "\n",
      "        [[3.0367e-01, 1.7565e-01, 6.6655e-02],\n",
      "         [2.2787e-01, 1.9574e-01, 6.9874e-03],\n",
      "         [3.7292e-01, 2.6836e-01, 8.5817e-02]],\n",
      "\n",
      "        [[3.0727e-01, 1.2541e-01, 5.7517e-02],\n",
      "         [3.0486e-01, 1.5152e-01, 1.9408e-02],\n",
      "         [3.3312e-01, 2.5512e-01, 1.2127e-01]],\n",
      "\n",
      "        [[2.4777e-01, 1.3489e-01, 2.3367e-02],\n",
      "         [3.8562e-01, 2.5689e-01, 1.1362e-01],\n",
      "         [3.8157e-01, 2.5344e-01, 1.4572e-01]],\n",
      "\n",
      "        [[4.1450e-01, 1.8266e-01, 5.3985e-02],\n",
      "         [3.5377e-01, 2.0256e-01, 6.4598e-02],\n",
      "         [3.4327e-01, 2.6901e-01, 3.6661e-03]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "대각행렬: \n",
      "tensor([[[[0.3729, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2285, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0917]],\n",
      "\n",
      "         [[0.3230, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2166, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1101]],\n",
      "\n",
      "         [[0.3039, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2354, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0006]]],\n",
      "\n",
      "\n",
      "        [[[0.2819, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1789, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0601]],\n",
      "\n",
      "         [[0.3352, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0906, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0096]],\n",
      "\n",
      "         [[0.2480, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0939, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0164]]],\n",
      "\n",
      "\n",
      "        [[[0.3559, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2209, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0019]],\n",
      "\n",
      "         [[0.3673, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3236, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0517]],\n",
      "\n",
      "         [[0.2703, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1668, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0262]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3073, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1254, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0575]],\n",
      "\n",
      "         [[0.3049, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1515, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0194]],\n",
      "\n",
      "         [[0.3331, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2551, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1213]]],\n",
      "\n",
      "\n",
      "        [[[0.2478, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1349, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0234]],\n",
      "\n",
      "         [[0.3856, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2569, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1136]],\n",
      "\n",
      "         [[0.3816, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2534, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1457]]],\n",
      "\n",
      "\n",
      "        [[[0.4145, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1827, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0540]],\n",
      "\n",
      "         [[0.3538, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2026, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0646]],\n",
      "\n",
      "         [[0.3433, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2690, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0037]]]], device='cuda:0',\n",
      "       grad_fn=<DiagEmbedBackward0>)\n",
      "------------------------------------\n",
      "Layer: classifier.layer_dict.conv1.conv.weight\n",
      "특이값 : \n",
      "tensor([[[0.1273, 0.0610, 0.0247],\n",
      "         [0.1148, 0.0712, 0.0250],\n",
      "         [0.1818, 0.0466, 0.0147],\n",
      "         ...,\n",
      "         [0.1301, 0.0846, 0.0403],\n",
      "         [0.1451, 0.0410, 0.0067],\n",
      "         [0.0858, 0.0625, 0.0125]],\n",
      "\n",
      "        [[0.0913, 0.0464, 0.0149],\n",
      "         [0.1519, 0.0336, 0.0053],\n",
      "         [0.1460, 0.0887, 0.0505],\n",
      "         ...,\n",
      "         [0.1270, 0.0506, 0.0300],\n",
      "         [0.1129, 0.0314, 0.0115],\n",
      "         [0.0927, 0.0646, 0.0311]],\n",
      "\n",
      "        [[0.1355, 0.0758, 0.0039],\n",
      "         [0.0749, 0.0520, 0.0168],\n",
      "         [0.1039, 0.0771, 0.0439],\n",
      "         ...,\n",
      "         [0.1167, 0.0482, 0.0277],\n",
      "         [0.1220, 0.0360, 0.0063],\n",
      "         [0.1001, 0.0571, 0.0052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1197, 0.0312, 0.0131],\n",
      "         [0.1135, 0.0586, 0.0091],\n",
      "         [0.1293, 0.1145, 0.0378],\n",
      "         ...,\n",
      "         [0.0789, 0.0606, 0.0176],\n",
      "         [0.1337, 0.0779, 0.0247],\n",
      "         [0.1257, 0.0380, 0.0168]],\n",
      "\n",
      "        [[0.1120, 0.0424, 0.0100],\n",
      "         [0.0668, 0.0441, 0.0134],\n",
      "         [0.1050, 0.0715, 0.0107],\n",
      "         ...,\n",
      "         [0.1096, 0.0549, 0.0508],\n",
      "         [0.1062, 0.0850, 0.0218],\n",
      "         [0.1058, 0.0795, 0.0237]],\n",
      "\n",
      "        [[0.1024, 0.0589, 0.0129],\n",
      "         [0.1059, 0.0564, 0.0048],\n",
      "         [0.1191, 0.0734, 0.0463],\n",
      "         ...,\n",
      "         [0.1074, 0.1015, 0.0298],\n",
      "         [0.1025, 0.0639, 0.0469],\n",
      "         [0.1209, 0.0880, 0.0311]]], device='cuda:0',\n",
      "       grad_fn=<LinalgSvdBackward0>)\n",
      "특이값 곱하기: \n",
      "tensor([[[0.2547, 0.1220, 0.0495],\n",
      "         [0.2296, 0.1423, 0.0501],\n",
      "         [0.3636, 0.0932, 0.0294],\n",
      "         ...,\n",
      "         [0.2602, 0.1692, 0.0806],\n",
      "         [0.2902, 0.0821, 0.0134],\n",
      "         [0.1716, 0.1250, 0.0249]],\n",
      "\n",
      "        [[0.1827, 0.0929, 0.0298],\n",
      "         [0.3038, 0.0671, 0.0107],\n",
      "         [0.2921, 0.1775, 0.1009],\n",
      "         ...,\n",
      "         [0.2539, 0.1012, 0.0600],\n",
      "         [0.2258, 0.0628, 0.0230],\n",
      "         [0.1854, 0.1291, 0.0622]],\n",
      "\n",
      "        [[0.2710, 0.1517, 0.0078],\n",
      "         [0.1497, 0.1041, 0.0337],\n",
      "         [0.2077, 0.1543, 0.0878],\n",
      "         ...,\n",
      "         [0.2335, 0.0964, 0.0554],\n",
      "         [0.2441, 0.0720, 0.0127],\n",
      "         [0.2001, 0.1142, 0.0103]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2395, 0.0625, 0.0262],\n",
      "         [0.2269, 0.1172, 0.0182],\n",
      "         [0.2586, 0.2290, 0.0757],\n",
      "         ...,\n",
      "         [0.1578, 0.1211, 0.0352],\n",
      "         [0.2675, 0.1559, 0.0493],\n",
      "         [0.2514, 0.0760, 0.0336]],\n",
      "\n",
      "        [[0.2240, 0.0848, 0.0200],\n",
      "         [0.1335, 0.0881, 0.0268],\n",
      "         [0.2101, 0.1429, 0.0214],\n",
      "         ...,\n",
      "         [0.2191, 0.1098, 0.1016],\n",
      "         [0.2124, 0.1700, 0.0436],\n",
      "         [0.2116, 0.1590, 0.0474]],\n",
      "\n",
      "        [[0.2048, 0.1177, 0.0259],\n",
      "         [0.2117, 0.1128, 0.0096],\n",
      "         [0.2382, 0.1467, 0.0926],\n",
      "         ...,\n",
      "         [0.2147, 0.2030, 0.0596],\n",
      "         [0.2049, 0.1279, 0.0939],\n",
      "         [0.2417, 0.1760, 0.0622]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "대각행렬: \n",
      "tensor([[[[0.2547, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1220, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0495]],\n",
      "\n",
      "         [[0.2296, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1423, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0501]],\n",
      "\n",
      "         [[0.3636, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0932, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0294]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2602, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1692, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0806]],\n",
      "\n",
      "         [[0.2902, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0821, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0134]],\n",
      "\n",
      "         [[0.1716, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1250, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0249]]],\n",
      "\n",
      "\n",
      "        [[[0.1827, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0929, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0298]],\n",
      "\n",
      "         [[0.3038, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0671, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0107]],\n",
      "\n",
      "         [[0.2921, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1775, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1009]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2539, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1012, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0600]],\n",
      "\n",
      "         [[0.2258, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0628, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0230]],\n",
      "\n",
      "         [[0.1854, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1291, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0622]]],\n",
      "\n",
      "\n",
      "        [[[0.2710, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1517, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0078]],\n",
      "\n",
      "         [[0.1497, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1041, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0337]],\n",
      "\n",
      "         [[0.2077, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1543, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0878]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2335, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0964, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0554]],\n",
      "\n",
      "         [[0.2441, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0720, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0127]],\n",
      "\n",
      "         [[0.2001, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1142, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0103]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.2395, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0625, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0262]],\n",
      "\n",
      "         [[0.2269, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1172, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0182]],\n",
      "\n",
      "         [[0.2586, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2290, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0757]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1578, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1211, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0352]],\n",
      "\n",
      "         [[0.2675, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1559, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0493]],\n",
      "\n",
      "         [[0.2514, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0760, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0336]]],\n",
      "\n",
      "\n",
      "        [[[0.2240, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0848, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0200]],\n",
      "\n",
      "         [[0.1335, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0881, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0268]],\n",
      "\n",
      "         [[0.2101, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1429, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0214]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2191, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1098, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1016]],\n",
      "\n",
      "         [[0.2124, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1700, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0436]],\n",
      "\n",
      "         [[0.2116, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1590, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0474]]],\n",
      "\n",
      "\n",
      "        [[[0.2048, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1177, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0259]],\n",
      "\n",
      "         [[0.2117, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1128, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0096]],\n",
      "\n",
      "         [[0.2382, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1467, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0926]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2147, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2030, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0596]],\n",
      "\n",
      "         [[0.2049, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1279, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0939]],\n",
      "\n",
      "         [[0.2417, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1760, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0622]]]], device='cuda:0',\n",
      "       grad_fn=<DiagEmbedBackward0>)\n",
      "------------------------------------\n",
      "Layer: classifier.layer_dict.conv2.conv.weight\n",
      "특이값 : \n",
      "tensor([[[1.2253e-01, 8.5623e-02, 4.1550e-02],\n",
      "         [1.6439e-01, 7.6272e-02, 1.7013e-02],\n",
      "         [1.2166e-01, 9.9934e-02, 7.9870e-02],\n",
      "         ...,\n",
      "         [1.1858e-01, 1.0267e-01, 1.3895e-03],\n",
      "         [1.1732e-01, 1.0558e-01, 4.2457e-02],\n",
      "         [1.1732e-01, 6.3027e-02, 7.5676e-03]],\n",
      "\n",
      "        [[1.1927e-01, 3.5618e-02, 8.1621e-06],\n",
      "         [8.3032e-02, 5.7344e-02, 7.0517e-04],\n",
      "         [1.0661e-01, 7.7844e-02, 6.0350e-03],\n",
      "         ...,\n",
      "         [1.0928e-01, 6.4834e-02, 1.3461e-02],\n",
      "         [8.5348e-02, 2.4793e-02, 2.7529e-03],\n",
      "         [9.2125e-02, 2.4676e-02, 1.0854e-02]],\n",
      "\n",
      "        [[7.6050e-02, 4.9894e-02, 3.2317e-02],\n",
      "         [1.1863e-01, 8.7823e-02, 2.5911e-02],\n",
      "         [1.1918e-01, 6.7633e-02, 3.8761e-02],\n",
      "         ...,\n",
      "         [1.1650e-01, 6.6512e-02, 4.6831e-02],\n",
      "         [1.4834e-01, 4.0743e-02, 1.6625e-02],\n",
      "         [1.3747e-01, 9.4442e-02, 3.2845e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.3495e-01, 8.5060e-02, 3.0742e-02],\n",
      "         [9.3469e-02, 6.3823e-02, 6.6969e-03],\n",
      "         [1.2904e-01, 9.6295e-02, 3.4720e-03],\n",
      "         ...,\n",
      "         [1.3754e-01, 7.6080e-02, 2.7220e-02],\n",
      "         [1.5527e-01, 6.9065e-02, 2.1873e-02],\n",
      "         [8.4760e-02, 5.8522e-02, 2.5126e-02]],\n",
      "\n",
      "        [[8.1476e-02, 5.5780e-02, 3.0115e-03],\n",
      "         [1.1422e-01, 5.8505e-02, 1.5015e-02],\n",
      "         [1.3132e-01, 7.6166e-02, 2.0644e-02],\n",
      "         ...,\n",
      "         [7.1886e-02, 6.7613e-02, 1.2457e-02],\n",
      "         [1.3736e-01, 4.1661e-02, 1.2863e-02],\n",
      "         [1.4428e-01, 7.4551e-02, 2.5406e-02]],\n",
      "\n",
      "        [[1.1998e-01, 1.0532e-01, 2.4516e-02],\n",
      "         [8.3610e-02, 5.6994e-02, 2.6029e-02],\n",
      "         [1.2706e-01, 9.1017e-02, 4.5599e-02],\n",
      "         ...,\n",
      "         [1.2674e-01, 6.8116e-02, 3.7206e-02],\n",
      "         [8.9939e-02, 5.1177e-02, 4.2440e-03],\n",
      "         [9.4130e-02, 5.0705e-02, 3.0623e-02]]], device='cuda:0',\n",
      "       grad_fn=<LinalgSvdBackward0>)\n",
      "특이값 곱하기: \n",
      "tensor([[[2.4507e-01, 1.7125e-01, 8.3100e-02],\n",
      "         [3.2879e-01, 1.5254e-01, 3.4026e-02],\n",
      "         [2.4331e-01, 1.9987e-01, 1.5974e-01],\n",
      "         ...,\n",
      "         [2.3716e-01, 2.0534e-01, 2.7790e-03],\n",
      "         [2.3465e-01, 2.1115e-01, 8.4914e-02],\n",
      "         [2.3464e-01, 1.2605e-01, 1.5135e-02]],\n",
      "\n",
      "        [[2.3854e-01, 7.1237e-02, 1.6324e-05],\n",
      "         [1.6606e-01, 1.1469e-01, 1.4103e-03],\n",
      "         [2.1322e-01, 1.5569e-01, 1.2070e-02],\n",
      "         ...,\n",
      "         [2.1857e-01, 1.2967e-01, 2.6921e-02],\n",
      "         [1.7070e-01, 4.9585e-02, 5.5058e-03],\n",
      "         [1.8425e-01, 4.9352e-02, 2.1709e-02]],\n",
      "\n",
      "        [[1.5210e-01, 9.9788e-02, 6.4634e-02],\n",
      "         [2.3725e-01, 1.7565e-01, 5.1821e-02],\n",
      "         [2.3836e-01, 1.3527e-01, 7.7521e-02],\n",
      "         ...,\n",
      "         [2.3300e-01, 1.3302e-01, 9.3663e-02],\n",
      "         [2.9667e-01, 8.1485e-02, 3.3250e-02],\n",
      "         [2.7493e-01, 1.8888e-01, 6.5689e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.6990e-01, 1.7012e-01, 6.1484e-02],\n",
      "         [1.8694e-01, 1.2765e-01, 1.3394e-02],\n",
      "         [2.5807e-01, 1.9259e-01, 6.9439e-03],\n",
      "         ...,\n",
      "         [2.7508e-01, 1.5216e-01, 5.4439e-02],\n",
      "         [3.1054e-01, 1.3813e-01, 4.3747e-02],\n",
      "         [1.6952e-01, 1.1704e-01, 5.0252e-02]],\n",
      "\n",
      "        [[1.6295e-01, 1.1156e-01, 6.0229e-03],\n",
      "         [2.2844e-01, 1.1701e-01, 3.0031e-02],\n",
      "         [2.6265e-01, 1.5233e-01, 4.1289e-02],\n",
      "         ...,\n",
      "         [1.4377e-01, 1.3523e-01, 2.4913e-02],\n",
      "         [2.7471e-01, 8.3321e-02, 2.5726e-02],\n",
      "         [2.8856e-01, 1.4910e-01, 5.0812e-02]],\n",
      "\n",
      "        [[2.3995e-01, 2.1065e-01, 4.9031e-02],\n",
      "         [1.6722e-01, 1.1399e-01, 5.2057e-02],\n",
      "         [2.5412e-01, 1.8203e-01, 9.1198e-02],\n",
      "         ...,\n",
      "         [2.5347e-01, 1.3623e-01, 7.4413e-02],\n",
      "         [1.7988e-01, 1.0235e-01, 8.4880e-03],\n",
      "         [1.8826e-01, 1.0141e-01, 6.1246e-02]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "대각행렬: \n",
      "tensor([[[[2.4507e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.7125e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 8.3100e-02]],\n",
      "\n",
      "         [[3.2879e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.5254e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 3.4026e-02]],\n",
      "\n",
      "         [[2.4331e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.9987e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.5974e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3716e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.0534e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.7790e-03]],\n",
      "\n",
      "         [[2.3465e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.1115e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 8.4914e-02]],\n",
      "\n",
      "         [[2.3464e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.2605e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.5135e-02]]],\n",
      "\n",
      "\n",
      "        [[[2.3854e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 7.1237e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.6324e-05]],\n",
      "\n",
      "         [[1.6606e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.1469e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.4103e-03]],\n",
      "\n",
      "         [[2.1322e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.5569e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.2070e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.1857e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.2967e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.6921e-02]],\n",
      "\n",
      "         [[1.7070e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 4.9585e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 5.5058e-03]],\n",
      "\n",
      "         [[1.8425e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 4.9352e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.1709e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.5210e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.9788e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.4634e-02]],\n",
      "\n",
      "         [[2.3725e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.7565e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 5.1821e-02]],\n",
      "\n",
      "         [[2.3836e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3527e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 7.7521e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3300e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3302e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 9.3663e-02]],\n",
      "\n",
      "         [[2.9667e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 8.1485e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 3.3250e-02]],\n",
      "\n",
      "         [[2.7493e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.8888e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.5689e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.6990e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.7012e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.1484e-02]],\n",
      "\n",
      "         [[1.8694e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.2765e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.3394e-02]],\n",
      "\n",
      "         [[2.5807e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.9259e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.9439e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.7508e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.5216e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 5.4439e-02]],\n",
      "\n",
      "         [[3.1054e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3813e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.3747e-02]],\n",
      "\n",
      "         [[1.6952e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.1704e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 5.0252e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.6295e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.1156e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.0229e-03]],\n",
      "\n",
      "         [[2.2844e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.1701e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 3.0031e-02]],\n",
      "\n",
      "         [[2.6265e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.5233e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.1289e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.4377e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3523e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.4913e-02]],\n",
      "\n",
      "         [[2.7471e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 8.3321e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.5726e-02]],\n",
      "\n",
      "         [[2.8856e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.4910e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 5.0812e-02]]],\n",
      "\n",
      "\n",
      "        [[[2.3995e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.1065e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.9031e-02]],\n",
      "\n",
      "         [[1.6722e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.1399e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 5.2057e-02]],\n",
      "\n",
      "         [[2.5412e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.8203e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 9.1198e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.5347e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3623e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 7.4413e-02]],\n",
      "\n",
      "         [[1.7988e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.0235e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 8.4880e-03]],\n",
      "\n",
      "         [[1.8826e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.0141e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.1246e-02]]]], device='cuda:0',\n",
      "       grad_fn=<DiagEmbedBackward0>)\n",
      "------------------------------------\n",
      "Layer: classifier.layer_dict.conv3.conv.weight\n",
      "특이값 : \n",
      "tensor([[[0.0943, 0.0343, 0.0202],\n",
      "         [0.1481, 0.1020, 0.0204],\n",
      "         [0.1108, 0.0503, 0.0125],\n",
      "         ...,\n",
      "         [0.1275, 0.0919, 0.0602],\n",
      "         [0.0981, 0.0727, 0.0189],\n",
      "         [0.1186, 0.0761, 0.0008]],\n",
      "\n",
      "        [[0.0962, 0.0398, 0.0150],\n",
      "         [0.1372, 0.0900, 0.0126],\n",
      "         [0.1191, 0.0926, 0.0187],\n",
      "         ...,\n",
      "         [0.1268, 0.0825, 0.0636],\n",
      "         [0.1330, 0.0503, 0.0004],\n",
      "         [0.1330, 0.0809, 0.0037]],\n",
      "\n",
      "        [[0.1079, 0.0285, 0.0027],\n",
      "         [0.1544, 0.0856, 0.0113],\n",
      "         [0.1452, 0.0602, 0.0225],\n",
      "         ...,\n",
      "         [0.1047, 0.0823, 0.0237],\n",
      "         [0.0785, 0.0570, 0.0173],\n",
      "         [0.1369, 0.0627, 0.0076]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0880, 0.0485, 0.0336],\n",
      "         [0.1007, 0.0833, 0.0077],\n",
      "         [0.1527, 0.0841, 0.0232],\n",
      "         ...,\n",
      "         [0.1171, 0.0719, 0.0002],\n",
      "         [0.1295, 0.0913, 0.0122],\n",
      "         [0.1090, 0.0821, 0.0303]],\n",
      "\n",
      "        [[0.1517, 0.1075, 0.0324],\n",
      "         [0.1566, 0.0477, 0.0140],\n",
      "         [0.1739, 0.1032, 0.0079],\n",
      "         ...,\n",
      "         [0.1349, 0.1025, 0.0198],\n",
      "         [0.1040, 0.0851, 0.0262],\n",
      "         [0.1153, 0.0431, 0.0066]],\n",
      "\n",
      "        [[0.1286, 0.0987, 0.0379],\n",
      "         [0.1254, 0.0487, 0.0156],\n",
      "         [0.1530, 0.0666, 0.0555],\n",
      "         ...,\n",
      "         [0.1536, 0.0652, 0.0025],\n",
      "         [0.1146, 0.0823, 0.0033],\n",
      "         [0.0799, 0.0672, 0.0026]]], device='cuda:0',\n",
      "       grad_fn=<LinalgSvdBackward0>)\n",
      "특이값 곱하기: \n",
      "tensor([[[0.1887, 0.0685, 0.0404],\n",
      "         [0.2962, 0.2040, 0.0407],\n",
      "         [0.2217, 0.1006, 0.0251],\n",
      "         ...,\n",
      "         [0.2550, 0.1838, 0.1203],\n",
      "         [0.1962, 0.1454, 0.0378],\n",
      "         [0.2371, 0.1523, 0.0017]],\n",
      "\n",
      "        [[0.1925, 0.0797, 0.0301],\n",
      "         [0.2743, 0.1800, 0.0252],\n",
      "         [0.2382, 0.1852, 0.0374],\n",
      "         ...,\n",
      "         [0.2536, 0.1649, 0.1271],\n",
      "         [0.2661, 0.1006, 0.0008],\n",
      "         [0.2661, 0.1618, 0.0074]],\n",
      "\n",
      "        [[0.2157, 0.0570, 0.0054],\n",
      "         [0.3089, 0.1712, 0.0226],\n",
      "         [0.2904, 0.1203, 0.0449],\n",
      "         ...,\n",
      "         [0.2094, 0.1645, 0.0473],\n",
      "         [0.1571, 0.1141, 0.0347],\n",
      "         [0.2739, 0.1254, 0.0152]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1759, 0.0970, 0.0671],\n",
      "         [0.2015, 0.1665, 0.0153],\n",
      "         [0.3053, 0.1681, 0.0464],\n",
      "         ...,\n",
      "         [0.2341, 0.1437, 0.0004],\n",
      "         [0.2590, 0.1826, 0.0244],\n",
      "         [0.2180, 0.1641, 0.0606]],\n",
      "\n",
      "        [[0.3034, 0.2150, 0.0648],\n",
      "         [0.3132, 0.0953, 0.0279],\n",
      "         [0.3478, 0.2063, 0.0158],\n",
      "         ...,\n",
      "         [0.2698, 0.2050, 0.0397],\n",
      "         [0.2079, 0.1701, 0.0524],\n",
      "         [0.2307, 0.0862, 0.0132]],\n",
      "\n",
      "        [[0.2571, 0.1974, 0.0757],\n",
      "         [0.2508, 0.0974, 0.0312],\n",
      "         [0.3060, 0.1332, 0.1111],\n",
      "         ...,\n",
      "         [0.3073, 0.1305, 0.0050],\n",
      "         [0.2293, 0.1646, 0.0067],\n",
      "         [0.1599, 0.1343, 0.0052]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "대각행렬: \n",
      "tensor([[[[0.1887, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0685, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0404]],\n",
      "\n",
      "         [[0.2962, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2040, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0407]],\n",
      "\n",
      "         [[0.2217, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1006, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0251]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2550, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1838, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1203]],\n",
      "\n",
      "         [[0.1962, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1454, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0378]],\n",
      "\n",
      "         [[0.2371, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1523, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0017]]],\n",
      "\n",
      "\n",
      "        [[[0.1925, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0797, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0301]],\n",
      "\n",
      "         [[0.2743, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1800, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0252]],\n",
      "\n",
      "         [[0.2382, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1852, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0374]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2536, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1649, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1271]],\n",
      "\n",
      "         [[0.2661, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1006, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0008]],\n",
      "\n",
      "         [[0.2661, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1618, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0074]]],\n",
      "\n",
      "\n",
      "        [[[0.2157, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0570, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0054]],\n",
      "\n",
      "         [[0.3089, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1712, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0226]],\n",
      "\n",
      "         [[0.2904, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1203, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0449]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2094, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1645, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0473]],\n",
      "\n",
      "         [[0.1571, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1141, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0347]],\n",
      "\n",
      "         [[0.2739, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1254, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0152]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.1759, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0970, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0671]],\n",
      "\n",
      "         [[0.2015, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1665, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0153]],\n",
      "\n",
      "         [[0.3053, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1681, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0464]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2341, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1437, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0004]],\n",
      "\n",
      "         [[0.2590, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1826, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0244]],\n",
      "\n",
      "         [[0.2180, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1641, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0606]]],\n",
      "\n",
      "\n",
      "        [[[0.3034, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2150, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0648]],\n",
      "\n",
      "         [[0.3132, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0953, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0279]],\n",
      "\n",
      "         [[0.3478, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2063, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0158]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2698, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2050, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0397]],\n",
      "\n",
      "         [[0.2079, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1701, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0524]],\n",
      "\n",
      "         [[0.2307, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0862, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0132]]],\n",
      "\n",
      "\n",
      "        [[[0.2571, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1974, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0757]],\n",
      "\n",
      "         [[0.2508, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0974, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0312]],\n",
      "\n",
      "         [[0.3060, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1332, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.3073, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1305, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0050]],\n",
      "\n",
      "         [[0.2293, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1646, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0067]],\n",
      "\n",
      "         [[0.1599, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1343, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0052]]]], device='cuda:0',\n",
      "       grad_fn=<DiagEmbedBackward0>)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 각 레이어의 가중치에 대한 SVD를 수행합니다\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:  # weight에 대해서만 SVD를 수행합니다\n",
    "        if \"norm_layer\" not in name:\n",
    "            if \"linear\" not in name:\n",
    "                print(f'Layer: {name}')\n",
    "                original_shape = param.shape\n",
    "                u, s, v = torch.svd(param, some=False)  # SVD 수행\n",
    "                print(\"특이값 : \")\n",
    "                print(s)\n",
    "                \n",
    "                s *= 2\n",
    "                print(\"특이값 곱하기: \")\n",
    "                print(s)\n",
    "                \n",
    "                print(\"대각행렬: \")\n",
    "                diag = torch.diag_embed(s)\n",
    "                print(diag)\n",
    "                \n",
    "                print('------------------------------------')\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
