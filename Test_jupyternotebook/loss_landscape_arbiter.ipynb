{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16249129",
   "metadata": {},
   "source": [
    "## [참고]\n",
    "### https://cocoa-t.tistory.com/entry/PyHessian-Loss-Landscape-%EC%8B%9C%EA%B0%81%ED%99%94-PyHessian-Neural-Networks-Through-the-Lens-of-the-Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5f86c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyhessian\n",
    "#!pip install pytorchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36ee9e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyhessian import hessian\n",
    "import numpy as np\n",
    "\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model # model\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import easydict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline \n",
    "\n",
    "# enable cuda devices\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "253a5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from meta_neural_network_architectures import VGGReLUNormNetwork, ResNet12\n",
    "from utils.parser_utils import get_args\n",
    "from data import MetaLearningSystemDataLoader\n",
    "from experiment_builder import ExperimentBuilder\n",
    "\n",
    "from few_shot_learning_system import MAMLFewShotClassifier\n",
    "from utils import loss_landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "199f9b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.environ['DATASET_DIR'] ===  C:/Users/JM/PycharmProjects/MAML/datasets\n"
     ]
    }
   ],
   "source": [
    "os.environ['DATASET_DIR'] = 'C:/Users/JM/PycharmProjects/MAML/datasets'\n",
    "print(\"os.environ['DATASET_DIR'] === \", os.environ['DATASET_DIR'])\n",
    "\n",
    "args = easydict.EasyDict(\n",
    "{\n",
    "  \"batch_size\":2,\n",
    "  \"image_height\":84,\n",
    "  \"image_width\":84,\n",
    "  \"image_channels\":3,\n",
    "  \"gpu_to_use\":0,\n",
    "  \"num_dataprovider_workers\":4,\n",
    "  \"max_models_to_save\":5,\n",
    "  \"dataset_name\":\"mini_imagenet_full_size\",\n",
    "  \"dataset_path\":\"mini_imagenet_full_size\",\n",
    "  \"reset_stored_paths\":False,\n",
    "  \"experiment_name\":\"../MAML+Arbiter_5way_5shot\",\n",
    "  \"train_seed\": 0, \"val_seed\": 0,\n",
    "  \"indexes_of_folders_indicating_class\": [-3, -2],\n",
    "  \"sets_are_pre_split\": True,\n",
    "  \"train_val_test_split\": [0.64, 0.16, 0.20],\n",
    "  \"evaluate_on_test_set_only\": False,\n",
    "\n",
    "  \"total_epochs\": 100,\n",
    "  \"total_iter_per_epoch\":500, \"continue_from_epoch\": -2,\n",
    "  \"num_evaluation_tasks\":600,\n",
    "  \"multi_step_loss_num_epochs\": 15,\n",
    "  \"minimum_per_task_contribution\": 0.01,\n",
    "  \"learnable_per_layer_per_step_inner_loop_learning_rate\": False,\n",
    "  \"enable_inner_loop_optimizable_bn_params\": False,\n",
    "  \"evalute_on_test_set_only\": False,\n",
    "\n",
    "  \"max_pooling\": True,\n",
    "  \"per_step_bn_statistics\": False,\n",
    "  \"learnable_batch_norm_momentum\": False,\n",
    "  \"load_into_memory\": False,\n",
    "  \"init_inner_loop_learning_rate\": 0.01,\n",
    "  \"init_inner_loop_weight_decay\": 0.0005,\n",
    "  \"learnable_bn_gamma\": True,\n",
    "  \"learnable_bn_beta\": True,\n",
    "\n",
    "  \"dropout_rate_value\":0.0,\n",
    "  \"min_learning_rate\":0.001,\n",
    "  \"meta_learning_rate\":0.001,   \"total_epochs_before_pause\": 100,\n",
    "  \"first_order_to_second_order_epoch\":-1,\n",
    "  \"weight_decay\": 0.0,\n",
    "\n",
    "  \"norm_layer\":\"batch_norm\",\n",
    "  \"cnn_num_filters\":48,\n",
    "  \"num_stages\":4,\n",
    "  \"conv_padding\": True,\n",
    "  \"number_of_training_steps_per_iter\":5,\n",
    "  \"number_of_evaluation_steps_per_iter\":5,\n",
    "  \"cnn_blocks_per_stage\":1,\n",
    "  \"num_classes_per_set\":5,\n",
    "  \"num_samples_per_class\":5,\n",
    "  \"num_target_samples\": 15,\n",
    "  \"samples_per_iter\" : 1,\n",
    "\n",
    "  \"second_order\": True,\n",
    "  \"use_multi_step_loss_optimization\":False,\n",
    "  \"backbone\": \"4-CONV\",\n",
    "  \"arbiter\": True,\n",
    "  \"SWA\": False\n",
    "}\n",
    ")\n",
    "\n",
    "device = torch.cuda.current_device()\n",
    "args.im_shape = (2, 3, args.image_height, args.image_width)\n",
    "\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "args.seed = 104\n",
    "args.reverse_channels=False\n",
    "args.labels_as_int=False\n",
    "args.reset_stored_filepaths=False\n",
    "args.num_of_gpus=1\n",
    "\n",
    "args.continue_from_epoch='latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f85286c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max pooling\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 84, 84])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 42, 42])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 21, 21])\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "torch.Size([2, 48, 10, 10])\n",
      "No inner loop params\n",
      "(VGGReLUNormNetwork) meta network params\n",
      "layer_dict.conv0.conv.weight torch.Size([48, 3, 3, 3])\n",
      "layer_dict.conv0.conv.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv1.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv1.conv.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv2.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv2.conv.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv3.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv3.conv.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.weight torch.Size([48])\n",
      "layer_dict.linear.weights torch.Size([5, 1200])\n",
      "layer_dict.linear.bias torch.Size([5])\n",
      "0.01\n",
      "Inner Loop parameters\n",
      "names_learning_rates_dict.layer_dict-conv0-conv-weight torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-conv0-conv-bias torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-conv1-conv-weight torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-conv1-conv-bias torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-conv2-conv-weight torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-conv2-conv-bias torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-conv3-conv-weight torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-conv3-conv-bias torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-linear-weights torch.Size([6])\n",
      "names_learning_rates_dict.layer_dict-linear-bias torch.Size([6])\n",
      "Outer Loop parameters\n",
      "classifier.layer_dict.conv0.conv.weight torch.Size([48, 3, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv0.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv0.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv0.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv1.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv2.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv3.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.linear.weights torch.Size([5, 1200]) cuda:0 True\n",
      "classifier.layer_dict.linear.bias torch.Size([5]) cuda:0 True\n",
      "arbiter.0.weight torch.Size([20, 20]) cuda:0 True\n",
      "arbiter.0.bias torch.Size([20]) cuda:0 True\n",
      "arbiter.2.weight torch.Size([10, 20]) cuda:0 True\n",
      "arbiter.2.bias torch.Size([10]) cuda:0 True\n",
      "log_dir ===  C:\\Users\\JM\\PycharmProjects\\MAML\\MAML+Arbiter_5way_5shot\n",
      "attempting to find existing checkpoint\n",
      "dataset_splits ==  dict_keys(['test', 'train', 'val'])\n",
      "data {'test': 12000, 'train': 38400, 'val': 9600}\n",
      "train_seed 985773, val_seed: 985773, at start time\n",
      "50000 50000\n"
     ]
    }
   ],
   "source": [
    "# 모델을 구성한다\n",
    "model = MAMLFewShotClassifier(args=args, device=device,\n",
    "                              im_shape=(2, 3,\n",
    "                                        args.image_height, args.image_width))\n",
    "\n",
    "data = MetaLearningSystemDataLoader\n",
    "\n",
    "maml_system = ExperimentBuilder(model=model, data=data, args=args, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e179503e",
   "metadata": {},
   "source": [
    "## 0. 모델 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fed56fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_val_acc': 0.6550666664044063,\n",
       " 'best_val_iter': 16500,\n",
       " 'current_iter': 50000,\n",
       " 'best_epoch': 33,\n",
       " 'train_loss_mean': 0.4869355769753456,\n",
       " 'train_loss_std': 0.12580969358408267,\n",
       " 'train_accuracy_mean': 0.8264800001382828,\n",
       " 'train_accuracy_std': 0.054369606032957596,\n",
       " 'train_loss_importance_vector_0_mean': 0.006000000052154064,\n",
       " 'train_loss_importance_vector_0_std': 0.0,\n",
       " 'train_loss_importance_vector_1_mean': 0.006000000052154064,\n",
       " 'train_loss_importance_vector_1_std': 0.0,\n",
       " 'train_loss_importance_vector_2_mean': 0.006000000052154064,\n",
       " 'train_loss_importance_vector_2_std': 0.0,\n",
       " 'train_loss_importance_vector_3_mean': 0.006000000052154064,\n",
       " 'train_loss_importance_vector_3_std': 0.0,\n",
       " 'train_loss_importance_vector_4_mean': 0.9760000109672546,\n",
       " 'train_loss_importance_vector_4_std': 0.0,\n",
       " 'train_learning_rate_mean': 0.0010000000000000005,\n",
       " 'train_learning_rate_std': 4.336808689942018e-19,\n",
       " 'val_loss_mean': 0.9529854895671209,\n",
       " 'val_loss_std': 0.14067764332256763,\n",
       " 'val_accuracy_mean': 0.6284444446365038,\n",
       " 'val_accuracy_std': 0.06644704535564427,\n",
       " 'val_loss_importance_vector_0_mean': 0.006000000052154064,\n",
       " 'val_loss_importance_vector_0_std': 0.0,\n",
       " 'val_loss_importance_vector_1_mean': 0.006000000052154064,\n",
       " 'val_loss_importance_vector_1_std': 0.0,\n",
       " 'val_loss_importance_vector_2_mean': 0.006000000052154064,\n",
       " 'val_loss_importance_vector_2_std': 0.0,\n",
       " 'val_loss_importance_vector_3_mean': 0.006000000052154064,\n",
       " 'val_loss_importance_vector_3_std': 0.0,\n",
       " 'val_loss_importance_vector_4_mean': 0.9760000109672546,\n",
       " 'val_loss_importance_vector_4_std': 0.0,\n",
       " 'network': OrderedDict([('classifier.layer_dict.conv0.conv.weight',\n",
       "               tensor([[[[-0.2229, -0.4079,  0.0229],\n",
       "                         [-0.4205, -0.3712, -0.1134],\n",
       "                         [-0.1798,  0.0387, -0.0479]],\n",
       "               \n",
       "                        [[ 0.0875,  0.1461,  0.5129],\n",
       "                         [-0.3017,  0.1216,  0.3612],\n",
       "                         [-0.3541,  0.0563,  0.1235]],\n",
       "               \n",
       "                        [[ 0.0737,  0.1099,  0.0783],\n",
       "                         [-0.3082,  0.0307, -0.0709],\n",
       "                         [-0.4206, -0.0144, -0.0508]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0198,  0.5814, -0.0080],\n",
       "                         [ 0.2629, -0.2386,  0.0913],\n",
       "                         [-0.2109, -0.4221, -0.0683]],\n",
       "               \n",
       "                        [[-0.2553,  0.2404, -0.1827],\n",
       "                         [ 0.2202, -0.3339, -0.0279],\n",
       "                         [ 0.2482, -0.1465,  0.2605]],\n",
       "               \n",
       "                        [[-0.2731,  0.2740, -0.2292],\n",
       "                         [-0.0269, -0.0361,  0.2049],\n",
       "                         [ 0.0167, -0.0107,  0.0535]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0299, -0.1038,  0.2057],\n",
       "                         [ 0.1687, -0.2716, -0.3158],\n",
       "                         [ 0.3400,  0.2465, -0.2081]],\n",
       "               \n",
       "                        [[-0.2896, -0.1635,  0.4933],\n",
       "                         [ 0.1406, -0.2526,  0.0727],\n",
       "                         [-0.2914, -0.0921,  0.2599]],\n",
       "               \n",
       "                        [[ 0.0506, -0.2271, -0.0086],\n",
       "                         [ 0.3426,  0.0461, -0.2961],\n",
       "                         [-0.0701,  0.1586,  0.0904]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.4581, -0.0384, -0.2547],\n",
       "                         [ 0.5722, -0.1844, -0.4678],\n",
       "                         [ 0.4209, -0.0859, -0.4157]],\n",
       "               \n",
       "                        [[ 0.0662,  0.0014, -0.0528],\n",
       "                         [ 0.0898, -0.0138, -0.1262],\n",
       "                         [ 0.1354, -0.0191, -0.1259]],\n",
       "               \n",
       "                        [[-0.0572, -0.0806,  0.1829],\n",
       "                         [-0.1003,  0.0039,  0.2054],\n",
       "                         [-0.2051, -0.0804,  0.2327]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0095, -0.0769,  0.0114],\n",
       "                         [ 0.0026,  0.1716, -0.0153],\n",
       "                         [-0.0260,  0.1488,  0.2865]],\n",
       "               \n",
       "                        [[-0.0198, -0.3633, -0.3081],\n",
       "                         [-0.4204, -0.5923, -0.0533],\n",
       "                         [-0.3964, -0.2715,  0.0382]],\n",
       "               \n",
       "                        [[ 0.4216,  0.0781,  0.0493],\n",
       "                         [ 0.1427, -0.0874,  0.1652],\n",
       "                         [-0.2659,  0.0831,  0.4186]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.4538, -0.6162, -0.0460],\n",
       "                         [-0.1943, -0.1862,  0.3005],\n",
       "                         [-0.0698,  0.2001,  0.4582]],\n",
       "               \n",
       "                        [[-0.2833, -0.2912,  0.0184],\n",
       "                         [-0.0533, -0.1320,  0.0959],\n",
       "                         [-0.0484,  0.2811,  0.2402]],\n",
       "               \n",
       "                        [[-0.0906, -0.0367,  0.1275],\n",
       "                         [ 0.0736, -0.0490,  0.1558],\n",
       "                         [ 0.0621,  0.2452, -0.0074]]]], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv0.conv.bias',\n",
       "               tensor([-0.0006, -0.0152,  0.0159, -0.0041,  0.0055,  0.0073,  0.0015,  0.0019,\n",
       "                       -0.0025,  0.0037,  0.0086,  0.0011, -0.0069, -0.0022, -0.0094,  0.0068,\n",
       "                        0.0010, -0.0023,  0.0030, -0.0057, -0.0054,  0.0066, -0.0049,  0.0036,\n",
       "                        0.0215,  0.0061, -0.0054, -0.0105,  0.0121,  0.0012,  0.0025, -0.0007,\n",
       "                        0.0055, -0.0019, -0.0002,  0.0108,  0.0029,  0.0227, -0.0103, -0.0296,\n",
       "                        0.0045,  0.0310,  0.0023,  0.0029, -0.0009,  0.0070, -0.0075,  0.0082],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv0.norm_layer.running_mean',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv0.norm_layer.running_var',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv0.norm_layer.bias',\n",
       "               tensor([-0.6625,  0.3722, -0.9954, -0.0411,  0.0047,  0.0956, -0.5131, -0.3034,\n",
       "                       -0.1839, -0.1969,  1.5331, -0.1288, -0.4148, -0.1719,  0.1362,  0.2457,\n",
       "                       -0.3061, -0.8333,  0.8492, -0.4338, -0.2871, -0.4858, -0.6078,  1.3922,\n",
       "                        0.7910, -0.8025, -0.8787, -0.2624, -0.0506,  1.1441, -0.0318, -0.0249,\n",
       "                        0.1848, -0.3849,  0.0065, -0.1025, -0.5109, -0.1119, -0.7590, -0.0587,\n",
       "                        0.0034, -0.0857, -0.7157, -0.0617, -0.7456, -0.1055, -0.5093, -0.8117],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv0.norm_layer.weight',\n",
       "               tensor([0.8325, 0.8915, 0.9018, 0.8677, 0.3670, 0.9607, 0.8851, 0.7135, 0.7859,\n",
       "                       1.2452, 0.7358, 1.1074, 0.7814, 0.4770, 1.2824, 0.7379, 0.6142, 0.9651,\n",
       "                       0.9260, 0.5504, 0.5593, 0.6499, 0.6584, 0.4491, 1.0249, 0.7382, 0.9084,\n",
       "                       0.7293, 1.2098, 0.9081, 1.1912, 0.4131, 1.0275, 1.1983, 0.4880, 1.0017,\n",
       "                       0.8400, 0.8717, 0.9610, 0.9765, 0.9199, 1.4345, 0.7718, 1.4513, 0.7413,\n",
       "                       0.9843, 0.8423, 0.8699], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv1.conv.weight',\n",
       "               tensor([[[[-2.4550e-01, -7.0583e-02,  1.0165e-01],\n",
       "                         [-1.2881e-02,  1.1375e-01, -5.7472e-02],\n",
       "                         [ 2.2521e-01,  2.6243e-01, -9.7690e-02]],\n",
       "               \n",
       "                        [[ 3.2756e-01,  1.6647e-01, -5.7900e-02],\n",
       "                         [ 1.7206e-01, -2.6450e-01, -2.6424e-02],\n",
       "                         [-4.5610e-02, -6.5824e-02, -1.3930e-01]],\n",
       "               \n",
       "                        [[-2.6223e-01, -8.8651e-01, -1.7628e-01],\n",
       "                         [ 4.2582e-02, -4.5672e-02, -2.3364e-01],\n",
       "                         [ 8.9514e-02,  1.1614e-01,  1.4581e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.1153e-01,  2.8701e-01, -1.5680e-01],\n",
       "                         [ 2.0830e-01, -1.4658e-01, -2.5149e-01],\n",
       "                         [ 1.3287e-01, -2.3293e-01,  1.8406e-01]],\n",
       "               \n",
       "                        [[-2.1624e-01, -9.8587e-02,  4.5522e-02],\n",
       "                         [-1.2330e-01,  1.0650e-01, -2.6539e-01],\n",
       "                         [-1.0172e-01,  2.0036e-01, -2.2697e-01]],\n",
       "               \n",
       "                        [[ 3.2798e-01,  1.7341e-01, -1.5265e-01],\n",
       "                         [ 1.2728e-01, -3.6572e-01, -2.6068e-01],\n",
       "                         [-8.5376e-02,  3.0680e-02,  8.6793e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.3595e-02,  2.9863e-01,  1.2771e-01],\n",
       "                         [-4.6254e-02,  5.6705e-01,  5.5972e-01],\n",
       "                         [ 1.3490e-01,  6.8911e-01,  5.8283e-01]],\n",
       "               \n",
       "                        [[ 1.1154e-01, -6.8610e-02, -3.1506e-02],\n",
       "                         [ 7.6753e-02,  2.7033e-04, -2.3118e-01],\n",
       "                         [ 5.5881e-02,  2.9074e-01, -2.4195e-02]],\n",
       "               \n",
       "                        [[-3.0587e-02, -2.4537e-01,  1.2448e-02],\n",
       "                         [-1.9095e-01,  1.0947e-01,  1.2538e-01],\n",
       "                         [ 1.0883e-01,  2.0870e-01,  2.4730e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.9221e-02, -2.6003e-02, -4.1915e-01],\n",
       "                         [ 1.1460e-01,  3.1237e-01, -1.6163e-01],\n",
       "                         [ 1.2113e-01,  1.5183e-01,  2.4002e-01]],\n",
       "               \n",
       "                        [[-3.8509e-01, -2.0445e-01,  1.6797e-01],\n",
       "                         [-1.6160e-01,  1.4015e-01, -1.4026e-01],\n",
       "                         [ 2.5152e-01,  3.2599e-01,  4.5183e-01]],\n",
       "               \n",
       "                        [[ 1.8231e-01, -1.5691e-01,  1.3338e-02],\n",
       "                         [-1.3949e-01,  4.1793e-02,  1.1197e-01],\n",
       "                         [-4.7997e-02, -2.5364e-02,  2.1427e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.2290e-01, -5.4640e-01, -6.9958e-01],\n",
       "                         [ 1.0006e-01, -2.3374e-02, -9.9947e-02],\n",
       "                         [ 3.1562e-01,  2.2881e-01,  1.8421e-01]],\n",
       "               \n",
       "                        [[ 9.9917e-02,  1.3306e-01,  2.9111e-02],\n",
       "                         [ 2.3437e-01,  1.0363e-01, -3.5433e-02],\n",
       "                         [ 3.6510e-01,  1.2385e-01,  4.3573e-02]],\n",
       "               \n",
       "                        [[-4.5530e-01, -4.3313e-02,  1.9196e-01],\n",
       "                         [ 5.2069e-02,  6.9833e-03,  1.2879e-02],\n",
       "                         [-6.8186e-02,  3.3050e-01,  3.7478e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.4510e-02, -3.7710e-03, -1.5390e-01],\n",
       "                         [ 2.3174e-01, -2.7983e-01, -3.0388e-01],\n",
       "                         [ 3.0722e-01,  1.8152e-01, -6.1590e-01]],\n",
       "               \n",
       "                        [[-2.7028e-01, -5.1731e-01, -7.4208e-01],\n",
       "                         [ 1.4682e-02, -1.0948e-02, -9.1068e-02],\n",
       "                         [ 2.9309e-01,  3.3063e-01,  1.6263e-01]],\n",
       "               \n",
       "                        [[-4.5780e-01, -3.1244e-01, -2.4952e-01],\n",
       "                         [ 1.1341e-01, -2.7278e-01, -1.7275e-01],\n",
       "                         [ 2.9558e-01, -7.5688e-02,  5.6176e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.9877e-01,  9.9871e-02, -1.2622e-01],\n",
       "                         [ 3.6963e-01, -4.1987e-02, -1.8821e-01],\n",
       "                         [ 3.1455e-01, -3.2216e-02,  1.3562e-01]],\n",
       "               \n",
       "                        [[ 1.5572e-01, -9.8052e-02,  1.7208e-02],\n",
       "                         [-2.1017e-01,  1.7668e-01, -2.4732e-01],\n",
       "                         [ 1.0612e-01,  1.5801e-01,  1.6879e-01]],\n",
       "               \n",
       "                        [[-3.1632e-02, -1.2551e-01,  2.6513e-01],\n",
       "                         [-2.3340e-02,  1.0314e-01,  4.1187e-02],\n",
       "                         [ 4.0668e-01,  1.4175e-01, -9.9149e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.7531e-01,  1.1112e-01,  2.5969e-01],\n",
       "                         [ 3.3609e-02,  4.4629e-01, -1.4472e-01],\n",
       "                         [ 1.9912e-02,  3.3521e-01, -3.0833e-02]],\n",
       "               \n",
       "                        [[ 5.7873e-01,  3.8785e-01, -1.3167e-01],\n",
       "                         [ 4.5392e-01, -2.9415e-01, -2.3837e-01],\n",
       "                         [ 1.7466e-01, -2.6371e-01, -4.7010e-01]],\n",
       "               \n",
       "                        [[ 6.8131e-02,  3.0248e-01,  1.7722e-01],\n",
       "                         [ 3.5105e-01,  1.6343e-01,  5.4907e-01],\n",
       "                         [ 3.6277e-01, -8.0636e-02,  2.7709e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.5644e-01, -3.7770e-01, -4.4822e-01],\n",
       "                         [ 4.6227e-01, -2.5546e-01, -2.5212e-01],\n",
       "                         [ 7.6517e-01,  2.7184e-01, -4.1682e-02]],\n",
       "               \n",
       "                        [[-1.7068e-01,  2.0729e-02, -1.2397e-01],\n",
       "                         [-2.4835e-01, -4.3194e-01, -1.5399e-01],\n",
       "                         [-5.2940e-02,  2.7487e-01, -3.7107e-01]],\n",
       "               \n",
       "                        [[ 1.5742e-01,  5.5573e-01,  2.5187e-02],\n",
       "                         [-3.0237e-01,  4.1298e-01,  7.7266e-02],\n",
       "                         [-3.9530e-01, -2.7978e-01, -9.1191e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.9762e-02,  1.8042e-01, -3.9363e-01],\n",
       "                         [-1.1389e-01,  5.3562e-02, -8.5925e-02],\n",
       "                         [ 3.2643e-01,  2.0999e-01, -3.2451e-01]],\n",
       "               \n",
       "                        [[-1.5259e-01, -4.6726e-02, -3.7368e-02],\n",
       "                         [-6.0230e-01, -4.3001e-01, -4.1538e-01],\n",
       "                         [ 1.5315e-01,  2.1337e-01, -2.8751e-02]],\n",
       "               \n",
       "                        [[ 2.2063e-01,  1.8856e-01, -6.6229e-02],\n",
       "                         [ 6.0206e-02,  2.6171e-01, -1.5934e-02],\n",
       "                         [ 5.4239e-02, -1.2904e-01, -5.3348e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.1277e-01, -6.8714e-02,  4.7774e-02],\n",
       "                         [-1.3994e-01,  1.1240e-01, -3.5280e-02],\n",
       "                         [-1.7965e-01, -6.1642e-02, -1.3224e-01]],\n",
       "               \n",
       "                        [[-1.2082e-01, -2.0590e-01, -1.8080e-01],\n",
       "                         [-1.6017e-01, -4.7813e-03, -9.3882e-02],\n",
       "                         [-2.2095e-01, -3.2664e-01,  1.4929e-01]],\n",
       "               \n",
       "                        [[-1.2257e-01,  1.8162e-01, -2.6050e-01],\n",
       "                         [-2.4270e-01, -2.1884e-01, -8.9875e-03],\n",
       "                         [-7.0932e-01,  4.2061e-02, -3.1313e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3492e-01, -1.5707e-01, -2.3038e-01],\n",
       "                         [ 2.0263e-01, -5.1399e-03, -1.5371e-01],\n",
       "                         [ 1.4894e-01,  1.2968e-01, -6.0286e-02]],\n",
       "               \n",
       "                        [[-3.9678e-01, -5.3239e-02, -1.4896e-01],\n",
       "                         [-2.5842e-01,  1.3163e-01,  6.6864e-02],\n",
       "                         [-2.7437e-01, -3.1992e-02,  1.7977e-01]],\n",
       "               \n",
       "                        [[-3.5988e-02, -5.5333e-02, -2.0786e-01],\n",
       "                         [-1.3925e-01,  3.3345e-01, -7.5424e-02],\n",
       "                         [ 1.4782e-01, -1.6331e-01,  1.7908e-02]]]], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv1.conv.bias',\n",
       "               tensor([ 3.4675e-07, -1.3822e-06,  3.6002e-05, -1.1692e-05,  5.6298e-05,\n",
       "                       -2.7983e-05,  4.3969e-04,  1.6799e-04, -1.4712e-05,  3.7967e-06,\n",
       "                       -1.6700e-05,  1.0681e-05, -1.8326e-05,  2.3052e-07, -6.3094e-02,\n",
       "                       -3.9045e-04, -1.0150e-06,  4.7115e-06,  9.7793e-06,  4.2916e-06,\n",
       "                       -1.4289e-05, -8.9777e-07, -7.7754e-06, -3.0376e-05, -1.6199e-06,\n",
       "                        3.4065e-08, -1.4880e-06, -4.5488e-08, -1.0447e-06, -2.9882e-05,\n",
       "                        8.2704e-06,  5.0056e-07, -6.8222e-06, -1.2699e-02,  8.6387e-08,\n",
       "                        7.1075e-06, -2.1831e-06, -3.8726e-06, -1.2091e-04,  9.3394e-05,\n",
       "                        2.3972e-06, -3.2954e-05, -3.8490e-05,  1.9007e-06,  2.8342e-06,\n",
       "                       -3.2070e-04,  7.4958e-06,  1.9534e-05], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv1.norm_layer.running_mean',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv1.norm_layer.running_var',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv1.norm_layer.bias',\n",
       "               tensor([-0.5073, -0.6803, -0.3216, -0.5089, -0.7080, -0.4846, -0.4969, -0.4622,\n",
       "                       -0.3015, -0.5555, -0.6584, -0.5288, -0.3721, -0.5625, -0.5150, -0.4783,\n",
       "                       -0.2941, -0.6178, -0.3896, -0.6185, -0.6657, -0.3833, -0.3716, -0.3223,\n",
       "                       -0.7735, -0.4618, -0.4702, -0.5204, -0.2095, -0.6722, -0.3779, -0.4234,\n",
       "                       -0.5684, -0.5538, -0.4552, -0.4130, -0.4760, -0.5486, -0.3618, -0.5576,\n",
       "                       -0.0569, -0.6033, -0.6100, -0.3355, -0.4784, -0.5823, -0.3100, -0.4946],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv1.norm_layer.weight',\n",
       "               tensor([0.9755, 0.7380, 0.7584, 0.9859, 0.9811, 1.0459, 1.1149, 0.9857, 0.7088,\n",
       "                       1.0036, 1.2683, 0.9150, 0.6523, 0.9748, 1.1094, 0.7687, 1.2251, 0.8960,\n",
       "                       0.7689, 0.7856, 1.1112, 0.8639, 1.0723, 1.3231, 1.0842, 0.8305, 1.1354,\n",
       "                       0.8854, 0.9567, 1.1720, 0.6357, 0.7800, 0.9924, 0.8931, 1.0498, 1.0436,\n",
       "                       0.7231, 0.9653, 1.1221, 0.8832, 0.9231, 0.9101, 1.3776, 0.9417, 0.8898,\n",
       "                       0.6269, 0.9028, 0.9212], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv2.conv.weight',\n",
       "               tensor([[[[-0.0551,  0.0386, -0.2548],\n",
       "                         [-0.0836,  0.1459, -0.3847],\n",
       "                         [-0.1549,  0.0171,  0.1230]],\n",
       "               \n",
       "                        [[-0.1021,  0.1959, -0.0437],\n",
       "                         [ 0.0747, -0.1348, -0.2001],\n",
       "                         [-0.1679, -0.5819,  0.0532]],\n",
       "               \n",
       "                        [[ 0.0995,  0.1882, -0.0167],\n",
       "                         [ 0.2096,  0.1006, -0.0100],\n",
       "                         [ 0.1125, -0.0997,  0.1279]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.3700, -0.7690, -0.6538],\n",
       "                         [-0.1612, -0.2821, -0.0579],\n",
       "                         [-0.0506, -0.3480, -0.2915]],\n",
       "               \n",
       "                        [[ 0.0827,  0.2635,  0.2415],\n",
       "                         [ 0.0458, -0.2100,  0.1349],\n",
       "                         [-0.0598, -0.2657,  0.1379]],\n",
       "               \n",
       "                        [[ 0.4273,  0.0273, -0.0490],\n",
       "                         [ 0.1972, -0.1230, -0.0062],\n",
       "                         [ 0.2973,  0.2393,  0.5921]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2870,  0.2035, -0.1604],\n",
       "                         [-0.0384, -0.2472, -0.0143],\n",
       "                         [-0.1714, -0.5509, -0.1046]],\n",
       "               \n",
       "                        [[-0.2980, -0.1562,  0.1516],\n",
       "                         [ 0.0349, -0.0638,  0.1129],\n",
       "                         [ 0.0273, -0.0478, -0.0555]],\n",
       "               \n",
       "                        [[-0.3174, -0.2526, -0.2561],\n",
       "                         [-0.0692,  0.3524, -0.1677],\n",
       "                         [ 0.0941,  0.2443,  0.1078]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1601, -0.0299, -0.0410],\n",
       "                         [-0.1526, -0.2685,  0.3021],\n",
       "                         [-0.3314, -0.0891, -0.0585]],\n",
       "               \n",
       "                        [[-0.7138,  0.0470, -0.0622],\n",
       "                         [-0.4234,  0.1162,  0.2022],\n",
       "                         [ 0.0897,  0.2663,  0.0168]],\n",
       "               \n",
       "                        [[ 0.0965, -0.4280, -0.3450],\n",
       "                         [ 0.2361,  0.0708,  0.2990],\n",
       "                         [-0.1464, -0.1316, -0.2739]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1009, -0.1944,  0.0183],\n",
       "                         [ 0.2331, -0.1083, -0.1692],\n",
       "                         [-0.2568, -0.1608, -0.2752]],\n",
       "               \n",
       "                        [[ 0.1822,  0.2075,  0.1133],\n",
       "                         [ 0.0738, -0.0447, -0.4281],\n",
       "                         [-0.0140,  0.1066,  0.0137]],\n",
       "               \n",
       "                        [[-0.0526, -0.3042, -0.1734],\n",
       "                         [-0.1675, -0.1860,  0.2161],\n",
       "                         [ 0.2241,  0.0564,  0.5510]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0011, -0.4297, -0.2971],\n",
       "                         [ 0.3855, -0.2051, -0.3019],\n",
       "                         [ 0.0034, -0.1980, -0.3490]],\n",
       "               \n",
       "                        [[ 0.5324,  0.2993,  0.3033],\n",
       "                         [-0.0986,  0.1608,  0.1256],\n",
       "                         [-0.1107, -0.2541, -0.4343]],\n",
       "               \n",
       "                        [[ 0.0366,  0.1533, -0.2988],\n",
       "                         [ 0.1007, -0.0845, -0.2157],\n",
       "                         [-0.0098,  0.0398, -0.1780]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.2956, -0.2389, -0.3466],\n",
       "                         [ 0.0589,  0.1177,  0.0698],\n",
       "                         [ 0.0139, -0.1299, -0.1228]],\n",
       "               \n",
       "                        [[-0.0276,  0.1440, -0.4216],\n",
       "                         [ 0.0282, -0.2313, -0.4467],\n",
       "                         [-0.1419, -0.1280,  0.4738]],\n",
       "               \n",
       "                        [[ 0.0739, -0.2851, -0.4027],\n",
       "                         [ 0.0277, -0.0399, -0.3409],\n",
       "                         [-0.1397, -0.0254, -0.3392]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0610,  0.3317, -0.2912],\n",
       "                         [-0.0746, -0.2666, -0.0813],\n",
       "                         [ 0.2096, -0.0097, -0.3440]],\n",
       "               \n",
       "                        [[ 0.2202,  0.4956,  0.0582],\n",
       "                         [-0.0024,  0.3627, -0.0543],\n",
       "                         [-0.0682,  0.2893, -0.0248]],\n",
       "               \n",
       "                        [[-0.0135, -0.3340, -0.2262],\n",
       "                         [ 0.2038, -0.1177,  0.0312],\n",
       "                         [ 0.0852,  0.3841, -0.0802]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2081,  0.2873, -0.0601],\n",
       "                         [-0.1575, -0.1335,  0.0296],\n",
       "                         [ 0.2671,  0.2290, -0.4022]],\n",
       "               \n",
       "                        [[-0.0090, -0.2006, -0.3800],\n",
       "                         [-0.2363, -0.0966, -0.2390],\n",
       "                         [-0.2024, -0.3317, -0.0149]],\n",
       "               \n",
       "                        [[ 0.0867, -0.0202, -0.0143],\n",
       "                         [ 0.2898,  0.1937,  0.1191],\n",
       "                         [ 0.2533, -0.0765, -0.3535]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.2507, -0.2394, -0.0038],\n",
       "                         [-0.0118, -0.0126, -0.1463],\n",
       "                         [ 0.1954, -0.1247,  0.1838]],\n",
       "               \n",
       "                        [[-0.0472, -0.1389, -0.0031],\n",
       "                         [-0.0042, -0.0094, -0.2507],\n",
       "                         [ 0.1166,  0.0937,  0.3499]],\n",
       "               \n",
       "                        [[-0.4724, -0.0689,  0.0020],\n",
       "                         [-0.5414, -0.1167, -0.0732],\n",
       "                         [ 0.2248, -0.0482,  0.3121]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0054,  0.1255, -0.0034],\n",
       "                         [ 0.0862, -0.2127, -0.2793],\n",
       "                         [-0.2717, -0.1859,  0.0695]],\n",
       "               \n",
       "                        [[-0.3568, -0.3591, -0.2921],\n",
       "                         [-0.1340, -0.1198, -0.0012],\n",
       "                         [-0.0049, -0.1523,  0.2611]],\n",
       "               \n",
       "                        [[-0.0319, -0.3560, -0.4190],\n",
       "                         [ 0.0418,  0.1293, -0.0649],\n",
       "                         [ 0.3580,  0.1353,  0.1102]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1890, -0.0299, -0.0055],\n",
       "                         [-0.2736,  0.1236, -0.0349],\n",
       "                         [-0.0298,  0.0247,  0.0491]],\n",
       "               \n",
       "                        [[-0.2591, -0.0104,  0.3085],\n",
       "                         [-0.3485,  0.0615, -0.2684],\n",
       "                         [-0.0247, -0.1887, -0.0024]],\n",
       "               \n",
       "                        [[-0.0888, -0.3364, -0.0901],\n",
       "                         [ 0.2140, -0.7166, -0.1792],\n",
       "                         [-0.1012, -0.0672, -0.0027]]]], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv2.conv.bias',\n",
       "               tensor([-2.3633e-06,  1.0469e-06,  7.8472e-02,  2.4988e-04, -5.1936e-05,\n",
       "                        1.3128e-04,  5.1106e-06,  2.4732e-06,  7.7365e-05,  3.2479e-04,\n",
       "                       -3.5754e-05,  7.4134e-05,  6.4770e-06,  2.5295e-07, -8.7708e-04,\n",
       "                       -1.8077e-06,  2.8812e-06, -7.9885e-06, -2.8181e-05,  1.3798e-05,\n",
       "                       -2.5233e-05,  4.6732e-06,  7.9271e-06, -1.2385e-05,  3.0971e-05,\n",
       "                       -6.7944e-06,  3.6456e-05,  6.6352e-04,  9.7610e-06,  5.5136e-05,\n",
       "                        1.1681e-06, -3.7099e-05,  1.4990e-06,  2.4114e-05, -3.4525e-06,\n",
       "                       -8.9465e-06,  5.5668e-04,  6.1941e-05,  6.6495e-06,  2.6177e-06,\n",
       "                       -4.6854e-04,  2.0417e-05,  7.2599e-05,  9.6248e-05,  2.3471e-06,\n",
       "                        1.7190e-06,  1.4704e-06, -1.1330e-04], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv2.norm_layer.running_mean',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv2.norm_layer.running_var',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv2.norm_layer.bias',\n",
       "               tensor([-0.7243, -0.7349, -0.6957, -0.9244, -0.5872, -0.6202, -1.5405, -0.5988,\n",
       "                       -0.8811, -0.3065, -0.7493, -0.2038, -0.4154, -0.6770, -0.7211, -0.3975,\n",
       "                       -0.5538, -0.3849, -0.7044, -0.8573, -0.7443, -0.8489, -0.8606, -0.6636,\n",
       "                       -1.1020, -0.7373, -0.6095, -0.7444, -0.7555, -1.2167, -0.9588, -0.6580,\n",
       "                       -0.7397, -0.7734, -0.4599, -1.1118, -0.8484, -0.7505, -0.4869, -0.3458,\n",
       "                       -0.8483, -0.5976, -1.2578, -0.5037, -1.6591, -0.4866, -0.7794, -1.0678],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv2.norm_layer.weight',\n",
       "               tensor([0.9002, 0.8365, 0.7665, 0.9873, 0.8324, 0.7809, 1.3866, 0.6501, 0.7894,\n",
       "                       0.5731, 0.7609, 0.4583, 0.7319, 0.5952, 0.9627, 0.4154, 0.6756, 0.4618,\n",
       "                       0.8304, 0.9394, 0.8271, 0.9145, 0.8206, 0.8766, 1.0868, 0.6922, 0.7333,\n",
       "                       0.8003, 0.7533, 1.0916, 0.8175, 1.0859, 0.8594, 0.7810, 0.7084, 0.9367,\n",
       "                       1.1040, 0.9170, 0.5442, 0.4612, 0.9007, 0.7373, 1.3747, 0.5808, 1.0918,\n",
       "                       0.6811, 0.7711, 1.1068], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv3.conv.weight',\n",
       "               tensor([[[[-2.8310e-01, -2.0914e-01, -6.5285e-02],\n",
       "                         [ 3.4184e-02, -2.1975e-02,  2.8535e-02],\n",
       "                         [-6.8668e-02,  1.8950e-01, -4.4843e-01]],\n",
       "               \n",
       "                        [[ 4.0438e-01,  1.6353e-01,  1.8204e-01],\n",
       "                         [ 2.6569e-01,  6.7784e-02,  3.4256e-03],\n",
       "                         [ 6.0006e-01,  5.3307e-01,  1.2031e-01]],\n",
       "               \n",
       "                        [[ 1.3756e-01,  1.7761e-01,  3.6982e-01],\n",
       "                         [ 9.2377e-02, -8.1022e-02, -2.1848e-01],\n",
       "                         [ 1.3620e-01,  1.0908e-01,  8.1515e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.6709e-01,  3.3983e-01,  5.7269e-01],\n",
       "                         [ 3.1856e-01,  1.3676e-01, -1.8426e-02],\n",
       "                         [ 1.5065e-01,  7.7990e-02, -1.9569e-02]],\n",
       "               \n",
       "                        [[-1.2466e-01,  9.7893e-03, -2.6080e-02],\n",
       "                         [ 2.4879e-01,  6.8848e-03, -4.4428e-02],\n",
       "                         [-9.6185e-02,  4.5038e-01,  1.4433e-01]],\n",
       "               \n",
       "                        [[-2.3295e-01, -2.4837e-01, -3.4987e-01],\n",
       "                         [-1.5908e-01, -2.6149e-01, -2.2362e-01],\n",
       "                         [-9.7676e-02, -2.1808e-01, -3.8856e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 9.4815e-02,  3.5949e-01,  3.5619e-01],\n",
       "                         [ 2.1663e-02,  4.6284e-02,  7.6257e-02],\n",
       "                         [-1.4976e-01, -6.8081e-02, -1.2647e-01]],\n",
       "               \n",
       "                        [[-4.7403e-02, -4.2210e-01,  2.9898e-02],\n",
       "                         [ 4.2945e-02, -2.1895e-01, -2.3066e-01],\n",
       "                         [-1.8456e-01,  1.9031e-01, -8.5742e-02]],\n",
       "               \n",
       "                        [[-1.5009e-02, -1.1156e-01,  2.5760e-01],\n",
       "                         [ 1.7109e-02, -1.2930e-02, -4.5699e-02],\n",
       "                         [-3.5880e-01, -4.2921e-02, -3.3210e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.8035e-02, -7.0373e-02, -2.3561e-01],\n",
       "                         [-5.2749e-01,  2.8336e-03, -1.5097e-01],\n",
       "                         [-1.6993e-01, -3.0056e-01, -3.1711e-01]],\n",
       "               \n",
       "                        [[ 7.8038e-02, -5.9466e-01,  8.4680e-02],\n",
       "                         [-1.5156e-01, -1.7239e-03, -1.9964e-01],\n",
       "                         [-1.7114e-01,  1.0609e-01,  1.4588e-01]],\n",
       "               \n",
       "                        [[ 1.0817e-01,  2.0990e-01,  1.1826e-01],\n",
       "                         [ 2.0106e-01,  5.5757e-02,  1.4667e-01],\n",
       "                         [ 2.2534e-01,  1.2010e-02, -3.8204e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.2592e-01,  6.3338e-01, -4.2481e-02],\n",
       "                         [-2.0465e-01,  7.1708e-01,  4.2461e-01],\n",
       "                         [-4.0162e-02,  9.3341e-02,  1.4045e-01]],\n",
       "               \n",
       "                        [[-1.7965e-01, -6.8501e-02, -2.1684e-01],\n",
       "                         [-6.3048e-01, -5.1482e-01, -3.9200e-02],\n",
       "                         [-5.3577e-01, -5.9225e-01, -3.0859e-01]],\n",
       "               \n",
       "                        [[ 1.0686e-01,  2.7417e-01,  6.5716e-02],\n",
       "                         [ 7.5422e-02,  1.9976e-01,  1.3875e-02],\n",
       "                         [-2.0662e-01, -1.0873e-01,  6.3057e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-7.2341e-01, -3.8039e-01, -2.6171e-01],\n",
       "                         [-3.7921e-01, -3.7799e-01, -5.4610e-01],\n",
       "                         [-4.8741e-01, -4.4255e-01, -3.0622e-01]],\n",
       "               \n",
       "                        [[ 1.1612e-01, -4.9641e-01, -1.2872e-01],\n",
       "                         [-9.2748e-02,  1.4422e-01, -1.2655e-01],\n",
       "                         [ 9.3112e-02, -9.5108e-02, -3.6291e-01]],\n",
       "               \n",
       "                        [[ 1.9802e-01,  3.5046e-02,  5.7140e-02],\n",
       "                         [-4.4809e-01,  9.2866e-02,  1.8988e-02],\n",
       "                         [-2.9893e-01, -1.0889e-02, -5.3089e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-7.8406e-02,  4.9826e-02,  7.0721e-02],\n",
       "                         [-5.7641e-02, -4.9315e-02, -4.9498e-03],\n",
       "                         [-5.3969e-02,  7.9533e-02, -8.5407e-02]],\n",
       "               \n",
       "                        [[-3.2632e-01,  1.5888e-01,  1.1490e-01],\n",
       "                         [-6.9644e-02,  5.1899e-03,  1.1905e-01],\n",
       "                         [-4.7614e-02, -1.4216e-01, -9.1484e-02]],\n",
       "               \n",
       "                        [[-2.6486e-02, -3.0101e-01, -7.8414e-02],\n",
       "                         [ 7.3886e-02,  1.1270e-01, -6.5406e-02],\n",
       "                         [ 2.5990e-02, -7.8440e-02,  1.5450e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.6765e-01,  2.5716e-01, -2.6811e-02],\n",
       "                         [ 1.8537e-01,  1.0663e-01, -8.4637e-02],\n",
       "                         [-9.6355e-02,  1.1779e-02, -1.6459e-01]],\n",
       "               \n",
       "                        [[-9.3641e-03, -9.5721e-03, -2.3495e-01],\n",
       "                         [-6.4733e-02, -4.4944e-01, -3.6356e-01],\n",
       "                         [ 1.4458e-01, -1.1898e-01,  1.4731e-01]],\n",
       "               \n",
       "                        [[ 1.3736e-01,  8.4425e-02,  2.2426e-01],\n",
       "                         [-2.0682e-01, -6.5508e-02,  2.5239e-02],\n",
       "                         [-1.4133e-01,  6.8302e-02, -1.1116e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.7145e-03,  7.3694e-03,  7.0604e-02],\n",
       "                         [ 2.3968e-02,  9.1227e-02, -2.2583e-02],\n",
       "                         [ 5.6406e-02,  5.1781e-02, -9.5081e-02]],\n",
       "               \n",
       "                        [[-1.3195e-02, -5.3338e-02, -4.3132e-03],\n",
       "                         [ 1.3948e-01, -6.9245e-02, -2.2298e-03],\n",
       "                         [ 2.2535e-01,  8.9276e-02, -5.9099e-02]],\n",
       "               \n",
       "                        [[-7.3223e-02,  8.4277e-02, -7.8187e-03],\n",
       "                         [ 4.1766e-02,  1.1646e-02,  6.7504e-02],\n",
       "                         [-4.5926e-02, -1.7276e-02, -4.1100e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.2332e-01,  1.2797e-01,  1.3707e-01],\n",
       "                         [ 6.3272e-03,  5.0328e-02,  3.7540e-02],\n",
       "                         [-3.8476e-02,  8.7270e-02,  3.2585e-02]],\n",
       "               \n",
       "                        [[-6.6257e-02, -1.6422e-02,  6.5831e-02],\n",
       "                         [ 3.7520e-03,  1.4050e-02,  2.7304e-02],\n",
       "                         [ 2.2253e-03,  1.0966e-01, -6.3325e-03]],\n",
       "               \n",
       "                        [[ 2.0294e-02,  9.6318e-02, -1.2270e-01],\n",
       "                         [ 1.1732e-02,  4.9912e-02, -3.3140e-02],\n",
       "                         [-3.6757e-02, -4.8870e-03, -1.2425e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.1599e-02, -4.2979e-02,  1.0060e-03],\n",
       "                         [ 5.9407e-02,  1.8185e-02,  2.2814e-04],\n",
       "                         [ 9.5778e-02, -2.0595e-02, -3.9948e-02]],\n",
       "               \n",
       "                        [[-5.0383e-02, -6.7711e-02, -4.0695e-03],\n",
       "                         [ 1.0549e-01, -2.0189e-02, -5.2930e-02],\n",
       "                         [ 1.9371e-01,  1.2850e-01, -3.5729e-02]],\n",
       "               \n",
       "                        [[-1.0376e-01,  1.6325e-01,  6.6750e-03],\n",
       "                         [ 5.5700e-02,  2.9303e-03,  8.7001e-02],\n",
       "                         [-6.1027e-02,  3.2602e-02,  1.3172e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.4478e-02,  5.3473e-02,  9.1972e-02],\n",
       "                         [-1.0676e-02,  5.8015e-02,  1.2178e-01],\n",
       "                         [-2.8701e-02,  6.7987e-02,  1.1676e-01]],\n",
       "               \n",
       "                        [[-2.0196e-02,  1.6919e-02,  4.3047e-02],\n",
       "                         [-3.7918e-02, -1.2018e-02,  3.2968e-02],\n",
       "                         [ 4.1434e-02,  1.0655e-01, -2.7636e-02]],\n",
       "               \n",
       "                        [[ 6.2689e-02,  1.0456e-01,  2.7545e-03],\n",
       "                         [ 3.6871e-02,  7.5025e-02,  6.4456e-02],\n",
       "                         [-1.0447e-02, -1.4049e-02, -8.7212e-02]]]], device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv3.conv.bias',\n",
       "               tensor([ 0.2010,  0.2236,  0.0486,  0.2353,  0.0010,  0.0091,  0.1996, -0.0036,\n",
       "                        0.1802,  0.1719,  0.1533,  0.1640,  0.0031,  0.0027,  0.0048,  0.1159,\n",
       "                        0.1487,  0.2060,  0.0016,  0.1909,  0.1915, -0.0082,  0.0669,  0.2673,\n",
       "                        0.1338,  0.1493,  0.0645,  0.1237, -0.0065, -0.0085,  0.1718,  0.2095,\n",
       "                       -0.0068, -0.0045, -0.0039, -0.0078,  0.0311,  0.0232,  0.1952, -0.0109,\n",
       "                        0.1167,  0.0860,  0.1613,  0.0374, -0.0316,  0.0182,  0.1428,  0.1329],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv3.norm_layer.running_mean',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv3.norm_layer.running_var',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv3.norm_layer.bias',\n",
       "               tensor([-0.4066, -0.4206, -0.3590, -0.6283, -0.7477, -0.6760, -0.5424, -0.4238,\n",
       "                       -0.5798, -0.4787, -0.4408, -0.4739, -0.5400, -0.5663, -0.3085, -0.4903,\n",
       "                       -0.8057, -0.4369, -0.6719, -0.4819, -0.2953, -0.7309, -0.1803, -0.7399,\n",
       "                       -0.6059, -0.6555, -0.5482, -0.2849, -0.8180, -0.6749, -0.6550, -0.6527,\n",
       "                       -0.2826, -0.5522, -0.1158, -0.5288, -0.8311, -0.1753, -0.5979, -0.5782,\n",
       "                       -0.5606, -0.5134, -0.3055, -0.2297, -0.7966, -0.2473, -0.5253, -0.5131],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.conv3.norm_layer.weight',\n",
       "               tensor([0.4355, 0.5044, 0.2624, 0.4089, 0.2649, 0.3203, 0.5236, 0.1470, 0.5827,\n",
       "                       0.4505, 0.4273, 0.4006, 0.2180, 0.1924, 0.1078, 0.3850, 0.6482, 0.4722,\n",
       "                       0.2644, 0.5090, 0.3512, 0.2718, 0.1048, 0.5889, 0.3515, 0.3442, 0.2368,\n",
       "                       0.3057, 0.2594, 0.2971, 0.5312, 0.5481, 0.0856, 0.1698, 0.0461, 0.2474,\n",
       "                       0.5142, 0.0805, 0.4602, 0.2276, 0.5240, 0.3991, 0.3274, 0.1164, 0.3288,\n",
       "                       0.0700, 0.4186, 0.4076], device='cuda:0')),\n",
       "              ('classifier.layer_dict.linear.weights',\n",
       "               tensor([[ 0.0047, -0.0215, -0.0624,  ..., -0.2331, -0.1596, -0.1752],\n",
       "                       [-0.0128, -0.0402, -0.0117,  ..., -0.2256, -0.1424, -0.1187],\n",
       "                       [-0.0512, -0.0676, -0.0439,  ..., -0.1770, -0.1248, -0.1140],\n",
       "                       [ 0.1212,  0.1377,  0.0317,  ..., -0.2126, -0.1075, -0.1941],\n",
       "                       [ 0.0609,  0.1498,  0.0380,  ...,  0.4780,  0.3586,  0.4213]],\n",
       "                      device='cuda:0')),\n",
       "              ('classifier.layer_dict.linear.bias',\n",
       "               tensor([-0.0251, -0.0171, -0.0427, -0.0276, -0.0232], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv0-conv-weight',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv0-conv-bias',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv1-conv-weight',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv1-conv-bias',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv2-conv-weight',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv2-conv-bias',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv3-conv-weight',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-conv3-conv-bias',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-linear-weights',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('inner_loop_optimizer.names_learning_rates_dict.layer_dict-linear-bias',\n",
       "               tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0')),\n",
       "              ('arbiter.0.weight',\n",
       "               tensor([[-2.2247e-01, -1.5931e-01,  9.6521e-02,  1.1918e-01, -7.0226e-02,\n",
       "                        -1.1884e-01, -7.2531e-02,  2.5318e-01, -2.2093e-01, -4.7102e-02,\n",
       "                         1.7146e-01,  8.8539e-02,  3.5216e-02,  9.6989e-03,  4.9386e-02,\n",
       "                         4.2055e-02, -1.7720e-01,  1.4861e-01,  1.3337e-01, -1.0836e-01],\n",
       "                       [ 1.1339e+00, -1.3940e+00,  6.2818e-01, -6.6696e-01,  9.5432e-01,\n",
       "                        -6.7190e-01,  1.0401e+00, -7.8026e-01,  5.8989e-01, -6.8534e-01,\n",
       "                        -1.2912e+00, -7.0929e-01, -5.5973e-01, -5.9905e-01, -7.1229e-01,\n",
       "                        -8.5548e-01, -3.7023e-01, -5.2063e-01,  4.0425e-01, -8.8635e-01],\n",
       "                       [-1.7650e-01, -7.4263e-02, -1.9603e-01,  1.7395e-01, -1.2017e-01,\n",
       "                         1.5592e-01, -2.8765e-03,  7.1014e-02,  7.4614e-02,  1.7035e-01,\n",
       "                        -1.8075e-01, -3.1389e-03, -6.3424e-02,  4.2344e-02, -8.9193e-02,\n",
       "                         1.8377e-01, -5.3476e-02,  1.4562e-01, -1.4323e-01, -1.9829e-01],\n",
       "                       [ 6.8407e-01, -8.2890e-01,  6.8174e-01, -7.5535e-01,  8.4494e-01,\n",
       "                        -7.3308e-01,  9.2288e-01, -6.0184e-01,  4.0720e-01, -6.2824e-01,\n",
       "                        -8.6108e-01, -7.1613e-01, -4.6364e-01, -8.8631e-01, -6.2843e-01,\n",
       "                        -5.6570e-01, -5.5475e-01, -8.5190e-01, -1.6904e-01, -5.8001e-01],\n",
       "                       [ 6.1037e-01, -1.6474e+00,  9.8530e-01, -6.7701e-01,  6.2578e-01,\n",
       "                        -7.1100e-01,  9.6076e-01, -1.3746e+00,  2.6624e-01, -8.7000e-01,\n",
       "                         1.8483e-01, -8.4143e-01, -6.7921e-01, -8.0056e-01, -6.3000e-01,\n",
       "                        -5.7448e-01, -3.4261e-01, -8.1264e-01,  3.0343e-01, -6.4937e-01],\n",
       "                       [-1.3744e-01,  8.8859e-02, -1.4254e-01, -2.0478e-02,  9.0880e-03,\n",
       "                         1.4116e-01,  1.2301e-02, -6.6963e-02, -1.7384e-01,  1.4978e-01,\n",
       "                         1.8470e-01, -1.6821e-01, -6.7825e-02, -9.9556e-02, -1.1804e-01,\n",
       "                         1.8543e-01,  5.4935e-02, -1.3889e-01, -8.5513e-02, -7.6293e-02],\n",
       "                       [-3.1918e-03,  1.6702e-01, -2.5259e-02, -5.8045e-02, -1.9568e-01,\n",
       "                        -1.8738e-01, -1.0919e-01, -2.0999e-01, -1.4216e-01,  3.0850e-02,\n",
       "                        -1.5226e-01,  1.8288e-01,  1.7433e-01, -8.3347e-02, -3.3173e-03,\n",
       "                         2.0585e-01,  3.2247e-02, -1.9702e-02, -1.5549e-01, -3.7919e-02],\n",
       "                       [-5.2119e-02,  5.8366e-02, -9.5376e-02,  4.1151e-02, -1.4242e-02,\n",
       "                        -1.3989e-01, -2.9618e-02, -4.6825e-02,  1.5251e-02, -5.1655e-03,\n",
       "                        -1.6485e-01,  1.5387e-01,  1.4536e-01,  3.0741e-02, -1.5371e-01,\n",
       "                         2.2002e-02, -5.1757e-02, -5.1059e-02, -1.4909e-02,  2.1917e-01],\n",
       "                       [ 8.6941e-01, -6.9592e-01,  8.4204e-01, -5.3590e-01,  9.1796e-01,\n",
       "                        -7.4439e-01,  8.4390e-01, -8.8405e-01,  7.3470e-01, -5.9659e-01,\n",
       "                        -9.6316e-01, -8.0717e-01, -4.9581e-01, -4.9376e-01, -8.4781e-01,\n",
       "                        -7.7259e-01, -5.9439e-01, -5.1684e-01, -1.1509e-01, -5.7943e-01],\n",
       "                       [ 9.6380e-01, -1.0576e+00,  7.2722e-01, -5.1482e-01,  8.9669e-01,\n",
       "                        -6.0853e-01,  7.4861e-01, -9.0947e-01,  6.6959e-01, -6.9792e-01,\n",
       "                        -9.8941e-01, -7.3063e-01, -1.0287e+00, -8.4421e-01, -8.5455e-01,\n",
       "                        -8.7129e-01, -6.4758e-01, -7.1543e-01,  1.1148e-01, -6.0509e-01],\n",
       "                       [ 9.4558e-01, -9.7096e-01,  6.5784e-01, -7.6383e-01,  7.3809e-01,\n",
       "                        -5.9879e-01,  9.0801e-01, -5.3441e-01,  1.3402e+00, -4.8692e-01,\n",
       "                        -1.7795e+00, -4.4081e-01, -1.0958e+00, -3.7528e-01, -1.1250e+00,\n",
       "                        -4.9806e-01, -9.2816e-01, -4.2413e-01,  2.9029e-01, -7.8440e-01],\n",
       "                       [-1.6299e-01,  1.9557e-01, -1.6206e-01,  2.2474e-01,  3.2993e-02,\n",
       "                         2.3002e-02,  9.7205e-02, -1.7096e-01,  1.7325e-01, -1.4765e-01,\n",
       "                        -7.1639e-02, -7.4825e-02,  4.6794e-02,  1.8881e-01, -1.0527e-01,\n",
       "                         9.9648e-02,  4.8222e-02, -1.8196e-02, -3.7068e-02,  2.4631e-01],\n",
       "                       [ 1.2785e-03,  7.8483e-02, -1.6075e-01,  3.5523e-03, -5.6337e-02,\n",
       "                         1.3809e-01, -1.3024e-01,  3.6182e-02,  1.8668e-01, -1.7668e-01,\n",
       "                        -1.1430e-01, -1.3822e-01,  1.0208e-01,  1.4600e-01, -1.7406e-01,\n",
       "                        -1.6048e-01,  1.0708e-01,  6.5007e-03,  3.6957e-02, -1.8922e-01],\n",
       "                       [ 5.0203e-02, -3.2657e-03, -1.4001e-01, -5.2389e-02,  8.2383e-02,\n",
       "                         1.4948e-02, -1.9413e-01,  2.1511e-01, -2.2565e-01, -2.6085e-02,\n",
       "                        -1.4133e-01,  6.7594e-02,  1.2138e-01, -1.7762e-01, -2.2753e-01,\n",
       "                        -2.7562e-02,  5.4655e-02, -2.3453e-02,  1.2776e-01, -1.9326e-01],\n",
       "                       [ 2.1353e-01,  2.0006e-01, -1.8942e-01,  7.9496e-02,  4.1478e-02,\n",
       "                        -1.1179e-01,  5.3119e-02,  1.8549e-01, -3.3323e-03, -1.2598e-01,\n",
       "                         2.5711e-02, -2.9604e-03, -2.0496e-02,  1.7962e-01, -1.9416e-02,\n",
       "                        -4.8471e-02, -7.4401e-02,  2.2016e-01, -8.8840e-03, -1.8109e-01],\n",
       "                       [ 6.9884e-01, -1.9052e+00,  8.9536e-01, -8.5159e-01,  8.8327e-01,\n",
       "                        -5.6440e-01,  6.9266e-01, -1.2121e+00,  3.1834e-02, -9.6104e-01,\n",
       "                        -2.1650e-01, -7.3143e-01, -6.7014e-01, -9.5005e-01, -6.9524e-01,\n",
       "                        -6.0115e-01, -2.8879e-01, -9.6045e-01,  3.7924e-02, -7.1621e-01],\n",
       "                       [ 8.7824e-01, -8.6416e-01,  6.7471e-01, -6.9491e-01,  7.6214e-01,\n",
       "                        -8.0100e-01,  5.8003e-01, -1.0440e+00,  5.8952e-01, -5.3776e-01,\n",
       "                        -1.6916e-01, -7.3688e-01, -6.3667e-01, -8.5702e-01, -4.9527e-01,\n",
       "                        -7.1978e-01, -5.0668e-01, -6.7977e-01, -2.2152e-02, -4.3600e-01],\n",
       "                       [ 1.5881e-01,  1.8694e-01, -9.5665e-02, -1.6845e-01,  7.3781e-02,\n",
       "                         1.4416e-01, -1.7335e-01, -1.3803e-01,  1.9204e-01, -1.5731e-01,\n",
       "                        -4.9296e-02,  2.4749e-02,  1.6346e-02,  1.5047e-01,  8.7614e-02,\n",
       "                        -4.4198e-02,  3.5807e-02, -1.8876e-01,  6.7670e-02,  1.8616e-01],\n",
       "                       [ 8.4664e-01, -1.2164e+00,  6.2694e-01, -6.7528e-01,  8.9729e-01,\n",
       "                        -7.6841e-01,  7.6079e-01, -1.1419e+00,  2.6913e-01, -7.6785e-01,\n",
       "                         7.7611e-02, -4.7037e-01, -5.2229e-01, -5.5774e-01, -5.6529e-01,\n",
       "                        -5.2306e-01, -4.3142e-01, -7.8037e-01,  1.5382e-01, -6.6937e-01],\n",
       "                       [ 9.0034e-02, -1.4732e-01,  1.2791e-01,  1.8062e-01, -2.2643e-01,\n",
       "                        -1.6065e-01,  4.1732e-02, -1.9450e-01, -1.8327e-01,  1.2446e-01,\n",
       "                        -1.2507e-01, -1.0608e-01, -5.7903e-02,  8.1527e-02,  1.6932e-01,\n",
       "                         2.4688e-02,  1.3024e-01,  1.7540e-01,  7.2658e-02,  2.2244e-01]],\n",
       "                      device='cuda:0')),\n",
       "              ('arbiter.0.bias',\n",
       "               tensor([ 0.0201,  0.9119,  0.0644,  0.7064,  0.8057, -0.0581,  0.0711, -0.2082,\n",
       "                        0.8379,  0.7319,  0.8915, -0.1592,  0.0547, -0.0025, -0.0097,  0.6112,\n",
       "                        0.8677, -0.1443,  0.7415,  0.0019], device='cuda:0')),\n",
       "              ('arbiter.2.weight',\n",
       "               tensor([[-1.6730e-01, -1.1959e-01, -1.9416e-01,  7.7802e-02,  1.2669e-01,\n",
       "                         1.5178e-01,  3.6239e-02,  2.3965e-02,  1.5949e-02, -1.0364e-02,\n",
       "                        -4.2260e-01, -2.8065e-02, -4.9352e-02, -1.2828e-01, -1.1449e-01,\n",
       "                         4.1683e-02,  1.4762e-01, -1.8167e-02,  1.8168e-01, -1.9080e-01],\n",
       "                       [ 1.0153e-01,  2.1473e+00,  2.0148e-02,  1.8247e+00,  2.1405e+00,\n",
       "                         1.4975e-01,  1.4924e-01,  1.6985e-02,  2.0014e+00,  1.8177e+00,\n",
       "                         2.2863e+00, -9.3935e-02,  1.9514e-01, -1.6500e-01,  1.4378e-01,\n",
       "                         2.1581e+00,  2.2681e+00,  1.1773e-01,  2.0554e+00,  1.6454e-01],\n",
       "                       [ 7.5235e-03, -2.5820e-01, -2.0589e-01, -1.1547e-01, -3.5018e-01,\n",
       "                         2.1607e-01,  1.5543e-01, -1.1048e-01,  1.7357e-02, -1.8394e-03,\n",
       "                        -4.0284e-01,  5.9812e-03, -7.0057e-02, -1.9036e-01,  3.9366e-03,\n",
       "                        -2.6834e-01, -1.7219e-01, -2.9052e-02, -1.1525e-01, -1.1373e-01],\n",
       "                       [ 6.7662e-02, -2.4105e-01,  1.6478e-01, -6.3654e-02, -2.1666e-01,\n",
       "                        -2.4171e-01,  6.4815e-02, -1.5311e-01,  1.6604e-02, -3.1266e-02,\n",
       "                        -1.3559e-01, -1.6420e-02,  1.8723e-01, -6.1182e-02, -1.8708e-01,\n",
       "                        -7.4751e-02, -2.9204e-01,  6.4915e-02, -1.0951e-01,  9.2902e-02],\n",
       "                       [ 9.9647e-02,  1.7909e-01,  2.1410e-01,  2.1573e-01, -2.7112e-02,\n",
       "                         1.1768e-01,  6.1226e-02, -5.4656e-02,  2.0588e-01,  1.6151e-01,\n",
       "                         3.0651e-01,  1.2463e-01, -4.2923e-02,  4.1856e-02,  9.8967e-02,\n",
       "                         2.3818e-03,  1.5596e-01,  8.1670e-02,  2.1747e-02,  2.3783e-02],\n",
       "                       [ 1.2777e-02, -1.0278e-01,  9.4219e-02,  3.3310e-02, -1.2960e-01,\n",
       "                         2.0553e-01,  1.8008e-01, -1.9471e-01,  2.7876e-02, -2.2569e-01,\n",
       "                         2.3035e-01, -1.4089e-01,  1.7361e-01,  1.2626e-01,  2.2125e-01,\n",
       "                         6.3840e-02, -2.5975e-01, -4.3063e-02, -3.2873e-01, -1.7439e-01],\n",
       "                       [-3.4667e-02,  8.3479e-01, -2.1800e-01,  7.7901e-01,  6.7884e-01,\n",
       "                        -1.2479e-01,  7.4694e-02, -2.1838e-01,  8.7846e-01,  9.8893e-01,\n",
       "                         1.0813e+00, -2.2720e-01, -6.6055e-02, -2.0785e-02, -8.1823e-02,\n",
       "                         7.3780e-01,  8.3614e-01, -2.1515e-01,  9.1527e-01, -9.1618e-02],\n",
       "                       [-1.5452e-01,  1.4643e+00, -1.7027e-01,  1.6270e+00,  1.5611e+00,\n",
       "                        -2.1366e-01,  4.6392e-02, -7.1841e-02,  1.5739e+00,  1.6726e+00,\n",
       "                         1.6515e+00,  3.3550e-02,  3.4054e-02, -1.1829e-01, -7.6839e-02,\n",
       "                         1.2949e+00,  1.6491e+00,  1.9570e-01,  1.2938e+00, -2.0401e-01],\n",
       "                       [-1.5696e-01,  1.1218e+00,  6.9845e-02,  1.0845e+00,  1.2435e+00,\n",
       "                        -8.0150e-02, -1.7155e-01, -9.1709e-02,  9.8733e-01,  1.0914e+00,\n",
       "                         7.9755e-01, -4.0581e-02,  2.8706e-02, -1.7417e-01,  2.1412e-01,\n",
       "                         1.3397e+00,  1.1466e+00,  1.6001e-01,  1.3013e+00, -1.4447e-01],\n",
       "                       [-7.8591e-02, -5.9629e-02,  9.2624e-02, -8.9901e-02, -7.2837e-02,\n",
       "                         2.1472e-01,  1.8529e-01,  1.1874e-01, -4.1833e-02, -1.8833e-01,\n",
       "                        -6.6415e-01, -6.1061e-02,  2.0867e-01, -1.1245e-01, -1.3026e-01,\n",
       "                        -3.7516e-01, -1.5701e-01,  2.0398e-01, -2.7524e-01,  2.8911e-02]],\n",
       "                      device='cuda:0')),\n",
       "              ('arbiter.2.bias',\n",
       "               tensor([-0.0093,  2.2027, -0.1076, -0.1869,  0.1249, -0.2151,  0.2933,  1.5668,\n",
       "                        1.1532, -0.2841], device='cuda:0'))]),\n",
       " 'per_epoch_statistics': {'train_loss_mean': [1.3880010995864869,\n",
       "   1.1681266173124314,\n",
       "   1.0543024513721466,\n",
       "   1.0028827078342437,\n",
       "   0.9615960403680801,\n",
       "   0.9269297261238099,\n",
       "   0.9020256378650665,\n",
       "   0.872249094247818,\n",
       "   0.8478070604205131,\n",
       "   0.8314304674863815,\n",
       "   0.7922845501303672,\n",
       "   0.7835283778309822,\n",
       "   0.7652127574682236,\n",
       "   0.7428346804976463,\n",
       "   0.7332226045131683,\n",
       "   0.7308824400901794,\n",
       "   0.705058721601963,\n",
       "   0.6948017406463624,\n",
       "   0.6930058258771896,\n",
       "   0.6839108386039734,\n",
       "   0.680693097770214,\n",
       "   0.6602493169307708,\n",
       "   0.6527665069699288,\n",
       "   0.6603941802978516,\n",
       "   0.6491406707167625,\n",
       "   0.6506650331020355,\n",
       "   0.6211030874848366,\n",
       "   0.631516472697258,\n",
       "   0.6266675333380699,\n",
       "   0.6418148913383483,\n",
       "   0.6225920960903167,\n",
       "   0.6224332730770111,\n",
       "   0.6151731034517288,\n",
       "   0.5966151193976402,\n",
       "   0.6072314867973327,\n",
       "   0.6112588542401791,\n",
       "   0.5932681545615196,\n",
       "   0.588482424557209,\n",
       "   0.5891214713454247,\n",
       "   0.5740478490591049,\n",
       "   0.5895799670219422,\n",
       "   0.5787645511031151,\n",
       "   0.5740910849571228,\n",
       "   0.5875121900439262,\n",
       "   0.5626180595755577,\n",
       "   0.5696809201836586,\n",
       "   0.5647759016156196,\n",
       "   0.5609338417649269,\n",
       "   0.569571004062891,\n",
       "   0.559442238688469,\n",
       "   0.5664950123429299,\n",
       "   0.5425387865006923,\n",
       "   0.5519939655363559,\n",
       "   0.5421509275436401,\n",
       "   0.5614877280592918,\n",
       "   0.550574865013361,\n",
       "   0.5462881864309311,\n",
       "   0.5507248792946339,\n",
       "   0.5487677071094513,\n",
       "   0.5512309635877609,\n",
       "   0.5514772172570228,\n",
       "   0.5507675117850304,\n",
       "   0.5388385071754456,\n",
       "   0.5326644408702851,\n",
       "   0.5503542674779892,\n",
       "   0.5595048902034759,\n",
       "   0.5605040855705739,\n",
       "   0.5318098911345005,\n",
       "   0.5330302594304085,\n",
       "   0.5450326809883118,\n",
       "   0.5329351550042629,\n",
       "   0.5452175827622414,\n",
       "   0.5499126724302769,\n",
       "   0.5484648705124855,\n",
       "   0.5291688284873962,\n",
       "   0.5271694138050079,\n",
       "   0.5388342508673668,\n",
       "   0.5393127513229847,\n",
       "   0.5420061250030994,\n",
       "   0.5373164128363133,\n",
       "   0.5268589859306813,\n",
       "   0.5365027299523354,\n",
       "   0.5262212351560592,\n",
       "   0.5327360532879829,\n",
       "   0.5246948049068451,\n",
       "   0.531257542192936,\n",
       "   0.5197355850934983,\n",
       "   0.5251022400856018,\n",
       "   0.5219416041076184,\n",
       "   0.5181742776036262,\n",
       "   0.520197881191969,\n",
       "   0.5178069486916065,\n",
       "   0.4986466233730316,\n",
       "   0.5120488120913506,\n",
       "   0.5180639134347439,\n",
       "   0.5253360925018787,\n",
       "   0.5145994372069835,\n",
       "   0.5116343019604683,\n",
       "   0.5055164863467216],\n",
       "  'train_loss_std': [0.1718720553380148,\n",
       "   0.13543342014482987,\n",
       "   0.15233810823942176,\n",
       "   0.13925313618004417,\n",
       "   0.13911213106800488,\n",
       "   0.13885642837270176,\n",
       "   0.14440579753894686,\n",
       "   0.1342315987283224,\n",
       "   0.14564704997778782,\n",
       "   0.14082242392747174,\n",
       "   0.13822568008662908,\n",
       "   0.14435348531644207,\n",
       "   0.13171308891804998,\n",
       "   0.14125151223621724,\n",
       "   0.13212036752060216,\n",
       "   0.14017007146898922,\n",
       "   0.1308188378766614,\n",
       "   0.13588048037026065,\n",
       "   0.13902349559961594,\n",
       "   0.1407540970569683,\n",
       "   0.1373276417993746,\n",
       "   0.12415524278795766,\n",
       "   0.1339184239042131,\n",
       "   0.13771383734837706,\n",
       "   0.13035643681054182,\n",
       "   0.14151314597366113,\n",
       "   0.13065243016184436,\n",
       "   0.12869313522516423,\n",
       "   0.12998550101484732,\n",
       "   0.13807770276899353,\n",
       "   0.13168075685302483,\n",
       "   0.13202116127793864,\n",
       "   0.13416423718600223,\n",
       "   0.13453603043511175,\n",
       "   0.13201436556185295,\n",
       "   0.14201132765948005,\n",
       "   0.1261596100997624,\n",
       "   0.1367771301803189,\n",
       "   0.1376009683822406,\n",
       "   0.13796446632692544,\n",
       "   0.1328359633874348,\n",
       "   0.13372205079298455,\n",
       "   0.12972398676590488,\n",
       "   0.13856240163147013,\n",
       "   0.13297252534249657,\n",
       "   0.1400199451309861,\n",
       "   0.13784142286408618,\n",
       "   0.1294204858446371,\n",
       "   0.1357055057001211,\n",
       "   0.13289227407452023,\n",
       "   0.13383902257712776,\n",
       "   0.12533856388999665,\n",
       "   0.13222042406819773,\n",
       "   0.13198655038527093,\n",
       "   0.1353321137332332,\n",
       "   0.1310135787218593,\n",
       "   0.13202928021903101,\n",
       "   0.13532369591149776,\n",
       "   0.12770903065083572,\n",
       "   0.13304869953271548,\n",
       "   0.13163240756649658,\n",
       "   0.1374003643186059,\n",
       "   0.13291842341969776,\n",
       "   0.13085078345380485,\n",
       "   0.13287801800555007,\n",
       "   0.13297659427306505,\n",
       "   0.13399650606488195,\n",
       "   0.14036222894527328,\n",
       "   0.1273058538908108,\n",
       "   0.1369425225172201,\n",
       "   0.12579883064567987,\n",
       "   0.12757776142672758,\n",
       "   0.12763509750743818,\n",
       "   0.13682456694201378,\n",
       "   0.13074319763275172,\n",
       "   0.12862558184315884,\n",
       "   0.13675631764982907,\n",
       "   0.13179777112812996,\n",
       "   0.12743522955126366,\n",
       "   0.133190334132086,\n",
       "   0.12505726341673326,\n",
       "   0.13566212177020245,\n",
       "   0.13614259223117275,\n",
       "   0.12625567748313332,\n",
       "   0.13594198072512936,\n",
       "   0.1259720741810102,\n",
       "   0.12833837227812459,\n",
       "   0.13533703070255057,\n",
       "   0.12535293822315055,\n",
       "   0.13385830637236623,\n",
       "   0.1316696916636857,\n",
       "   0.1353652657511138,\n",
       "   0.12529006849307425,\n",
       "   0.13136219308808625,\n",
       "   0.13185292255685188,\n",
       "   0.13791414438109006,\n",
       "   0.12165253599215675,\n",
       "   0.12873833993298953,\n",
       "   0.12616680230800362],\n",
       "  'train_accuracy_mean': [0.4233066675364971,\n",
       "   0.5390666657090187,\n",
       "   0.59481333142519,\n",
       "   0.6148399997353554,\n",
       "   0.6336266662478447,\n",
       "   0.6479866663217545,\n",
       "   0.659893333017826,\n",
       "   0.6721333324313163,\n",
       "   0.6828533319830894,\n",
       "   0.6881466675400734,\n",
       "   0.7052000002264976,\n",
       "   0.7074266669154167,\n",
       "   0.7155999996066094,\n",
       "   0.7252266653180123,\n",
       "   0.7277200006246567,\n",
       "   0.7313733336925506,\n",
       "   0.7405066672563553,\n",
       "   0.7441199996471405,\n",
       "   0.7469200004339218,\n",
       "   0.7481066665649414,\n",
       "   0.7511333339214324,\n",
       "   0.7609066662788391,\n",
       "   0.7601466664075851,\n",
       "   0.7574666669368744,\n",
       "   0.7627066668272019,\n",
       "   0.7620266656875611,\n",
       "   0.775120000243187,\n",
       "   0.7727733331918717,\n",
       "   0.7716933337450027,\n",
       "   0.7667866671085357,\n",
       "   0.7756533328294754,\n",
       "   0.7737999999523163,\n",
       "   0.7772266652584076,\n",
       "   0.7842000005245209,\n",
       "   0.7803199998140335,\n",
       "   0.7784400005340576,\n",
       "   0.7871199995279312,\n",
       "   0.7897466659545899,\n",
       "   0.7880399997234344,\n",
       "   0.7939333324432373,\n",
       "   0.7867066669464111,\n",
       "   0.791426666021347,\n",
       "   0.7953066686391831,\n",
       "   0.7888533326387406,\n",
       "   0.7986133317947388,\n",
       "   0.795106665968895,\n",
       "   0.7972266665697098,\n",
       "   0.7984666662216187,\n",
       "   0.7960800006389618,\n",
       "   0.7987200003862381,\n",
       "   0.7975200002193451,\n",
       "   0.8062000006437302,\n",
       "   0.8019066665172577,\n",
       "   0.8044266678094864,\n",
       "   0.7996133328676224,\n",
       "   0.8038933326005936,\n",
       "   0.8049999990463257,\n",
       "   0.8013066655397415,\n",
       "   0.8033866665363312,\n",
       "   0.8012399994134903,\n",
       "   0.8026266663074494,\n",
       "   0.8034933333396912,\n",
       "   0.8078533325195313,\n",
       "   0.8083866667747498,\n",
       "   0.8038666669130325,\n",
       "   0.800573331952095,\n",
       "   0.7989600002765656,\n",
       "   0.8101599998474122,\n",
       "   0.8092800005674362,\n",
       "   0.8054799995422364,\n",
       "   0.8114533323049545,\n",
       "   0.80664000082016,\n",
       "   0.8021466664075851,\n",
       "   0.8030266677141189,\n",
       "   0.8117600002288818,\n",
       "   0.8121599991321564,\n",
       "   0.8081066673994064,\n",
       "   0.8081066660881042,\n",
       "   0.8070399987697602,\n",
       "   0.8062800006866455,\n",
       "   0.8129333328008652,\n",
       "   0.8059733326435089,\n",
       "   0.8130933339595795,\n",
       "   0.8083600002527237,\n",
       "   0.8117466689348221,\n",
       "   0.8093733336925507,\n",
       "   0.8143200014829636,\n",
       "   0.813666667342186,\n",
       "   0.811933333516121,\n",
       "   0.81567999958992,\n",
       "   0.8139199993610382,\n",
       "   0.8152666662931443,\n",
       "   0.8225999999046326,\n",
       "   0.8172533321380615,\n",
       "   0.8137999997138977,\n",
       "   0.8116133325099945,\n",
       "   0.8165200002193451,\n",
       "   0.8162133325338363,\n",
       "   0.8200666670799255],\n",
       "  'train_accuracy_std': [0.09250441017521906,\n",
       "   0.06813854998784334,\n",
       "   0.07728869919849311,\n",
       "   0.06829443626941314,\n",
       "   0.06984111023670288,\n",
       "   0.06882467210071173,\n",
       "   0.06691545022536181,\n",
       "   0.06469195523092033,\n",
       "   0.06831196972052894,\n",
       "   0.06719547643557558,\n",
       "   0.064569548494271,\n",
       "   0.066387750168935,\n",
       "   0.06237250086954995,\n",
       "   0.06712818380391292,\n",
       "   0.06020890683181795,\n",
       "   0.06459568654633001,\n",
       "   0.0613384863060337,\n",
       "   0.06339157832572556,\n",
       "   0.0641070491663232,\n",
       "   0.06448198498182356,\n",
       "   0.06307424152310069,\n",
       "   0.05659583882831817,\n",
       "   0.06115827042228327,\n",
       "   0.0625884599457373,\n",
       "   0.058472848037456136,\n",
       "   0.06383575528384056,\n",
       "   0.05856209400402444,\n",
       "   0.0588349645170612,\n",
       "   0.058361890902662125,\n",
       "   0.061831914805562896,\n",
       "   0.061086058580134765,\n",
       "   0.05980601957238949,\n",
       "   0.05854340794498474,\n",
       "   0.06056075063222086,\n",
       "   0.05837263263372414,\n",
       "   0.06199040879298005,\n",
       "   0.05766854577583528,\n",
       "   0.060695435593681825,\n",
       "   0.0606584479842574,\n",
       "   0.06327432487687529,\n",
       "   0.06067983834927738,\n",
       "   0.059172142290492585,\n",
       "   0.05794571647831502,\n",
       "   0.06248641402300734,\n",
       "   0.058651791215897676,\n",
       "   0.06222512764154951,\n",
       "   0.060548216095650684,\n",
       "   0.05661295487057218,\n",
       "   0.06078240164827344,\n",
       "   0.05866936993192973,\n",
       "   0.05955300723013841,\n",
       "   0.056268050277295575,\n",
       "   0.057080140388256845,\n",
       "   0.05813360330850108,\n",
       "   0.058076821173439576,\n",
       "   0.057275531290293155,\n",
       "   0.057075195416284544,\n",
       "   0.05982106152478251,\n",
       "   0.056336266675819445,\n",
       "   0.05837632987437048,\n",
       "   0.05750469093541408,\n",
       "   0.06093399966165079,\n",
       "   0.058235658077786835,\n",
       "   0.05750958929785716,\n",
       "   0.05761311691815642,\n",
       "   0.058849187251826585,\n",
       "   0.058469237034720144,\n",
       "   0.06129180648372267,\n",
       "   0.0558371996246257,\n",
       "   0.05970829763804626,\n",
       "   0.056525501649062934,\n",
       "   0.05636862277362295,\n",
       "   0.056774922914718515,\n",
       "   0.06072447225725964,\n",
       "   0.05581409914511799,\n",
       "   0.05691046572530966,\n",
       "   0.05959319237257311,\n",
       "   0.05995900276061789,\n",
       "   0.05655945367929914,\n",
       "   0.058734294462033106,\n",
       "   0.05489723799039951,\n",
       "   0.06024143427399667,\n",
       "   0.059562368968577244,\n",
       "   0.055483925037965655,\n",
       "   0.057904655644531865,\n",
       "   0.05479868823745104,\n",
       "   0.056715311587304466,\n",
       "   0.05789626937941102,\n",
       "   0.05486383158699988,\n",
       "   0.05903373620158079,\n",
       "   0.0580866248537325,\n",
       "   0.05641036190375222,\n",
       "   0.05485897107152519,\n",
       "   0.057202276624876695,\n",
       "   0.05644942810074001,\n",
       "   0.06141134081481692,\n",
       "   0.05378703518614399,\n",
       "   0.056446386230667916,\n",
       "   0.05493669109213588],\n",
       "  'train_loss_importance_vector_0_mean': [0.20000000298023224,\n",
       "   0.18666666746139526,\n",
       "   0.1733333319425583,\n",
       "   0.1599999964237213,\n",
       "   0.14666666090488434,\n",
       "   0.13333334028720856,\n",
       "   0.11999999731779099,\n",
       "   0.1066666692495346,\n",
       "   0.09333333373069763,\n",
       "   0.07999999821186066,\n",
       "   0.06666667014360428,\n",
       "   0.0533333346247673,\n",
       "   0.03999999910593033,\n",
       "   0.02666666731238365,\n",
       "   0.013333333656191826,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064],\n",
       "  'train_loss_importance_vector_0_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'train_loss_importance_vector_1_mean': [0.20000000298023224,\n",
       "   0.18666666746139526,\n",
       "   0.1733333319425583,\n",
       "   0.1599999964237213,\n",
       "   0.14666666090488434,\n",
       "   0.13333334028720856,\n",
       "   0.11999999731779099,\n",
       "   0.1066666692495346,\n",
       "   0.09333333373069763,\n",
       "   0.07999999821186066,\n",
       "   0.06666667014360428,\n",
       "   0.0533333346247673,\n",
       "   0.03999999910593033,\n",
       "   0.02666666731238365,\n",
       "   0.013333333656191826,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064],\n",
       "  'train_loss_importance_vector_1_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'train_loss_importance_vector_2_mean': [0.20000000298023224,\n",
       "   0.18666666746139526,\n",
       "   0.1733333319425583,\n",
       "   0.1599999964237213,\n",
       "   0.14666666090488434,\n",
       "   0.13333334028720856,\n",
       "   0.11999999731779099,\n",
       "   0.1066666692495346,\n",
       "   0.09333333373069763,\n",
       "   0.07999999821186066,\n",
       "   0.06666667014360428,\n",
       "   0.0533333346247673,\n",
       "   0.03999999910593033,\n",
       "   0.02666666731238365,\n",
       "   0.013333333656191826,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064],\n",
       "  'train_loss_importance_vector_2_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'train_loss_importance_vector_3_mean': [0.20000000298023224,\n",
       "   0.18666666746139526,\n",
       "   0.1733333319425583,\n",
       "   0.1599999964237213,\n",
       "   0.14666666090488434,\n",
       "   0.13333334028720856,\n",
       "   0.11999999731779099,\n",
       "   0.1066666692495346,\n",
       "   0.09333333373069763,\n",
       "   0.07999999821186066,\n",
       "   0.06666667014360428,\n",
       "   0.0533333346247673,\n",
       "   0.03999999910593033,\n",
       "   0.02666666731238365,\n",
       "   0.013333333656191826,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064],\n",
       "  'train_loss_importance_vector_3_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'train_loss_importance_vector_4_mean': [0.20000000298023224,\n",
       "   0.25333333015441895,\n",
       "   0.30666667222976685,\n",
       "   0.36000001430511475,\n",
       "   0.41333332657814026,\n",
       "   0.46666666865348816,\n",
       "   0.5199999809265137,\n",
       "   0.5733333230018616,\n",
       "   0.6266666650772095,\n",
       "   0.6800000071525574,\n",
       "   0.7333333492279053,\n",
       "   0.7866666913032532,\n",
       "   0.8399999737739563,\n",
       "   0.8933333158493042,\n",
       "   0.9466666579246521,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546],\n",
       "  'train_loss_importance_vector_4_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'train_learning_rate_mean': [0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005,\n",
       "   0.0010000000000000005],\n",
       "  'train_learning_rate_std': [4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19,\n",
       "   4.336808689942018e-19],\n",
       "  'val_loss_mean': [1.3638961803913117,\n",
       "   1.2229010911782583,\n",
       "   1.1647925506035486,\n",
       "   1.139654997388522,\n",
       "   1.113648825287819,\n",
       "   1.0629060816764833,\n",
       "   1.0590756314992904,\n",
       "   1.050997693737348,\n",
       "   1.013101231654485,\n",
       "   0.9954779247442881,\n",
       "   0.9761733635266622,\n",
       "   0.9652349529663722,\n",
       "   0.9637797162930171,\n",
       "   0.9637210756540299,\n",
       "   0.9739676823218664,\n",
       "   0.9613964915275574,\n",
       "   0.9383996158838273,\n",
       "   0.9271624314785004,\n",
       "   0.9681146003802618,\n",
       "   0.9345628271500269,\n",
       "   0.9574245816469192,\n",
       "   0.924825358192126,\n",
       "   0.9099760947624842,\n",
       "   0.9220849227905273,\n",
       "   0.9042441620429357,\n",
       "   0.9115960707267126,\n",
       "   0.9247081176439921,\n",
       "   0.9176876652240753,\n",
       "   0.9108298009634018,\n",
       "   0.9138818176587423,\n",
       "   0.9138319814205169,\n",
       "   0.9772489287455877,\n",
       "   0.9007962890466055,\n",
       "   0.916221942504247,\n",
       "   0.906806378364563,\n",
       "   0.9111019708712895,\n",
       "   0.908636908531189,\n",
       "   0.9187039248148601,\n",
       "   0.9300190496444702,\n",
       "   0.9174943564335505,\n",
       "   0.925990361769994,\n",
       "   0.9284041764338812,\n",
       "   0.9129143816232681,\n",
       "   0.9187601880232493,\n",
       "   0.9091062966982524,\n",
       "   0.920066639582316,\n",
       "   0.9259215766191482,\n",
       "   0.9952064357201258,\n",
       "   0.9087821064392726,\n",
       "   0.9124377131462097,\n",
       "   0.9128633306423823,\n",
       "   0.9305381552378337,\n",
       "   0.9132787841558456,\n",
       "   0.9143071681261062,\n",
       "   0.9157892527182897,\n",
       "   0.9324130817254385,\n",
       "   0.9162640319267908,\n",
       "   0.9254227860768636,\n",
       "   0.9330246579647065,\n",
       "   0.9400067675113678,\n",
       "   0.9340177313486735,\n",
       "   0.9320868148406347,\n",
       "   0.9525225881735484,\n",
       "   0.9482289747397105,\n",
       "   0.9265881925821304,\n",
       "   0.9236228664716085,\n",
       "   0.9470560677846273,\n",
       "   0.9329888266324997,\n",
       "   0.9437516049544017,\n",
       "   0.9403902192910513,\n",
       "   0.9602256021896998,\n",
       "   0.9389830219745636,\n",
       "   0.9568384102980296,\n",
       "   0.9422046653429668,\n",
       "   0.9681998399893442,\n",
       "   0.9543885354200999,\n",
       "   0.9464990103244781,\n",
       "   0.9502060796817143,\n",
       "   0.9459489307800929,\n",
       "   0.9593949955701828,\n",
       "   0.9555120392640432,\n",
       "   0.9443522866566976,\n",
       "   0.9535773112376531,\n",
       "   0.9516563880443573,\n",
       "   0.9455244183540344,\n",
       "   0.9667045164108277,\n",
       "   0.9599228282769521,\n",
       "   0.9518605438868205,\n",
       "   0.9412835854291915,\n",
       "   0.9627139083544414,\n",
       "   0.9615793863932292,\n",
       "   0.946319442987442,\n",
       "   0.9537743016084035,\n",
       "   0.974657630721728,\n",
       "   0.9483506641785304,\n",
       "   0.951670036315918,\n",
       "   0.9397315577665964,\n",
       "   0.9537831139564514,\n",
       "   0.9555253247419994],\n",
       "  'val_loss_std': [0.10239758349535745,\n",
       "   0.11866311920411354,\n",
       "   0.1306360657056468,\n",
       "   0.1333222818529221,\n",
       "   0.13876616641253603,\n",
       "   0.13236389371519758,\n",
       "   0.13777845607154837,\n",
       "   0.13513394329444267,\n",
       "   0.1292642122075696,\n",
       "   0.1293804102528254,\n",
       "   0.12882529755154007,\n",
       "   0.12924482490042055,\n",
       "   0.135525014409551,\n",
       "   0.1288272688530453,\n",
       "   0.12418143917879028,\n",
       "   0.1239191561531761,\n",
       "   0.12898017790288954,\n",
       "   0.13127132864553434,\n",
       "   0.13275107467698585,\n",
       "   0.13073412037938256,\n",
       "   0.12470883856811306,\n",
       "   0.1256644364414366,\n",
       "   0.12737831345182746,\n",
       "   0.12579512202309362,\n",
       "   0.12581353794693906,\n",
       "   0.12745391830176708,\n",
       "   0.12467283173704864,\n",
       "   0.1288788358037708,\n",
       "   0.13118940811468152,\n",
       "   0.1229335274615152,\n",
       "   0.13116700095034095,\n",
       "   0.12424667309354273,\n",
       "   0.12441023115603621,\n",
       "   0.12559014950639996,\n",
       "   0.1290592829462789,\n",
       "   0.13207456941409587,\n",
       "   0.1304668032177877,\n",
       "   0.12745929000599368,\n",
       "   0.1347886662577716,\n",
       "   0.13074526732423308,\n",
       "   0.13177432725144522,\n",
       "   0.1219544659635333,\n",
       "   0.1278525072523663,\n",
       "   0.12817855015878588,\n",
       "   0.12565686352386343,\n",
       "   0.1276531991406745,\n",
       "   0.12841630730243736,\n",
       "   0.11759603649471859,\n",
       "   0.13618490079711543,\n",
       "   0.13182464797432772,\n",
       "   0.12696886058011111,\n",
       "   0.13615627761753127,\n",
       "   0.12683988633267376,\n",
       "   0.12397767130940682,\n",
       "   0.13455501594354236,\n",
       "   0.12974344761183013,\n",
       "   0.13452024880098706,\n",
       "   0.12795267878873548,\n",
       "   0.12885507349838046,\n",
       "   0.13310465772640892,\n",
       "   0.12810861466666887,\n",
       "   0.13234160869627581,\n",
       "   0.13017980365624346,\n",
       "   0.13058247581479845,\n",
       "   0.13001907142668065,\n",
       "   0.13262728545493738,\n",
       "   0.13584498807255505,\n",
       "   0.12750972898283053,\n",
       "   0.1381385434014239,\n",
       "   0.1331765437011908,\n",
       "   0.13318257524168908,\n",
       "   0.12691321869804828,\n",
       "   0.13398790897921317,\n",
       "   0.12451727967036623,\n",
       "   0.13785298679111255,\n",
       "   0.1325953943453727,\n",
       "   0.12663011824512427,\n",
       "   0.1297897864624669,\n",
       "   0.13181410133322902,\n",
       "   0.1362259832173056,\n",
       "   0.13153849873457057,\n",
       "   0.13451571142973134,\n",
       "   0.13992757200730452,\n",
       "   0.14289648490571477,\n",
       "   0.12741409237974613,\n",
       "   0.1316415949120241,\n",
       "   0.1315493391493938,\n",
       "   0.135725609846602,\n",
       "   0.13640001260995727,\n",
       "   0.13258777613345726,\n",
       "   0.13995084248222087,\n",
       "   0.1335404110772166,\n",
       "   0.14055777429895724,\n",
       "   0.13846317862945065,\n",
       "   0.14088242172688836,\n",
       "   0.13840149291044754,\n",
       "   0.13778243641490254,\n",
       "   0.13851464415597958,\n",
       "   0.13226622872251972],\n",
       "  'val_accuracy_mean': [0.43920000036557516,\n",
       "   0.513955555955569,\n",
       "   0.5412666650613149,\n",
       "   0.5509555546442667,\n",
       "   0.5619555549820264,\n",
       "   0.5849777761101723,\n",
       "   0.5892222210764885,\n",
       "   0.5891777747869491,\n",
       "   0.609466665883859,\n",
       "   0.6142888884743055,\n",
       "   0.6231111108263334,\n",
       "   0.6281111116210619,\n",
       "   0.6277555550138155,\n",
       "   0.627644444902738,\n",
       "   0.6233333312471707,\n",
       "   0.6279111100236575,\n",
       "   0.640399999221166,\n",
       "   0.6448888886968295,\n",
       "   0.6257111098368963,\n",
       "   0.6421333333849907,\n",
       "   0.632088886698087,\n",
       "   0.6468444437781969,\n",
       "   0.6511111116409302,\n",
       "   0.6453333336114884,\n",
       "   0.6499111103018125,\n",
       "   0.6517777775724729,\n",
       "   0.6475333309173584,\n",
       "   0.6481777769327164,\n",
       "   0.652555555899938,\n",
       "   0.6486222232381503,\n",
       "   0.648933333158493,\n",
       "   0.6216222219665846,\n",
       "   0.6550666664044063,\n",
       "   0.6487777760624885,\n",
       "   0.650888887445132,\n",
       "   0.6512666644652685,\n",
       "   0.6510888870557149,\n",
       "   0.6479777775208155,\n",
       "   0.6425555549065272,\n",
       "   0.6479777759313583,\n",
       "   0.6439555558562279,\n",
       "   0.6441555554668109,\n",
       "   0.6482666647434234,\n",
       "   0.6485111115376154,\n",
       "   0.650466668109099,\n",
       "   0.6461111116409302,\n",
       "   0.6453333327174187,\n",
       "   0.6152222200234732,\n",
       "   0.6519777767856916,\n",
       "   0.6514000005523364,\n",
       "   0.6501555563012759,\n",
       "   0.6436222221453984,\n",
       "   0.6450222206115722,\n",
       "   0.6462666644652685,\n",
       "   0.648022221326828,\n",
       "   0.6387555555502573,\n",
       "   0.6483999999364217,\n",
       "   0.6427777783075969,\n",
       "   0.6391777761777242,\n",
       "   0.6379555541276932,\n",
       "   0.639422222574552,\n",
       "   0.6415999986728033,\n",
       "   0.6313555545608203,\n",
       "   0.6311111097534498,\n",
       "   0.6429555557171504,\n",
       "   0.6459555552403132,\n",
       "   0.6361111102501551,\n",
       "   0.6411555561423302,\n",
       "   0.6348666664958,\n",
       "   0.6380222205320994,\n",
       "   0.6276444437106451,\n",
       "   0.6392444445689519,\n",
       "   0.6329555549224217,\n",
       "   0.6370888884862264,\n",
       "   0.626733333170414,\n",
       "   0.6309555545449257,\n",
       "   0.6333111110329628,\n",
       "   0.6336444439490636,\n",
       "   0.6319333329796791,\n",
       "   0.6260222225387891,\n",
       "   0.628666666050752,\n",
       "   0.6319333319862683,\n",
       "   0.6339111090699832,\n",
       "   0.6315555555621782,\n",
       "   0.6325333323081335,\n",
       "   0.6221333328882853,\n",
       "   0.6266444443662962,\n",
       "   0.6305999989310901,\n",
       "   0.6344222214818,\n",
       "   0.626466666162014,\n",
       "   0.6254888895153999,\n",
       "   0.6331333327293396,\n",
       "   0.633444443444411,\n",
       "   0.6249777776996295,\n",
       "   0.6343555554747582,\n",
       "   0.6322666666905086,\n",
       "   0.6357777770360311,\n",
       "   0.6307777764399847,\n",
       "   0.6295333321889242],\n",
       "  'val_accuracy_std': [0.05540380990769798,\n",
       "   0.060228438185702705,\n",
       "   0.06400019562609857,\n",
       "   0.06419511603599963,\n",
       "   0.06339784665539014,\n",
       "   0.0636201051942842,\n",
       "   0.06494774681815277,\n",
       "   0.06359179571136145,\n",
       "   0.061743890944465266,\n",
       "   0.06340094172902971,\n",
       "   0.06257518949130769,\n",
       "   0.0596122243407247,\n",
       "   0.061813335556880775,\n",
       "   0.06162436616343117,\n",
       "   0.06298853554539659,\n",
       "   0.06137142164960313,\n",
       "   0.06270084175988012,\n",
       "   0.060636950692598834,\n",
       "   0.0649544988312707,\n",
       "   0.06267999743813801,\n",
       "   0.06069418960277866,\n",
       "   0.06061876909436977,\n",
       "   0.0631338008964403,\n",
       "   0.060745981142224625,\n",
       "   0.06274102881691714,\n",
       "   0.061513825320116705,\n",
       "   0.06179287833327865,\n",
       "   0.062418644405241766,\n",
       "   0.06135134707783905,\n",
       "   0.060538554680592126,\n",
       "   0.061301102223439374,\n",
       "   0.06554301617864175,\n",
       "   0.06094043368491554,\n",
       "   0.06094675003741202,\n",
       "   0.06269227179487509,\n",
       "   0.06373808640823317,\n",
       "   0.06491133255863522,\n",
       "   0.06256895136750189,\n",
       "   0.0664629320245928,\n",
       "   0.06241248385757635,\n",
       "   0.06331858088220954,\n",
       "   0.060175592965309325,\n",
       "   0.06191119156521017,\n",
       "   0.0650789118198778,\n",
       "   0.06041526809045952,\n",
       "   0.06350843211501762,\n",
       "   0.06133575016364911,\n",
       "   0.06451519238994377,\n",
       "   0.061331638289794606,\n",
       "   0.062498320882509076,\n",
       "   0.06402411204272013,\n",
       "   0.06325075014842858,\n",
       "   0.060346832962845307,\n",
       "   0.061380320885398236,\n",
       "   0.06338430346968271,\n",
       "   0.0636047356646884,\n",
       "   0.06517863881846517,\n",
       "   0.06304721084830671,\n",
       "   0.05909745608225456,\n",
       "   0.06268296213097893,\n",
       "   0.06179505846223131,\n",
       "   0.06396378787694844,\n",
       "   0.06587822374874754,\n",
       "   0.06300460475365206,\n",
       "   0.06422649596632221,\n",
       "   0.0625892995685028,\n",
       "   0.06366453261543414,\n",
       "   0.06539111810909536,\n",
       "   0.06498219809225353,\n",
       "   0.06394047967749321,\n",
       "   0.06149922722455358,\n",
       "   0.06120535873532953,\n",
       "   0.06279424184814865,\n",
       "   0.06321251391184396,\n",
       "   0.062464177569439554,\n",
       "   0.063673749350074,\n",
       "   0.06329589180230587,\n",
       "   0.063583539199474,\n",
       "   0.062058242012673986,\n",
       "   0.06350059302992492,\n",
       "   0.06381106412381227,\n",
       "   0.06594697224152704,\n",
       "   0.06445641471309749,\n",
       "   0.064340145460968,\n",
       "   0.061107895376712025,\n",
       "   0.0648659931339262,\n",
       "   0.0676318979708645,\n",
       "   0.06671839362336646,\n",
       "   0.06371347807404341,\n",
       "   0.0638826827636937,\n",
       "   0.06564510173984796,\n",
       "   0.0660939058838478,\n",
       "   0.0641097645988135,\n",
       "   0.06600196183759525,\n",
       "   0.06283069280479699,\n",
       "   0.06774497079898716,\n",
       "   0.06493491699861399,\n",
       "   0.06341972794862683,\n",
       "   0.06411278451417123],\n",
       "  'val_loss_importance_vector_0_mean': [0.20000000298023224,\n",
       "   0.18666666746139526,\n",
       "   0.1733333319425583,\n",
       "   0.1599999964237213,\n",
       "   0.14666666090488434,\n",
       "   0.13333334028720856,\n",
       "   0.11999999731779099,\n",
       "   0.1066666692495346,\n",
       "   0.09333333373069763,\n",
       "   0.07999999821186066,\n",
       "   0.06666667014360428,\n",
       "   0.0533333346247673,\n",
       "   0.03999999910593033,\n",
       "   0.02666666731238365,\n",
       "   0.013333333656191826,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064],\n",
       "  'val_loss_importance_vector_0_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'val_loss_importance_vector_1_mean': [0.20000000298023224,\n",
       "   0.18666666746139526,\n",
       "   0.1733333319425583,\n",
       "   0.1599999964237213,\n",
       "   0.14666666090488434,\n",
       "   0.13333334028720856,\n",
       "   0.11999999731779099,\n",
       "   0.1066666692495346,\n",
       "   0.09333333373069763,\n",
       "   0.07999999821186066,\n",
       "   0.06666667014360428,\n",
       "   0.0533333346247673,\n",
       "   0.03999999910593033,\n",
       "   0.02666666731238365,\n",
       "   0.013333333656191826,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064],\n",
       "  'val_loss_importance_vector_1_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'val_loss_importance_vector_2_mean': [0.20000000298023224,\n",
       "   0.18666666746139526,\n",
       "   0.1733333319425583,\n",
       "   0.1599999964237213,\n",
       "   0.14666666090488434,\n",
       "   0.13333334028720856,\n",
       "   0.11999999731779099,\n",
       "   0.1066666692495346,\n",
       "   0.09333333373069763,\n",
       "   0.07999999821186066,\n",
       "   0.06666667014360428,\n",
       "   0.0533333346247673,\n",
       "   0.03999999910593033,\n",
       "   0.02666666731238365,\n",
       "   0.013333333656191826,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064],\n",
       "  'val_loss_importance_vector_2_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'val_loss_importance_vector_3_mean': [0.20000000298023224,\n",
       "   0.18666666746139526,\n",
       "   0.1733333319425583,\n",
       "   0.1599999964237213,\n",
       "   0.14666666090488434,\n",
       "   0.13333334028720856,\n",
       "   0.11999999731779099,\n",
       "   0.1066666692495346,\n",
       "   0.09333333373069763,\n",
       "   0.07999999821186066,\n",
       "   0.06666667014360428,\n",
       "   0.0533333346247673,\n",
       "   0.03999999910593033,\n",
       "   0.02666666731238365,\n",
       "   0.013333333656191826,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064,\n",
       "   0.006000000052154064],\n",
       "  'val_loss_importance_vector_3_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'val_loss_importance_vector_4_mean': [0.20000000298023224,\n",
       "   0.25333333015441895,\n",
       "   0.30666667222976685,\n",
       "   0.36000001430511475,\n",
       "   0.41333332657814026,\n",
       "   0.46666666865348816,\n",
       "   0.5199999809265137,\n",
       "   0.5733333230018616,\n",
       "   0.6266666650772095,\n",
       "   0.6800000071525574,\n",
       "   0.7333333492279053,\n",
       "   0.7866666913032532,\n",
       "   0.8399999737739563,\n",
       "   0.8933333158493042,\n",
       "   0.9466666579246521,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546,\n",
       "   0.9760000109672546],\n",
       "  'val_loss_importance_vector_4_std': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maml_system.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576fb176",
   "metadata": {},
   "source": [
    "# 1. 학습된 모델을 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2a4a658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_dir = maml_system.saved_models_filepath\n",
    "model_name = \"train_model\"\n",
    "model_idx = maml_system.state['best_epoch']\n",
    "\n",
    "state = maml_system.model.load_model(model_save_dir=model_save_dir,\n",
    "                                     model_name=model_name,\n",
    "                                     model_idx=model_idx+1)\n",
    "\n",
    "state_dict_loaded = state['network']\n",
    "\n",
    "maml_system.model.load_state_dict(state_dict=state_dict_loaded)\n",
    "\n",
    "# # 잘 불러왔는지 확인하는 코드\n",
    "# print(\"state_dict_loaded == \",state_dict_loaded)\n",
    "# print(\"=\"*10)\n",
    "# for key, value in maml_system.model.named_parameters():\n",
    "#     print(key)\n",
    "#     print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d164b2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.layer_dict.conv0.conv.weight\n",
      "torch.Size([48, 3, 3, 3])\n",
      "classifier.layer_dict.conv0.conv.bias\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv0.norm_layer.bias\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv0.norm_layer.weight\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv1.conv.weight\n",
      "torch.Size([48, 48, 3, 3])\n",
      "classifier.layer_dict.conv1.conv.bias\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv1.norm_layer.bias\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv1.norm_layer.weight\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv2.conv.weight\n",
      "torch.Size([48, 48, 3, 3])\n",
      "classifier.layer_dict.conv2.conv.bias\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv2.norm_layer.bias\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv2.norm_layer.weight\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv3.conv.weight\n",
      "torch.Size([48, 48, 3, 3])\n",
      "classifier.layer_dict.conv3.conv.bias\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv3.norm_layer.bias\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.conv3.norm_layer.weight\n",
      "torch.Size([48])\n",
      "classifier.layer_dict.linear.weights\n",
      "torch.Size([5, 1200])\n",
      "classifier.layer_dict.linear.bias\n",
      "torch.Size([5])\n",
      "arbiter.0.weight\n",
      "torch.Size([20, 20])\n",
      "arbiter.0.bias\n",
      "torch.Size([20])\n",
      "arbiter.2.weight\n",
      "torch.Size([10, 20])\n",
      "arbiter.2.bias\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for key, value in maml_system.model.named_parameters():\n",
    "    #print(key)\n",
    "    if value.requires_grad:\n",
    "        print(key)\n",
    "        print(value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1484a472",
   "metadata": {},
   "source": [
    "# 2. Data를 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "170a7604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "tensor([-2.7831e-05,  1.6364e-04,  7.8645e-05, -1.3428e-04,  7.3941e-05,\n",
      "         1.3584e-04,  2.3336e-04,  1.0114e-05,  1.9297e-04, -4.8166e-05,\n",
      "         1.5378e-04,  3.2436e-05, -6.1915e-05,  1.1114e-04,  3.7253e-04,\n",
      "         1.0191e-04, -2.0678e-05, -1.3672e-05,  1.2581e-04,  1.7060e-04,\n",
      "         8.3038e-05, -2.2846e-05, -2.4171e-05,  2.0010e-04,  1.6366e-04,\n",
      "         1.7225e-04,  1.1767e-04,  1.0054e-04,  1.0600e-04,  2.4578e-04,\n",
      "         1.3775e-04,  1.4697e-04,  2.2743e-04, -1.5442e-05,  1.5667e-04,\n",
      "        -8.7674e-06, -2.0144e-04,  6.9026e-05,  4.7663e-05,  2.0954e-04,\n",
      "        -3.9548e-05,  1.4349e-04,  3.7335e-04,  1.9904e-05, -1.5863e-05,\n",
      "        -9.7062e-06, -5.9548e-05, -1.3889e-04], device='cuda:0',\n",
      "       grad_fn=<CopyBackwards>)\n",
      "tensor([-5.3978e-05,  4.0786e-05,  1.4302e-04, -7.9829e-05, -3.6876e-05,\n",
      "         5.7697e-05,  3.1358e-04,  4.3675e-05,  1.6941e-04, -2.0291e-05,\n",
      "         1.0947e-04, -4.5364e-05, -7.4292e-05,  9.8706e-05, -1.4675e-04,\n",
      "         1.0286e-05, -2.6757e-06, -2.2843e-05, -5.5476e-05,  2.0508e-04,\n",
      "         1.0051e-04, -3.1000e-05, -2.0751e-05,  1.0139e-04,  2.7551e-06,\n",
      "         2.3230e-04,  1.3393e-04,  1.7958e-04, -1.8749e-04,  3.9953e-05,\n",
      "         5.9057e-06, -1.9140e-04, -2.2716e-04, -1.6759e-04,  2.1967e-04,\n",
      "        -1.6247e-05, -2.9958e-04,  1.0331e-05,  1.3304e-04, -1.2553e-04,\n",
      "         1.2636e-04, -4.9711e-05,  4.7608e-04, -2.1181e-04, -2.1670e-05,\n",
      "         3.7889e-05, -1.3639e-04, -1.4814e-04], device='cuda:0',\n",
      "       grad_fn=<CopyBackwards>)\n",
      "tensor([ 7.7307e-12, -7.2760e-12,  5.4570e-12,  0.0000e+00,  8.1855e-12,\n",
      "         3.6380e-12, -5.0022e-12,  1.6371e-11,  0.0000e+00, -5.6843e-12,\n",
      "        -4.5475e-13,  9.0949e-13,  7.2760e-12,  4.5475e-12,  1.0687e-11,\n",
      "        -3.6380e-12,  7.2760e-12, -1.3642e-12,  5.4570e-12,  4.5475e-12,\n",
      "        -4.5475e-12,  4.0927e-12, -1.8190e-12, -7.7307e-12,  4.5475e-13,\n",
      "        -9.0949e-12,  1.0914e-11,  9.0949e-12, -3.6380e-12, -1.8190e-12,\n",
      "         7.2760e-12, -4.5475e-12,  7.2760e-12, -9.0949e-12,  0.0000e+00,\n",
      "         9.0949e-12,  1.5461e-11,  3.6380e-12, -3.6380e-12,  1.8190e-11,\n",
      "         1.8190e-12,  0.0000e+00, -7.2760e-12, -6.8212e-12, -3.1832e-12,\n",
      "         5.4570e-12, -4.5475e-13,  1.5461e-11], device='cuda:0',\n",
      "       grad_fn=<CopyBackwards>)\n",
      "tensor([ 2.9115e-04,  4.5893e-05,  2.1071e-04,  1.3379e-05,  2.6262e-04,\n",
      "         2.0299e-05,  1.5219e-04, -1.6865e-04,  3.5551e-05,  5.0356e-04,\n",
      "        -1.7192e-04,  1.7147e-05,  1.3294e-04,  2.4224e-04,  1.3357e-04,\n",
      "        -9.3596e-05,  1.8165e-04, -2.6495e-04,  1.6379e-04,  9.8180e-05,\n",
      "         1.1621e-04,  8.3675e-05,  5.9937e-05, -1.3401e-04, -6.4893e-05,\n",
      "        -1.2440e-04,  1.9820e-05, -1.7293e-04,  1.9220e-04,  7.5862e-05,\n",
      "         2.2458e-04, -3.6364e-04, -9.5094e-05,  1.4760e-04,  2.5065e-04,\n",
      "         2.4213e-04,  8.3307e-05,  1.3026e-04, -2.6750e-05,  1.7306e-04,\n",
      "         2.7740e-04,  3.7902e-04, -2.4424e-04,  8.9380e-05,  8.8953e-05,\n",
      "        -2.0232e-04,  7.8134e-05,  2.4267e-04], device='cuda:0',\n",
      "       grad_fn=<CopyBackwards>)\n",
      "tensor([ 1.6061e-04, -5.1732e-05,  1.8937e-04, -3.0198e-04,  3.6339e-04,\n",
      "        -3.3646e-05,  6.5907e-06, -1.3808e-04, -8.3925e-05,  7.7938e-04,\n",
      "         2.5626e-04, -5.7073e-05,  4.8645e-05,  1.4674e-04,  1.4731e-04,\n",
      "        -2.5013e-04, -9.2141e-05, -3.5098e-04, -3.4665e-05, -1.2225e-04,\n",
      "         2.3072e-04, -8.7756e-05,  3.2199e-04,  4.1168e-04, -8.4335e-06,\n",
      "        -9.9784e-05,  3.4238e-04, -3.5015e-04, -1.3403e-04, -1.0008e-04,\n",
      "         1.3950e-04, -6.7117e-04, -1.9047e-04,  2.4902e-04,  6.1178e-05,\n",
      "         1.3471e-04,  5.0229e-05, -1.2315e-04, -3.0312e-05,  3.0943e-04,\n",
      "         3.8088e-04,  3.8252e-04, -2.3869e-04,  1.3274e-06, -8.9702e-05,\n",
      "        -4.5304e-04,  1.4273e-05, -7.3229e-05], device='cuda:0',\n",
      "       grad_fn=<CopyBackwards>)\n",
      "tensor([[[[-6.8197e-06, -1.5818e-06, -2.7215e-06],\n",
      "          [ 2.4436e-07,  1.0624e-06,  4.9574e-06],\n",
      "          [ 2.7166e-06, -1.4742e-05, -2.4562e-05]],\n",
      "\n",
      "         [[ 1.5433e-06, -7.8903e-06,  1.3934e-05],\n",
      "          [ 7.5360e-07, -4.1670e-06,  8.2326e-06],\n",
      "          [ 9.4182e-06,  6.9383e-06,  1.2728e-05]],\n",
      "\n",
      "         [[-3.3161e-06, -6.5979e-06,  5.6514e-06],\n",
      "          [-1.1412e-05, -7.8575e-06,  1.0652e-05],\n",
      "          [ 3.3797e-07, -2.6171e-05, -3.1847e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3710e-06, -5.1665e-06, -1.2293e-06],\n",
      "          [ 1.0498e-05, -1.8489e-06, -1.2432e-06],\n",
      "          [ 1.4526e-05,  1.4666e-05,  7.3667e-06]],\n",
      "\n",
      "         [[ 2.9898e-06,  1.4072e-05,  2.4813e-05],\n",
      "          [ 1.0780e-05,  7.4641e-06,  1.7090e-05],\n",
      "          [ 1.3648e-05,  9.2054e-06,  7.7633e-06]],\n",
      "\n",
      "         [[ 6.9040e-06,  5.3458e-06,  2.3925e-05],\n",
      "          [-1.2951e-06, -2.7118e-06,  2.7975e-05],\n",
      "          [-6.2932e-07, -2.3018e-05, -4.7705e-06]]],\n",
      "\n",
      "\n",
      "        [[[-6.7032e-05, -2.6918e-05, -8.0836e-06],\n",
      "          [-2.1774e-05, -1.4261e-05,  6.3309e-06],\n",
      "          [ 1.4419e-05, -4.5174e-06, -2.3840e-05]],\n",
      "\n",
      "         [[ 2.2643e-06, -4.8776e-06,  2.5320e-06],\n",
      "          [ 2.6804e-05,  2.6372e-05, -1.6985e-05],\n",
      "          [ 2.3585e-05,  4.8082e-05,  2.7591e-05]],\n",
      "\n",
      "         [[ 4.2016e-06, -2.1447e-05, -2.5603e-05],\n",
      "          [ 1.7885e-05,  1.7659e-05,  2.7153e-05],\n",
      "          [ 3.0457e-05, -5.6046e-06,  1.9226e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7012e-05,  4.6104e-06,  1.2656e-05],\n",
      "          [-3.7698e-05,  1.8612e-05, -1.0856e-05],\n",
      "          [-3.6280e-06,  2.4699e-05,  1.4717e-05]],\n",
      "\n",
      "         [[-1.4771e-05, -5.2685e-05, -1.0980e-05],\n",
      "          [ 4.6084e-07, -2.4964e-06, -9.9602e-06],\n",
      "          [ 2.1589e-05, -4.0861e-06, -3.6180e-05]],\n",
      "\n",
      "         [[-3.2092e-05,  5.3117e-06, -3.5264e-05],\n",
      "          [-5.1654e-05,  3.2352e-05, -3.3508e-05],\n",
      "          [-1.7967e-05,  2.3259e-05, -7.2057e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4194e-05,  2.7293e-05,  1.5807e-06],\n",
      "          [ 5.2230e-06,  1.4580e-05,  1.6928e-05],\n",
      "          [-9.3548e-06,  6.8349e-06,  3.1527e-05]],\n",
      "\n",
      "         [[-2.0317e-05, -2.2585e-05,  1.0608e-06],\n",
      "          [ 2.9482e-07, -2.1562e-05, -1.8350e-05],\n",
      "          [ 2.2043e-05,  1.1651e-05, -4.9735e-06]],\n",
      "\n",
      "         [[-5.4900e-05, -5.1541e-05, -7.2563e-06],\n",
      "          [-2.5121e-05, -1.6259e-05, -2.0783e-05],\n",
      "          [-1.4623e-05, -6.6951e-06,  1.1986e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6639e-06, -3.3897e-06,  2.4615e-05],\n",
      "          [-8.2984e-06,  2.7848e-06, -2.4280e-05],\n",
      "          [ 1.7353e-05,  2.3168e-05,  6.7540e-06]],\n",
      "\n",
      "         [[-1.3694e-05,  3.6558e-06,  8.0379e-06],\n",
      "          [-2.3846e-05, -7.0348e-07,  1.7257e-06],\n",
      "          [-2.0671e-05,  1.1569e-05,  1.6234e-05]],\n",
      "\n",
      "         [[ 1.2178e-05,  3.1112e-05,  3.2313e-05],\n",
      "          [ 2.5758e-05,  9.3790e-06,  1.6199e-05],\n",
      "          [ 1.3373e-05,  1.0189e-05,  2.8235e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2277e-05,  8.0752e-06,  1.7117e-05],\n",
      "          [ 1.3039e-05,  2.3624e-06,  1.9115e-05],\n",
      "          [-9.3414e-06, -2.7410e-05, -4.5148e-06]],\n",
      "\n",
      "         [[-6.3268e-06, -4.7733e-06, -1.1036e-05],\n",
      "          [-2.2190e-05, -2.3944e-05, -1.2905e-05],\n",
      "          [ 1.2599e-05, -7.7810e-06,  1.2995e-05]],\n",
      "\n",
      "         [[-3.7680e-05, -2.9109e-05,  3.6726e-05],\n",
      "          [-2.1524e-07, -8.2822e-06,  1.6521e-05],\n",
      "          [ 4.0634e-05,  2.1307e-05,  1.7389e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1643e-05,  1.3372e-05,  1.5146e-05],\n",
      "          [-2.7580e-05, -2.8217e-05, -2.7775e-05],\n",
      "          [-3.6462e-05, -1.3223e-05, -1.9921e-05]],\n",
      "\n",
      "         [[ 1.8011e-05,  2.1535e-05,  3.9031e-05],\n",
      "          [ 1.6516e-05, -1.0720e-05,  3.8148e-05],\n",
      "          [ 2.9061e-05,  6.0606e-06,  2.6726e-05]],\n",
      "\n",
      "         [[-3.5463e-05, -1.9877e-05, -1.2217e-05],\n",
      "          [-2.6642e-05, -2.5618e-05, -2.9998e-05],\n",
      "          [-6.1633e-05, -7.5431e-06, -2.1914e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.6083e-05, -3.7868e-05, -1.0730e-05],\n",
      "          [ 1.5712e-05,  1.7014e-05,  2.7248e-05],\n",
      "          [ 3.4852e-05,  3.4463e-05,  2.3158e-05]],\n",
      "\n",
      "         [[-1.5949e-05, -1.2761e-05,  8.8824e-06],\n",
      "          [-3.7337e-05, -8.9141e-06,  6.5298e-06],\n",
      "          [-4.6343e-05,  1.2435e-05,  1.5276e-05]],\n",
      "\n",
      "         [[-6.1737e-05, -4.7977e-05, -6.5546e-06],\n",
      "          [-2.4110e-05, -2.2313e-05,  1.6031e-05],\n",
      "          [-2.5309e-05,  2.7117e-06,  8.6653e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3957e-05, -1.2780e-05,  8.4175e-06],\n",
      "          [-3.5091e-05, -2.4691e-05, -4.2648e-06],\n",
      "          [-1.0045e-04, -7.1614e-05,  3.3750e-05]],\n",
      "\n",
      "         [[-7.5974e-06,  5.9326e-06,  5.1335e-05],\n",
      "          [ 1.0930e-05,  2.1269e-05,  2.7935e-05],\n",
      "          [ 4.8363e-05,  4.2845e-05,  2.7184e-05]],\n",
      "\n",
      "         [[-4.0004e-05,  5.3312e-06,  2.3880e-05],\n",
      "          [-9.4652e-05,  3.2935e-05,  2.9342e-05],\n",
      "          [-1.4266e-04,  3.0427e-05,  1.1028e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1447e-05,  2.1296e-05, -8.9163e-06],\n",
      "          [ 3.2490e-06,  2.2729e-06, -6.1523e-06],\n",
      "          [-5.7848e-06, -4.0425e-05, -1.5624e-05]],\n",
      "\n",
      "         [[-1.9802e-05, -2.4145e-05, -2.3900e-05],\n",
      "          [-9.4614e-06, -7.4797e-06, -4.5239e-06],\n",
      "          [ 6.4839e-06, -5.0675e-06,  3.1948e-06]],\n",
      "\n",
      "         [[-2.1258e-05, -4.2101e-06, -2.6106e-05],\n",
      "          [-3.1238e-05, -2.2516e-05, -1.6292e-05],\n",
      "          [-8.3132e-06, -2.7159e-05,  3.4160e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.4555e-05, -1.4065e-05, -3.0222e-06],\n",
      "          [ 3.1600e-06,  6.6607e-06,  1.0349e-05],\n",
      "          [ 9.8870e-06,  1.7712e-05,  1.2934e-05]],\n",
      "\n",
      "         [[-1.1025e-05,  2.6915e-05,  2.8669e-05],\n",
      "          [ 4.1686e-05,  2.7144e-05,  4.0429e-05],\n",
      "          [ 7.4382e-06,  2.2577e-05,  3.7112e-05]],\n",
      "\n",
      "         [[ 1.7246e-05,  6.7706e-06,  2.0726e-05],\n",
      "          [-4.4034e-06, -6.7979e-07,  2.4604e-05],\n",
      "          [-1.4834e-05,  7.8804e-06,  2.1635e-05]]]], device='cuda:0',\n",
      "       grad_fn=<CopyBackwards>)\n",
      "tensor([ 1.8190e-12, -1.8190e-12,  1.1823e-11,  2.5466e-11, -1.0914e-11,\n",
      "         9.0949e-12,  0.0000e+00,  7.2760e-12,  3.6380e-12, -3.6380e-12,\n",
      "         1.8190e-12,  1.4552e-11,  1.4552e-11, -2.7285e-12,  3.6380e-11,\n",
      "        -7.2760e-12,  1.2733e-11, -9.0949e-12, -1.6371e-11,  2.9104e-11,\n",
      "         1.8190e-11,  1.4552e-11, -7.2760e-12,  3.6380e-12, -1.8190e-11,\n",
      "         2.1828e-11, -1.1369e-11,  7.2760e-12, -7.2760e-12, -2.2737e-11,\n",
      "        -1.0914e-11,  1.0004e-11, -7.2760e-12,  1.0004e-11, -1.2733e-11,\n",
      "         4.9113e-11,  5.4570e-12, -2.0009e-11,  6.8212e-12, -1.0914e-11,\n",
      "        -6.3665e-12,  1.6371e-11,  7.2760e-12,  9.0949e-13, -3.5243e-12,\n",
      "        -3.6380e-12, -1.0914e-11, -1.7280e-11], device='cuda:0',\n",
      "       grad_fn=<CopyBackwards>)\n",
      "tensor([[ 4.1706e-06,  1.7662e-05, -1.4364e-05,  ...,  9.0147e-07,\n",
      "          9.4430e-06,  6.6601e-07],\n",
      "        [-3.5354e-06,  1.6845e-05,  4.3287e-05,  ...,  8.3826e-07,\n",
      "         -6.3421e-05,  2.9526e-06],\n",
      "        [ 3.6303e-06,  8.7052e-06,  7.0819e-05,  ...,  7.1827e-06,\n",
      "          1.7386e-05,  3.0871e-06],\n",
      "        [ 4.4449e-06,  2.0191e-05, -1.0249e-04,  ..., -3.7846e-05,\n",
      "         -3.2242e-05, -2.3299e-05],\n",
      "        [-8.7112e-06, -6.3409e-05,  2.7326e-06,  ...,  2.8924e-05,\n",
      "          6.8834e-05,  1.6596e-05]], device='cuda:0', grad_fn=<CopyBackwards>)\n",
      "tensor([-6.5099e-05, -2.2249e-04,  3.2202e-05, -2.4826e-04,  5.0368e-04],\n",
      "       device='cuda:0', grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "tensor([-1.8190e-12,  2.6193e-10,  0.0000e+00,  8.7311e-11,  2.9104e-11,\n",
      "        -3.0559e-10,  7.2760e-12,  2.8194e-11,  1.2187e-10,  7.2760e-11,\n",
      "        -1.1642e-10, -1.6371e-11,  2.0009e-11,  2.0464e-11, -1.2369e-10,\n",
      "         2.9104e-11,  1.3642e-12,  1.4552e-11, -1.6371e-10, -3.5016e-11,\n",
      "        -3.2742e-11, -1.3188e-11, -8.1855e-12,  2.1828e-11, -1.4552e-10,\n",
      "        -4.5475e-12,  1.8190e-12,  3.4561e-11,  7.3123e-10,  7.2760e-10,\n",
      "        -1.7462e-10,  1.6371e-11,  7.9308e-10,  4.2201e-10,  1.8190e-12,\n",
      "         1.6189e-10,  5.8208e-11,  1.1642e-10, -7.2760e-12,  1.1642e-10,\n",
      "        -2.3283e-10, -3.4925e-10,  1.3642e-11,  1.4552e-11,  6.3665e-12,\n",
      "        -1.6007e-10,  2.5466e-11, -1.0914e-11], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-3.7066e-05,  6.6511e-05,  3.2223e-05,  2.2225e-04, -6.0799e-05,\n",
      "         3.3666e-04, -1.9636e-04,  3.3946e-05, -1.8728e-05,  1.5316e-04,\n",
      "         2.8041e-05, -1.6219e-05, -1.2530e-04, -5.9675e-05,  8.8674e-05,\n",
      "         3.5064e-05, -5.2081e-05,  1.0390e-04,  7.6864e-05, -2.0843e-04,\n",
      "         7.3130e-05,  5.7339e-05,  7.3417e-05,  1.3215e-04,  1.9563e-05,\n",
      "        -8.4453e-05,  9.4772e-06,  6.0978e-05, -2.5848e-06,  1.2711e-04,\n",
      "        -7.5637e-05,  4.0269e-05,  1.9387e-04,  3.6201e-04,  1.2428e-04,\n",
      "         4.8364e-06, -6.3227e-05,  4.8465e-05,  8.6859e-05,  2.4641e-05,\n",
      "         3.1844e-04, -4.7289e-04,  7.6982e-05, -3.0271e-04,  6.8349e-05,\n",
      "        -2.2534e-04,  1.1594e-04, -3.1239e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-1.5130e-05,  9.4639e-05, -2.6124e-05,  1.9757e-05,  2.7077e-04,\n",
      "        -1.5965e-04, -3.0350e-04,  3.3748e-05,  2.8346e-05, -2.3371e-04,\n",
      "         8.4282e-05, -1.4073e-05, -1.4413e-04,  1.6873e-05,  4.8581e-05,\n",
      "         3.4594e-05, -9.5822e-05,  2.6762e-04,  1.7916e-04, -1.9583e-04,\n",
      "         2.4964e-04,  1.0422e-04,  1.0086e-04,  2.5212e-04, -2.1290e-04,\n",
      "        -1.1894e-04, -9.7131e-05,  5.0725e-05,  1.7233e-04,  2.0191e-04,\n",
      "         2.8612e-04,  3.8175e-05,  1.7269e-04, -6.9502e-06,  7.5249e-05,\n",
      "        -1.7176e-04, -3.6727e-04,  2.2930e-05,  8.7908e-06, -1.9481e-04,\n",
      "         1.5197e-04, -3.3310e-04,  1.2912e-04, -4.6070e-04,  1.2420e-04,\n",
      "        -5.5232e-05,  3.4807e-04, -3.2108e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[[-9.5063e-07, -1.6186e-05, -2.4610e-06],\n",
      "          [-1.9682e-06, -1.8694e-05, -1.2455e-05],\n",
      "          [-9.0307e-06, -1.8871e-05, -6.1652e-06]],\n",
      "\n",
      "         [[ 5.3197e-05,  5.0668e-05,  1.0426e-04],\n",
      "          [ 6.2142e-07,  1.1063e-05,  4.3504e-05],\n",
      "          [ 3.0196e-05,  3.3759e-05,  2.6493e-05]],\n",
      "\n",
      "         [[ 2.4820e-05,  7.4461e-06,  7.1253e-06],\n",
      "          [ 1.9585e-05, -2.4204e-06,  1.2019e-05],\n",
      "          [ 7.1590e-05, -2.2855e-05,  6.1558e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1322e-05,  3.4990e-05,  5.8372e-05],\n",
      "          [ 2.8084e-05,  4.6372e-05,  9.3579e-05],\n",
      "          [ 1.0974e-04,  8.6937e-05,  8.5776e-05]],\n",
      "\n",
      "         [[-1.2734e-06, -2.5565e-05, -3.5329e-05],\n",
      "          [-1.8551e-06, -3.4029e-05, -4.2104e-05],\n",
      "          [-1.9497e-05, -2.8042e-05, -1.9832e-05]],\n",
      "\n",
      "         [[ 3.3922e-08, -1.7386e-05, -1.9173e-05],\n",
      "          [ 2.7501e-06, -2.2855e-05, -3.1662e-05],\n",
      "          [-3.4328e-05, -5.9035e-05, -3.6355e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 8.8292e-06,  5.7588e-06, -4.2768e-06],\n",
      "          [ 1.4941e-06,  6.5055e-06, -1.1557e-06],\n",
      "          [-4.9189e-06,  4.6582e-06,  4.7958e-06]],\n",
      "\n",
      "         [[ 2.0178e-05, -6.2210e-05, -4.8657e-05],\n",
      "          [ 3.1215e-07, -9.3686e-06, -3.9318e-05],\n",
      "          [ 4.6732e-06, -1.7438e-06, -1.0183e-05]],\n",
      "\n",
      "         [[-6.6319e-06, -3.7593e-05, -3.7574e-05],\n",
      "          [ 2.6791e-05,  2.4730e-05,  1.5164e-05],\n",
      "          [-1.9036e-05, -1.5135e-05,  1.0135e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8353e-05,  1.8360e-05, -2.6051e-05],\n",
      "          [ 2.8122e-05,  5.1602e-05, -2.9200e-06],\n",
      "          [-6.8198e-06,  1.5534e-05,  2.6662e-06]],\n",
      "\n",
      "         [[-1.4896e-05, -3.6361e-05, -5.6841e-05],\n",
      "          [-2.3982e-05, -3.3377e-05, -4.6137e-05],\n",
      "          [-3.7205e-05, -4.3265e-05, -4.4890e-05]],\n",
      "\n",
      "         [[-1.0974e-05, -3.7774e-05, -5.1214e-05],\n",
      "          [ 8.4040e-06, -7.2390e-07, -1.0383e-05],\n",
      "          [-1.6454e-05, -7.3781e-06, -2.3857e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9233e-05,  1.8541e-05,  2.3987e-05],\n",
      "          [ 1.3415e-05,  1.3688e-05,  2.0110e-05],\n",
      "          [ 2.1338e-05,  2.2593e-05,  2.4494e-05]],\n",
      "\n",
      "         [[ 9.3808e-05,  7.9069e-05,  8.5416e-05],\n",
      "          [ 6.8610e-05,  5.9126e-05,  5.7302e-05],\n",
      "          [ 1.2630e-04,  2.6003e-05,  6.9753e-05]],\n",
      "\n",
      "         [[-2.8211e-05,  3.6519e-06, -2.4760e-06],\n",
      "          [-4.1486e-05, -3.2656e-05, -1.1017e-05],\n",
      "          [-1.8563e-05, -4.7763e-05, -1.8400e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0129e-06,  2.3898e-05,  2.2536e-05],\n",
      "          [-5.5789e-07,  2.1918e-05,  2.0435e-05],\n",
      "          [ 2.7118e-05, -6.0725e-06,  4.3664e-05]],\n",
      "\n",
      "         [[ 3.1079e-05,  2.5150e-05,  2.8355e-05],\n",
      "          [ 9.8053e-06,  1.6277e-05,  2.5093e-05],\n",
      "          [ 1.1833e-05,  1.6806e-05,  2.2885e-05]],\n",
      "\n",
      "         [[ 1.6649e-05,  5.1877e-06,  1.2204e-05],\n",
      "          [-2.1072e-06, -9.4928e-06,  2.3894e-06],\n",
      "          [-1.0544e-05, -1.0361e-06,  8.5918e-06]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7420e-05,  1.9436e-05,  7.6106e-06],\n",
      "          [ 1.0034e-05,  1.0484e-05,  9.4556e-07],\n",
      "          [ 4.8372e-06,  4.4818e-06,  5.1622e-06]],\n",
      "\n",
      "         [[-1.5968e-05,  2.3959e-06, -3.3938e-05],\n",
      "          [-9.3532e-06, -2.4962e-05, -2.2273e-05],\n",
      "          [-1.9490e-05, -1.9342e-05,  4.6336e-05]],\n",
      "\n",
      "         [[-4.1076e-05, -3.4579e-05, -5.1022e-05],\n",
      "          [-2.4064e-05, -2.0176e-05, -5.3551e-06],\n",
      "          [-8.7565e-06, -7.5295e-08, -7.0808e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0492e-07,  4.2495e-05, -2.9413e-05],\n",
      "          [-8.0039e-06,  3.4632e-05,  1.2541e-05],\n",
      "          [-6.3100e-05,  4.9754e-05,  3.8727e-05]],\n",
      "\n",
      "         [[ 2.3846e-05,  1.2644e-05,  1.0700e-05],\n",
      "          [ 1.9142e-05,  8.5006e-06,  1.7986e-06],\n",
      "          [ 8.5403e-06, -1.5054e-05, -2.0290e-06]],\n",
      "\n",
      "         [[ 2.3107e-05,  3.8784e-06, -1.8932e-05],\n",
      "          [ 2.6101e-05,  2.0361e-05,  9.1286e-06],\n",
      "          [ 3.3335e-05,  4.3529e-06, -4.7927e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3844e-05,  1.7481e-05,  1.1529e-05],\n",
      "          [ 1.1036e-05,  1.4525e-05,  6.7998e-06],\n",
      "          [ 1.4202e-05,  1.6578e-05,  7.8006e-06]],\n",
      "\n",
      "         [[ 3.6875e-05,  7.5729e-05,  7.2055e-05],\n",
      "          [ 2.1372e-05, -6.4777e-06, -5.7800e-06],\n",
      "          [ 3.3971e-05, -7.3114e-06,  4.0625e-06]],\n",
      "\n",
      "         [[ 4.6452e-06,  4.1349e-05,  5.2247e-06],\n",
      "          [ 3.7701e-06,  2.9196e-05,  1.0389e-05],\n",
      "          [-6.0037e-06,  9.0281e-06,  9.6501e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2769e-05,  3.7961e-05,  2.2365e-05],\n",
      "          [ 3.9392e-05,  1.8065e-05, -1.3714e-05],\n",
      "          [ 2.3496e-05, -1.3881e-05,  3.5025e-06]],\n",
      "\n",
      "         [[ 8.0100e-06,  2.0497e-05,  1.3265e-05],\n",
      "          [ 1.6410e-05,  2.9802e-05,  1.8958e-05],\n",
      "          [ 1.7911e-05,  2.6388e-05,  1.1768e-05]],\n",
      "\n",
      "         [[ 9.1340e-06,  1.6934e-05,  1.1372e-05],\n",
      "          [ 2.7674e-05,  4.0090e-05,  4.2602e-05],\n",
      "          [ 5.1884e-06,  2.2381e-05,  1.4613e-05]]],\n",
      "\n",
      "\n",
      "        [[[-9.8184e-09, -6.2404e-06, -1.8091e-05],\n",
      "          [ 1.5481e-06, -7.1774e-06, -2.0342e-05],\n",
      "          [ 4.7604e-06, -9.9163e-06, -1.5396e-05]],\n",
      "\n",
      "         [[ 5.1272e-05, -3.2799e-05, -5.5968e-05],\n",
      "          [ 2.3261e-05, -2.5806e-05, -4.3327e-05],\n",
      "          [ 2.1275e-05,  1.6195e-05,  2.6114e-05]],\n",
      "\n",
      "         [[ 5.5605e-06, -9.8392e-06, -7.4084e-06],\n",
      "          [ 7.2334e-06,  3.4111e-06, -9.5140e-06],\n",
      "          [ 2.3471e-05,  6.0887e-06, -1.3812e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1291e-05, -1.3125e-04, -3.0207e-05],\n",
      "          [ 1.5243e-05, -1.4376e-04, -3.0708e-05],\n",
      "          [ 3.8689e-05, -8.5454e-05,  3.1002e-06]],\n",
      "\n",
      "         [[ 1.5081e-05,  1.4146e-05,  5.9840e-06],\n",
      "          [ 1.9346e-05,  2.5353e-05,  8.2099e-06],\n",
      "          [ 2.2195e-05,  1.5825e-05,  2.1322e-05]],\n",
      "\n",
      "         [[-1.6823e-05, -2.7289e-05, -4.0138e-05],\n",
      "          [-1.6324e-05, -2.1823e-05, -5.3836e-05],\n",
      "          [-1.5582e-05, -4.2350e-05, -4.8998e-05]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-5.2269e-06,  1.2566e-04,  3.6619e-04, -3.5363e-04, -1.9383e-04,\n",
      "        -1.8373e-05,  3.1494e-04,  1.3382e-04,  3.7432e-04,  6.4123e-04,\n",
      "         1.9903e-05, -2.3344e-04, -2.3530e-04, -3.9864e-05,  4.2778e-04,\n",
      "        -5.3165e-04,  2.2164e-04,  4.1538e-05, -1.5564e-04,  7.2735e-04,\n",
      "         1.2197e-04, -1.1483e-04, -3.2017e-04, -9.4514e-05, -4.4265e-04,\n",
      "         1.5696e-04,  1.0359e-04,  2.4023e-04,  8.2215e-05, -1.2341e-06,\n",
      "        -7.6627e-05,  5.0225e-04,  1.5615e-04,  1.4854e-04,  2.9059e-04,\n",
      "         4.3437e-04, -3.4007e-04,  1.1004e-04, -1.1364e-04, -7.8526e-06,\n",
      "         8.6907e-05,  2.2931e-04, -4.0513e-04,  6.0582e-04, -3.5829e-04,\n",
      "         1.6495e-04, -8.3877e-05,  4.5823e-06], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-1.4072e-04,  3.2497e-04,  1.7208e-04, -4.7098e-04, -4.4078e-04,\n",
      "        -3.1564e-04,  3.0622e-04,  4.2165e-04,  3.5210e-04,  1.0305e-03,\n",
      "         2.2815e-04, -3.2783e-04, -4.6622e-04,  2.9061e-05,  3.5287e-04,\n",
      "        -5.0404e-04, -5.8807e-06, -6.7932e-04, -3.8765e-04,  8.0308e-04,\n",
      "         3.9738e-04, -2.8389e-04, -2.1100e-04,  1.9794e-04, -6.1312e-04,\n",
      "         1.4768e-04,  4.2764e-04,  1.5603e-04, -1.5813e-05, -1.6255e-04,\n",
      "         9.0855e-06,  2.0439e-04,  1.3269e-05, -2.0714e-05,  2.0473e-04,\n",
      "         4.9759e-04, -3.1770e-04,  1.3312e-04, -3.2903e-05,  1.6597e-04,\n",
      "         3.6120e-04,  1.9354e-04, -3.1702e-04,  3.6665e-04, -6.2206e-04,\n",
      "         1.8258e-04, -1.8968e-04, -2.1961e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 1.2157e-04, -6.2825e-04,  4.0231e-04, -1.4717e-04,  6.2150e-05,\n",
      "        -4.2256e-04, -5.0177e-05, -7.1981e-05, -3.5621e-04, -7.4557e-05,\n",
      "         1.8300e-04,  2.0231e-04, -2.2675e-05,  1.8989e-04,  2.0906e-04,\n",
      "         2.8009e-04, -3.7829e-04,  6.8773e-04, -5.5401e-05,  2.8288e-04,\n",
      "        -2.8342e-04,  2.1136e-04, -6.1059e-05, -5.6090e-05, -4.2540e-04,\n",
      "         1.3204e-04, -2.0954e-04,  2.0498e-04,  5.6536e-04, -5.9475e-04,\n",
      "        -2.6611e-04,  1.5154e-04,  4.3607e-04, -5.2208e-05,  3.6666e-04,\n",
      "         1.6987e-03, -5.7684e-05, -4.1944e-04,  1.1044e-04, -4.0605e-05,\n",
      "         2.3345e-04, -6.2931e-04,  6.9503e-06, -2.9242e-04, -4.6867e-05,\n",
      "         1.5925e-04, -1.6089e-04, -6.3236e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[-1.1507e-05,  2.0378e-05,  5.2418e-05,  ..., -1.1779e-05,\n",
      "         -4.2286e-05,  2.0368e-05],\n",
      "        [ 1.2859e-05, -1.2239e-04,  2.3852e-05,  ...,  4.3044e-05,\n",
      "          1.2875e-05,  2.7419e-05],\n",
      "        [ 3.8210e-06,  2.4037e-05, -4.8031e-05,  ..., -1.7014e-05,\n",
      "         -1.4338e-05, -9.1750e-06],\n",
      "        [ 1.5332e-05,  7.7747e-05,  2.0643e-05,  ...,  1.4999e-05,\n",
      "          4.9863e-05,  1.7436e-05],\n",
      "        [-2.0505e-05,  2.2547e-07, -4.8881e-05,  ..., -2.9248e-05,\n",
      "         -6.1139e-06, -5.6046e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([ 1.0919e-04,  1.3626e-04, -3.0579e-05, -3.2717e-04,  1.1232e-04],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "tensor([[[[-3.4917e-05, -1.1537e-05,  1.4615e-05],\n",
      "          [ 1.1105e-05,  2.0244e-05,  3.9047e-05],\n",
      "          [ 2.4627e-05,  4.5108e-05,  3.4644e-05]],\n",
      "\n",
      "         [[-2.6621e-04, -2.6124e-04, -2.2719e-04],\n",
      "          [-2.2340e-04, -2.2306e-04, -2.0734e-04],\n",
      "          [-2.0252e-04, -1.8520e-04, -1.9892e-04]],\n",
      "\n",
      "         [[-3.3091e-04, -3.3815e-04, -3.2518e-04],\n",
      "          [-2.6238e-04, -2.7369e-04, -2.7601e-04],\n",
      "          [-2.3772e-04, -2.4305e-04, -2.6276e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.4226e-03, -1.6420e-03, -1.5027e-03],\n",
      "          [-1.2803e-03, -1.4269e-03, -1.6036e-03],\n",
      "          [-1.5797e-03, -1.1092e-03, -9.4961e-04]],\n",
      "\n",
      "         [[-3.8595e-03, -4.1543e-03, -3.9349e-03],\n",
      "          [-3.4453e-03, -3.6642e-03, -3.9021e-03],\n",
      "          [-3.6066e-03, -3.2780e-03, -3.3984e-03]],\n",
      "\n",
      "         [[-7.2722e-04, -1.4654e-03, -1.0830e-03],\n",
      "          [ 1.2494e-04, -4.6414e-04, -7.0599e-04],\n",
      "          [-2.7548e-04, -1.0626e-05, -1.5839e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0184e-04,  1.0055e-03,  1.1509e-03],\n",
      "          [ 7.7125e-04,  7.3808e-04,  3.4339e-04],\n",
      "          [ 5.7589e-04,  6.6414e-04,  2.9029e-04]],\n",
      "\n",
      "         [[ 9.1724e-04,  8.2312e-04,  8.7451e-04],\n",
      "          [ 8.1101e-04,  6.1442e-04,  2.0285e-04],\n",
      "          [ 6.6512e-04,  6.0654e-04,  2.7029e-04]],\n",
      "\n",
      "         [[ 9.3136e-04,  1.1413e-03,  1.4166e-03],\n",
      "          [ 6.2664e-04,  6.4298e-04,  5.5600e-04],\n",
      "          [ 5.4162e-04,  4.7119e-04,  4.2138e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.7952e-04, -6.2544e-04, -5.7239e-04],\n",
      "          [-4.1976e-04, -4.5807e-04, -1.8011e-04],\n",
      "          [-2.4170e-04, -3.0922e-04, -1.5370e-04]],\n",
      "\n",
      "         [[ 1.3445e-03,  1.0841e-03,  1.0631e-03],\n",
      "          [ 1.2111e-03,  1.1904e-03,  1.3614e-03],\n",
      "          [ 1.2663e-03,  1.3010e-03,  1.3866e-03]],\n",
      "\n",
      "         [[ 1.5269e-03,  1.2963e-03,  1.2455e-03],\n",
      "          [ 1.4409e-03,  1.4929e-03,  1.6678e-03],\n",
      "          [ 1.4529e-03,  1.5712e-03,  1.7320e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0679e-04,  6.6051e-04,  6.6968e-04],\n",
      "          [ 6.4436e-04,  5.8743e-04,  6.1132e-04],\n",
      "          [ 6.0712e-04,  5.7572e-04,  6.5375e-04]],\n",
      "\n",
      "         [[ 3.1805e-04,  2.1109e-04,  2.0879e-04],\n",
      "          [ 2.5308e-04,  1.4960e-04,  1.5388e-04],\n",
      "          [ 2.0406e-04,  1.2574e-04,  1.5949e-04]],\n",
      "\n",
      "         [[ 1.7810e-04,  6.0728e-05,  2.8572e-05],\n",
      "          [ 1.6870e-04,  4.3282e-05,  1.5847e-05],\n",
      "          [ 1.7919e-04,  7.4475e-05,  6.9687e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1138e-04,  7.9267e-05,  7.7400e-05],\n",
      "          [ 9.7140e-05,  3.4395e-05,  1.8953e-06],\n",
      "          [ 1.4868e-04,  5.4269e-05,  3.6584e-05]],\n",
      "\n",
      "         [[ 4.5746e-04,  4.0417e-04,  3.8363e-04],\n",
      "          [ 4.3436e-04,  3.4739e-04,  2.9909e-04],\n",
      "          [ 4.5423e-04,  3.4170e-04,  2.9795e-04]],\n",
      "\n",
      "         [[ 5.5324e-04,  4.5897e-04,  4.2316e-04],\n",
      "          [ 5.6089e-04,  4.4269e-04,  3.8661e-04],\n",
      "          [ 6.1771e-04,  4.9215e-04,  4.4148e-04]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 4.3656e-11,  9.3132e-10,  2.9104e-11, -5.8208e-11,  0.0000e+00,\n",
      "        -1.7462e-10, -6.5484e-11,  7.2760e-11,  6.5484e-11,  2.3283e-10,\n",
      "        -8.7311e-11, -1.1642e-10,  0.0000e+00,  4.0018e-11,  4.6566e-10,\n",
      "        -1.4552e-10, -5.8208e-11,  1.4552e-11,  2.9104e-11,  0.0000e+00,\n",
      "        -7.6398e-11,  5.8208e-11,  7.2760e-12,  1.1642e-10,  6.1118e-10,\n",
      "         1.4552e-11,  6.5484e-11,  1.4552e-11, -1.7462e-10,  5.2387e-10,\n",
      "         9.3132e-10, -3.6380e-12,  2.3283e-10, -1.6298e-09,  5.4570e-11,\n",
      "        -1.7462e-10, -8.7311e-11, -1.1642e-10,  2.5466e-11, -5.2387e-10,\n",
      "         1.1642e-10, -4.6566e-10, -1.8190e-12,  1.1642e-10, -7.2760e-12,\n",
      "         1.7462e-10,  8.7311e-11,  0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 6.2587e-04, -2.7602e-07,  2.3550e-04, -7.3037e-04,  2.9371e-04,\n",
      "         1.5678e-04, -7.6474e-04, -2.1897e-05, -2.3345e-05,  1.0499e-04,\n",
      "         3.8495e-04, -2.9616e-04,  5.1594e-05,  8.4878e-05, -8.0616e-05,\n",
      "         7.2039e-04,  6.8265e-04,  1.0055e-03,  2.9205e-04,  2.2600e-05,\n",
      "         1.0454e-04,  1.5587e-04,  3.2174e-05,  4.0876e-04,  1.1586e-04,\n",
      "        -1.4781e-04, -1.6757e-04,  9.6203e-05,  5.9940e-04,  8.2805e-04,\n",
      "         3.0872e-04, -2.4895e-04,  4.7999e-04, -3.2774e-05, -3.1897e-04,\n",
      "        -1.2548e-04,  3.0529e-04,  1.0039e-04,  7.5549e-05,  2.2556e-04,\n",
      "        -2.1374e-04,  4.2124e-04, -1.0223e-04,  4.0406e-04, -4.2798e-04,\n",
      "         6.6084e-05, -7.4176e-05, -2.5831e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[[-2.2489e-05, -3.6746e-05, -3.9163e-05],\n",
      "          [-1.3992e-05, -2.9677e-05, -4.6310e-05],\n",
      "          [-8.2507e-06, -2.8114e-05, -3.1768e-05]],\n",
      "\n",
      "         [[ 5.5828e-05,  9.3610e-06, -3.8719e-05],\n",
      "          [-1.7101e-06,  1.0779e-05,  1.4279e-05],\n",
      "          [ 1.4809e-05,  2.5246e-05,  2.2903e-05]],\n",
      "\n",
      "         [[-4.4261e-05, -2.7675e-05, -3.1054e-05],\n",
      "          [ 1.7374e-05, -1.7861e-05, -1.9976e-05],\n",
      "          [-2.4383e-05, -4.0827e-06, -5.8059e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1007e-05, -3.1332e-05, -6.8754e-05],\n",
      "          [-1.5010e-06, -6.0275e-05, -5.0310e-05],\n",
      "          [-4.8493e-05, -2.8650e-05, -3.5293e-05]],\n",
      "\n",
      "         [[-6.1569e-05, -5.3148e-05, -4.0409e-05],\n",
      "          [-3.0248e-05, -3.8938e-05, -2.4891e-05],\n",
      "          [-1.7837e-05, -2.1713e-05,  3.9661e-06]],\n",
      "\n",
      "         [[-2.5902e-05, -3.7150e-05, -3.4171e-05],\n",
      "          [-1.9726e-05, -3.6064e-05, -4.0368e-05],\n",
      "          [-3.2921e-05, -4.3342e-05, -3.0312e-05]]],\n",
      "\n",
      "\n",
      "        [[[-2.7351e-05, -3.9232e-05, -3.7193e-05],\n",
      "          [-2.5040e-05, -3.8174e-05, -4.2951e-05],\n",
      "          [-3.2880e-05, -3.5348e-05, -4.9514e-05]],\n",
      "\n",
      "         [[-6.2846e-05, -5.4645e-05, -2.4463e-05],\n",
      "          [-8.9094e-05, -8.6619e-05, -1.5207e-04],\n",
      "          [-1.2018e-04, -9.7021e-05, -1.0806e-04]],\n",
      "\n",
      "         [[-9.6585e-05, -5.1231e-05, -3.3799e-05],\n",
      "          [-7.2092e-05, -7.3680e-05, -3.6539e-05],\n",
      "          [-3.5670e-05, -9.9454e-07, -3.1603e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3178e-04, -3.1317e-05, -2.6813e-05],\n",
      "          [-1.5806e-04, -2.8192e-05, -4.9280e-05],\n",
      "          [-1.2720e-04, -1.9263e-05, -2.0221e-05]],\n",
      "\n",
      "         [[-2.0502e-05, -2.5937e-05, -4.3503e-05],\n",
      "          [-1.9942e-05, -1.7481e-05, -3.8514e-05],\n",
      "          [-2.9679e-05, -2.5259e-05, -4.0480e-05]],\n",
      "\n",
      "         [[-8.1568e-05, -6.2889e-05, -6.3567e-05],\n",
      "          [-3.9624e-05, -3.6277e-05, -4.6654e-05],\n",
      "          [-3.0078e-05, -3.7486e-05, -6.4686e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7324e-05,  3.0544e-05,  2.0602e-05],\n",
      "          [ 2.8198e-05,  3.2731e-05,  2.8175e-05],\n",
      "          [ 3.2465e-05,  4.0184e-05,  3.7398e-05]],\n",
      "\n",
      "         [[ 2.8863e-04,  2.8368e-04,  1.8429e-04],\n",
      "          [ 2.1364e-04,  2.5452e-04,  1.9657e-04],\n",
      "          [ 2.2480e-04,  2.2086e-04,  1.9904e-04]],\n",
      "\n",
      "         [[ 9.3902e-05,  1.0234e-04,  7.0671e-05],\n",
      "          [ 1.4845e-04,  1.2212e-04,  7.0238e-05],\n",
      "          [ 1.2265e-04,  1.6357e-04,  1.2854e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5882e-04,  1.7855e-04,  1.3196e-04],\n",
      "          [ 1.5436e-04,  1.3848e-04,  6.5958e-05],\n",
      "          [ 1.2828e-04,  1.4671e-04,  5.1146e-05]],\n",
      "\n",
      "         [[-7.9101e-06,  1.9714e-05,  3.4735e-05],\n",
      "          [-1.9151e-05,  1.2640e-06, -6.8103e-07],\n",
      "          [-2.9530e-05, -2.2471e-05, -1.3422e-05]],\n",
      "\n",
      "         [[ 4.6678e-05,  5.5838e-05,  7.8462e-05],\n",
      "          [ 7.1799e-05,  7.9767e-05,  6.0862e-05],\n",
      "          [ 8.3778e-05,  1.0600e-04,  1.0998e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.3427e-06, -7.0694e-06,  7.8559e-06],\n",
      "          [ 1.6898e-05, -4.8521e-06,  8.3083e-06],\n",
      "          [ 2.2233e-05,  1.6368e-07,  8.5246e-06]],\n",
      "\n",
      "         [[ 1.3007e-04,  1.0045e-04,  1.4866e-04],\n",
      "          [ 5.1437e-05,  1.0440e-04,  5.1078e-05],\n",
      "          [ 2.2903e-05,  1.4822e-04,  1.2951e-07]],\n",
      "\n",
      "         [[-1.7147e-06,  1.0166e-06, -3.8028e-06],\n",
      "          [-2.2251e-05, -7.8746e-06, -8.4964e-06],\n",
      "          [-7.2237e-06,  1.6676e-05, -2.6762e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2748e-05,  5.2528e-05,  8.1816e-05],\n",
      "          [ 2.8278e-05,  8.2305e-05,  3.9337e-05],\n",
      "          [ 1.3161e-05,  9.3669e-05, -9.4492e-06]],\n",
      "\n",
      "         [[ 4.7873e-05,  2.8239e-05,  3.9462e-05],\n",
      "          [ 3.0733e-05,  1.8909e-05,  3.7004e-05],\n",
      "          [ 4.0922e-05,  2.4240e-05,  2.5867e-05]],\n",
      "\n",
      "         [[ 2.7768e-05,  1.2417e-06,  1.5585e-05],\n",
      "          [ 2.3354e-05, -1.9138e-05,  2.4016e-06],\n",
      "          [ 5.3768e-05,  2.6874e-05,  3.4036e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.2300e-06,  2.6181e-06, -2.2364e-06],\n",
      "          [ 6.1544e-06, -7.2485e-07,  1.5014e-06],\n",
      "          [ 2.5687e-06,  2.1796e-06, -1.5139e-06]],\n",
      "\n",
      "         [[-3.9461e-05, -9.8849e-05, -1.8188e-05],\n",
      "          [-4.2715e-05, -6.9120e-05, -8.7319e-06],\n",
      "          [-5.1456e-05,  5.5081e-06,  1.6501e-05]],\n",
      "\n",
      "         [[-3.7925e-05, -4.7843e-06, -2.1334e-05],\n",
      "          [ 7.0437e-07,  1.0445e-06,  1.1155e-05],\n",
      "          [ 4.0175e-06, -1.4813e-06,  4.9024e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8644e-05, -1.3064e-04, -4.3142e-05],\n",
      "          [-6.3843e-05, -9.6786e-05,  9.7481e-06],\n",
      "          [-2.6972e-05, -7.3963e-05,  2.6401e-05]],\n",
      "\n",
      "         [[-5.1230e-05, -4.0852e-05, -3.3190e-05],\n",
      "          [-4.0703e-05, -3.5477e-05, -2.7852e-05],\n",
      "          [-5.0282e-05, -3.2895e-05, -2.8351e-05]],\n",
      "\n",
      "         [[-2.3302e-05, -1.5434e-05, -2.2394e-05],\n",
      "          [ 9.5144e-07, -6.2371e-06, -1.3369e-05],\n",
      "          [-3.1932e-06, -8.9855e-06, -1.0575e-05]]],\n",
      "\n",
      "\n",
      "        [[[-2.4542e-05, -1.8946e-05, -2.5220e-05],\n",
      "          [-3.0425e-05, -2.2967e-05, -2.8467e-05],\n",
      "          [-2.0349e-05, -2.9832e-05, -1.9133e-05]],\n",
      "\n",
      "         [[ 5.6786e-05,  4.1023e-05,  3.8635e-05],\n",
      "          [ 5.8699e-05,  8.8326e-06,  3.4629e-05],\n",
      "          [ 1.1009e-04,  4.4210e-05,  1.2935e-04]],\n",
      "\n",
      "         [[ 9.0133e-06, -7.8236e-06,  9.7670e-08],\n",
      "          [ 1.5517e-05, -6.1888e-07,  2.4385e-05],\n",
      "          [-1.4634e-05,  2.6942e-06,  3.2330e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8967e-05, -2.8979e-05,  4.2857e-05],\n",
      "          [ 5.3723e-05, -3.3350e-05,  2.2890e-05],\n",
      "          [ 1.2133e-05, -8.7011e-06,  1.6461e-05]],\n",
      "\n",
      "         [[-4.4114e-05, -4.9131e-05, -4.1179e-05],\n",
      "          [-5.0836e-05, -4.0419e-05, -3.9595e-05],\n",
      "          [-3.2459e-05, -4.9780e-05, -2.4341e-05]],\n",
      "\n",
      "         [[ 9.6891e-06, -3.4464e-06,  7.2012e-07],\n",
      "          [ 1.7028e-06,  2.8837e-06,  1.6524e-05],\n",
      "          [ 5.9011e-06, -7.5949e-06,  1.2132e-05]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-4.0430e-04, -7.7982e-04, -5.7154e-04, -2.4669e-04,  1.7359e-03,\n",
      "        -3.3120e-04,  1.5798e-03,  3.4515e-04, -1.0750e-03,  7.7806e-04,\n",
      "        -6.2691e-05,  4.1159e-04,  1.5853e-04,  1.1671e-04,  7.5369e-04,\n",
      "        -1.1645e-03, -4.0697e-04, -4.6419e-04,  1.2515e-04,  5.7947e-04,\n",
      "         6.5515e-04,  1.4341e-04,  2.0156e-04,  9.3604e-05,  4.6424e-04,\n",
      "         3.4086e-04,  2.0062e-04, -3.9254e-04,  6.9361e-05,  1.0238e-03,\n",
      "         1.8599e-04,  5.3030e-04, -9.8925e-04,  8.4203e-04,  9.7558e-04,\n",
      "         5.6896e-04,  1.7187e-04, -2.1795e-04,  2.9157e-04,  8.7149e-04,\n",
      "         3.7356e-04, -2.7490e-04, -8.8755e-04,  7.0070e-04, -5.2065e-04,\n",
      "        -1.4944e-03,  5.7843e-04,  9.3796e-05], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-4.0231e-04, -1.7885e-03, -4.7121e-04, -8.6035e-04,  2.1428e-03,\n",
      "        -4.6660e-04,  1.4596e-03,  3.0495e-04, -1.3174e-03,  1.2469e-03,\n",
      "         7.6444e-04, -2.3007e-04,  4.5182e-04, -1.8899e-04,  5.0392e-04,\n",
      "        -1.7112e-03, -7.0016e-04, -2.8297e-04, -2.2448e-04,  5.7872e-04,\n",
      "         1.1302e-03, -2.7098e-04,  5.6011e-04,  1.0831e-03,  6.1797e-04,\n",
      "        -4.1623e-04,  5.9107e-04, -3.6361e-04, -5.0113e-04,  7.1982e-04,\n",
      "        -1.3387e-04,  4.3151e-04, -1.1212e-03,  8.3127e-04,  4.8987e-04,\n",
      "        -1.5630e-04, -2.4395e-04,  3.3494e-04, -9.1519e-06,  1.2099e-03,\n",
      "         2.9858e-04,  1.4593e-04, -7.7082e-04,  5.4610e-04, -4.8953e-04,\n",
      "        -3.0460e-03,  1.6131e-04, -2.0418e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "tensor([[[[-1.6497e-06, -3.8985e-06, -2.1865e-06],\n",
      "          [-2.1750e-06, -3.2860e-06, -5.6074e-07],\n",
      "          [-1.6220e-06, -1.3743e-06,  1.3738e-06]],\n",
      "\n",
      "         [[-9.0583e-06, -1.1887e-05, -1.2435e-05],\n",
      "          [-9.7123e-06, -1.1520e-05, -1.1314e-05],\n",
      "          [-9.7714e-06, -1.0330e-05, -9.6082e-06]],\n",
      "\n",
      "         [[ 3.1447e-07, -1.1559e-06, -1.5719e-06],\n",
      "          [-1.0129e-06, -2.2475e-06, -1.3395e-06],\n",
      "          [-8.0300e-07, -7.5196e-07,  6.2476e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4777e-04,  2.4736e-04,  2.3623e-04],\n",
      "          [ 2.3028e-04,  2.2690e-04,  2.2168e-04],\n",
      "          [ 2.0330e-04,  1.9157e-04,  1.7374e-04]],\n",
      "\n",
      "         [[ 3.7810e-05,  3.7842e-05,  4.5883e-05],\n",
      "          [ 4.6824e-05,  4.4101e-05,  4.6426e-05],\n",
      "          [ 3.3055e-05,  2.2979e-05,  7.5264e-07]],\n",
      "\n",
      "         [[ 1.7605e-04,  1.6873e-04,  1.6181e-04],\n",
      "          [ 1.8375e-04,  1.6312e-04,  1.5653e-04],\n",
      "          [ 1.6326e-04,  1.2688e-04,  9.8627e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.2757e-05,  1.6011e-05,  2.0230e-05],\n",
      "          [-9.9754e-06,  1.6095e-05,  1.1143e-05],\n",
      "          [-8.2686e-06,  9.2174e-06,  6.4436e-06]],\n",
      "\n",
      "         [[-1.4218e-06,  1.8465e-05,  2.5148e-05],\n",
      "          [-1.2950e-06,  2.2024e-05,  7.4399e-06],\n",
      "          [-1.2080e-05,  6.8852e-06, -1.0699e-07]],\n",
      "\n",
      "         [[ 3.4888e-05,  6.0802e-05,  6.8257e-05],\n",
      "          [ 3.0600e-05,  5.7156e-05,  4.5146e-05],\n",
      "          [ 1.3778e-05,  3.6255e-05,  3.4658e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5730e-04, -1.5994e-04, -1.5838e-04],\n",
      "          [-1.6441e-04, -1.6734e-04, -1.6850e-04],\n",
      "          [-1.6046e-04, -1.6221e-04, -1.6379e-04]],\n",
      "\n",
      "         [[ 2.7446e-05,  3.7066e-05,  3.8558e-05],\n",
      "          [ 3.4293e-05,  4.5690e-05,  4.8319e-05],\n",
      "          [ 4.1691e-05,  5.0529e-05,  5.0330e-05]],\n",
      "\n",
      "         [[-4.0072e-05, -3.0052e-05, -2.7440e-05],\n",
      "          [-2.9008e-05, -1.6410e-05, -1.5815e-05],\n",
      "          [-1.8820e-05, -8.3905e-06, -1.6217e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1562e-04,  1.1649e-04,  1.0476e-04],\n",
      "          [ 1.1449e-04,  1.1590e-04,  1.0058e-04],\n",
      "          [ 1.0843e-04,  1.0908e-04,  9.6974e-05]],\n",
      "\n",
      "         [[ 3.7176e-05,  3.5311e-05,  2.6373e-05],\n",
      "          [ 3.5601e-05,  3.1489e-05,  1.4886e-05],\n",
      "          [ 2.8883e-05,  2.3132e-05,  9.7532e-06]],\n",
      "\n",
      "         [[ 2.4651e-05,  2.2367e-05,  1.5161e-05],\n",
      "          [ 2.0014e-05,  1.6019e-05,  4.3091e-06],\n",
      "          [ 1.3829e-05,  9.2287e-06,  1.3623e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8011e-05,  1.9315e-05,  1.8120e-05],\n",
      "          [ 2.2992e-05,  2.5170e-05,  2.3771e-05],\n",
      "          [ 3.0503e-05,  3.0913e-05,  3.0538e-05]],\n",
      "\n",
      "         [[ 1.2003e-05,  1.2669e-05,  1.0281e-05],\n",
      "          [ 1.6374e-05,  1.6951e-05,  1.3665e-05],\n",
      "          [ 2.4807e-05,  2.2537e-05,  2.0055e-05]],\n",
      "\n",
      "         [[ 1.5644e-05,  1.6278e-05,  1.2695e-05],\n",
      "          [ 2.1777e-05,  2.1570e-05,  1.8304e-05],\n",
      "          [ 3.2633e-05,  3.0515e-05,  2.7561e-05]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[[ 1.7152e-07,  5.6473e-09, -5.4257e-08],\n",
      "          [ 3.7580e-07,  3.3952e-07,  6.2275e-07],\n",
      "          [ 6.4358e-07,  1.0921e-06,  7.4923e-07]],\n",
      "\n",
      "         [[ 2.6930e-06, -2.9793e-06,  4.2096e-06],\n",
      "          [ 1.7447e-06,  2.2615e-06,  6.9990e-06],\n",
      "          [ 9.1158e-06,  1.4213e-05,  2.5216e-06]],\n",
      "\n",
      "         [[ 4.9152e-07, -1.8924e-06,  7.7065e-07],\n",
      "          [ 2.1847e-06,  4.7232e-07,  1.2700e-07],\n",
      "          [ 2.6363e-06, -2.9681e-08,  1.7635e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7337e-07,  7.6506e-07,  1.1922e-06],\n",
      "          [ 8.0221e-06,  1.2793e-06,  5.6986e-06],\n",
      "          [ 1.4015e-05,  2.3442e-06,  6.3900e-06]],\n",
      "\n",
      "         [[-6.2996e-06, -3.4524e-06, -5.6236e-06],\n",
      "          [-6.0614e-06, -6.9406e-06, -7.3236e-06],\n",
      "          [-7.4756e-06, -6.8256e-06, -5.4834e-06]],\n",
      "\n",
      "         [[ 1.7476e-08, -9.5773e-07, -2.7988e-06],\n",
      "          [-1.5854e-07, -2.4304e-06, -3.3219e-06],\n",
      "          [-1.1105e-06, -1.8046e-06, -1.2763e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.2279e-06, -1.3731e-06, -1.2340e-06],\n",
      "          [-1.0639e-06, -7.7914e-07,  1.6156e-08],\n",
      "          [-7.3566e-07, -8.1400e-08,  5.9127e-07]],\n",
      "\n",
      "         [[ 3.8635e-06,  6.5675e-06, -1.3579e-06],\n",
      "          [ 5.5811e-06,  2.4098e-06,  6.8505e-07],\n",
      "          [ 6.3865e-06,  3.9077e-06,  6.3202e-06]],\n",
      "\n",
      "         [[ 3.9512e-06,  5.7456e-07, -1.8482e-06],\n",
      "          [ 7.9446e-07, -5.2568e-07, -2.5038e-06],\n",
      "          [ 2.6199e-06,  1.2324e-06, -1.0274e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1883e-05,  1.0562e-05,  4.1003e-06],\n",
      "          [ 1.4198e-05,  1.2675e-05,  1.7457e-06],\n",
      "          [ 1.1746e-05,  1.2897e-05,  1.5188e-06]],\n",
      "\n",
      "         [[-9.3583e-07, -6.6656e-08,  3.3224e-06],\n",
      "          [-1.9549e-06, -5.1862e-07,  2.3889e-06],\n",
      "          [-1.4034e-06, -9.0506e-07,  2.9038e-06]],\n",
      "\n",
      "         [[ 2.0660e-06, -6.4099e-07,  5.8309e-07],\n",
      "          [-9.7646e-07, -1.6273e-06, -1.0925e-06],\n",
      "          [-8.2477e-07, -9.5809e-07,  1.9149e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4429e-07,  5.7916e-07,  8.6313e-07],\n",
      "          [ 2.5819e-07,  5.5164e-07,  6.9694e-07],\n",
      "          [ 5.5488e-07,  9.4513e-07,  5.6984e-07]],\n",
      "\n",
      "         [[-5.2056e-06, -2.5761e-06, -8.3313e-06],\n",
      "          [-2.6693e-06, -6.1815e-06, -8.0195e-06],\n",
      "          [-3.7184e-06, -5.4055e-06, -6.8646e-06]],\n",
      "\n",
      "         [[-2.7969e-06, -4.2422e-06, -3.0273e-06],\n",
      "          [-4.6546e-06, -2.3911e-06, -2.5335e-06],\n",
      "          [-2.8172e-06, -4.5267e-06, -4.3324e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0664e-06, -2.1464e-06, -3.9811e-06],\n",
      "          [-1.1517e-06, -5.4685e-06, -5.1179e-06],\n",
      "          [-1.2033e-06, -6.5213e-06, -2.3229e-06]],\n",
      "\n",
      "         [[-2.0665e-06, -1.9214e-06, -1.8275e-06],\n",
      "          [-1.2905e-06, -1.3088e-06, -1.3016e-06],\n",
      "          [-2.2982e-06, -1.1595e-06, -2.8168e-06]],\n",
      "\n",
      "         [[-6.9728e-07, -6.8589e-07, -2.3687e-07],\n",
      "          [-7.1610e-07, -6.7230e-07,  2.1071e-07],\n",
      "          [-1.6325e-06, -7.6215e-07, -1.7049e-06]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.6650e-06,  4.3290e-06,  3.5983e-06],\n",
      "          [ 4.1665e-06,  3.7330e-06,  4.0316e-06],\n",
      "          [ 2.9269e-06,  2.3892e-06,  3.6131e-06]],\n",
      "\n",
      "         [[ 1.3078e-05,  5.2069e-06,  3.0580e-06],\n",
      "          [-1.6694e-06,  5.8789e-06,  1.4996e-07],\n",
      "          [-1.4096e-06,  7.6184e-06,  1.0721e-06]],\n",
      "\n",
      "         [[ 8.7570e-07,  8.4753e-07,  2.8598e-06],\n",
      "          [ 3.6454e-06,  4.2071e-06,  9.3493e-07],\n",
      "          [ 7.7730e-07,  2.9398e-06,  4.7976e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5594e-06,  8.9921e-06,  7.8561e-06],\n",
      "          [-4.2672e-07,  9.2622e-06,  7.8677e-08],\n",
      "          [ 1.0451e-07,  1.0374e-05, -4.4104e-06]],\n",
      "\n",
      "         [[-1.5410e-05, -2.0609e-05, -2.1441e-05],\n",
      "          [-1.4370e-05, -1.9517e-05, -1.8966e-05],\n",
      "          [-1.2816e-05, -1.8965e-05, -1.7417e-05]],\n",
      "\n",
      "         [[ 7.6511e-06,  5.5787e-06,  2.4348e-06],\n",
      "          [ 9.8819e-06,  5.1089e-06,  6.0973e-06],\n",
      "          [ 6.4158e-06,  4.0545e-06,  6.5237e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.0604e-07, -7.7560e-07, -1.0952e-07],\n",
      "          [ 9.3161e-08, -7.0643e-07, -3.8050e-07],\n",
      "          [-2.5905e-07, -9.6984e-07,  1.2858e-07]],\n",
      "\n",
      "         [[ 4.3380e-07, -1.6745e-07,  3.6350e-07],\n",
      "          [-3.2733e-06, -2.3456e-06,  3.6099e-06],\n",
      "          [-4.2112e-06,  2.6995e-08,  4.4602e-06]],\n",
      "\n",
      "         [[-1.7537e-06, -1.7225e-06,  1.7155e-06],\n",
      "          [-8.5936e-07, -7.8005e-07,  1.6986e-06],\n",
      "          [ 2.6655e-07, -1.1409e-06,  7.4266e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0746e-06, -3.7071e-06, -4.6736e-07],\n",
      "          [-5.1388e-06, -5.6861e-06,  1.3261e-06],\n",
      "          [-5.0070e-06, -3.3327e-06,  2.0171e-06]],\n",
      "\n",
      "         [[-2.2249e-06, -5.2712e-07,  2.0723e-06],\n",
      "          [ 1.2282e-06,  4.3981e-07,  7.5661e-07],\n",
      "          [-2.9432e-07, -1.0633e-06,  6.1919e-08]],\n",
      "\n",
      "         [[-7.4356e-07,  1.4171e-07,  2.2250e-06],\n",
      "          [ 1.0808e-08, -2.5127e-07, -2.3469e-07],\n",
      "          [-6.7452e-07, -2.2721e-06, -1.6209e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.6440e-07,  9.4298e-08,  8.5305e-08],\n",
      "          [ 7.1050e-08, -3.7692e-07, -6.9897e-07],\n",
      "          [ 2.4403e-07, -6.2488e-07, -9.0060e-07]],\n",
      "\n",
      "         [[ 6.8152e-06,  2.7889e-06,  2.9199e-06],\n",
      "          [ 6.7958e-06,  4.1218e-06,  7.0274e-06],\n",
      "          [ 6.9972e-06,  7.0613e-06,  7.6226e-06]],\n",
      "\n",
      "         [[ 1.4218e-06,  4.8150e-06,  1.9908e-06],\n",
      "          [ 1.5918e-06,  2.1303e-06,  1.3428e-06],\n",
      "          [ 4.7691e-07,  2.0872e-06,  1.8650e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6082e-06,  4.7824e-06,  4.6259e-06],\n",
      "          [ 1.7594e-06,  5.2898e-06,  6.8925e-06],\n",
      "          [ 1.7152e-06,  5.6962e-06,  8.4264e-06]],\n",
      "\n",
      "         [[ 4.8902e-06,  6.8055e-06,  8.8265e-06],\n",
      "          [ 6.6092e-06,  8.2396e-06,  1.0012e-05],\n",
      "          [ 7.2785e-06,  9.9812e-06,  1.2761e-05]],\n",
      "\n",
      "         [[ 1.1671e-06,  2.1515e-06,  2.6396e-06],\n",
      "          [ 6.9612e-07,  1.4079e-06,  1.1800e-06],\n",
      "          [ 5.9946e-07,  5.7182e-07,  6.7896e-07]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-1.9279e-06,  3.3617e-05,  2.1112e-05,  2.3372e-05,  6.1152e-05,\n",
      "         1.7372e-05,  2.8880e-05, -1.6576e-05,  3.1114e-05,  1.9826e-05,\n",
      "         4.5183e-06, -3.3640e-05,  8.2187e-06, -1.0324e-05,  9.3473e-06,\n",
      "         7.3704e-06, -7.5871e-06, -5.3804e-05, -2.5334e-05,  9.3931e-06,\n",
      "         4.0193e-05, -3.6659e-05,  4.9666e-05,  4.0264e-05,  3.3226e-05,\n",
      "        -3.2573e-06, -6.8375e-06, -4.5405e-05,  5.9538e-05, -8.5585e-06,\n",
      "         3.0396e-05, -1.4318e-05, -1.3231e-05, -2.8535e-06,  9.9569e-06,\n",
      "        -1.3143e-04,  9.9372e-05,  3.2144e-05,  4.9933e-06,  4.3320e-06,\n",
      "         4.5407e-05, -1.3047e-05,  7.6164e-06, -3.2701e-05, -7.8845e-06,\n",
      "        -7.2666e-05,  2.1687e-05, -2.0903e-06], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-3.6044e-06,  6.0722e-05,  2.7407e-06,  3.2262e-05,  5.8537e-05,\n",
      "         2.9882e-05,  2.5072e-05,  6.6766e-06,  3.7391e-05,  2.4403e-05,\n",
      "         3.6889e-05, -5.7559e-05, -4.6293e-06, -5.3367e-05,  1.5083e-06,\n",
      "        -1.1033e-05, -3.1853e-05, -1.1230e-04, -7.0825e-06,  2.8471e-07,\n",
      "         5.1366e-06, -2.2389e-05,  7.0037e-05,  6.5789e-05,  2.3970e-05,\n",
      "        -1.2508e-05,  1.8706e-05, -5.2991e-05,  3.9278e-05,  5.3848e-06,\n",
      "         7.5103e-05, -3.5745e-05, -2.7577e-05, -1.7797e-06, -1.5508e-05,\n",
      "        -8.9158e-05,  1.1373e-04,  3.4303e-05, -6.1072e-05,  4.5270e-05,\n",
      "         3.6721e-05,  2.7946e-07,  9.7958e-06, -2.9015e-05, -2.0632e-05,\n",
      "        -1.9152e-04,  2.0600e-05,  2.9604e-06], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "tensor([ 1.0979e-03,  1.3386e-03, -8.8086e-05, -8.9596e-04,  2.8153e-05,\n",
      "         3.1919e-03, -6.9175e-04,  2.1102e-04,  2.1020e-04, -4.2501e-04,\n",
      "         5.3951e-04, -2.0397e-03, -6.5712e-04, -5.8342e-05,  3.3672e-04,\n",
      "         4.2728e-04,  1.8769e-03, -1.7465e-04,  6.5806e-04,  1.8888e-03,\n",
      "        -1.8467e-05,  1.1545e-03, -2.9178e-04,  1.3485e-04, -1.0458e-04,\n",
      "         1.4504e-03,  2.9934e-04,  8.6184e-04,  7.1668e-04, -3.1803e-04,\n",
      "        -2.1399e-03, -7.4732e-04, -6.1439e-04, -1.7449e-03, -1.8661e-05,\n",
      "        -1.0460e-03,  3.2810e-05,  2.9308e-04, -1.3606e-04, -9.3960e-04,\n",
      "        -7.2132e-04, -6.7910e-04, -1.2536e-03, -7.8910e-04, -5.0308e-04,\n",
      "         4.7772e-04,  2.2629e-03,  4.8201e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 2.3728e-03,  2.0513e-03,  9.0254e-04, -2.0561e-03, -1.7456e-04,\n",
      "         2.0361e-03, -2.3469e-03, -1.0461e-03, -9.7431e-04, -2.0065e-03,\n",
      "         1.8610e-03, -2.7843e-03, -6.3194e-04, -3.3738e-05, -4.8663e-03,\n",
      "         4.8054e-04,  4.0006e-03,  5.4502e-04,  7.8213e-04,  2.2073e-03,\n",
      "        -2.0047e-04,  1.2761e-03, -1.0754e-03, -1.7963e-03,  5.5780e-04,\n",
      "         2.1108e-03, -2.1497e-04,  9.2507e-04,  9.8236e-04, -3.4377e-03,\n",
      "         2.4778e-03, -1.2185e-03, -1.2341e-03, -1.0895e-03,  4.5071e-04,\n",
      "         4.6520e-04,  7.6734e-04,  1.1194e-03, -4.6703e-04, -1.2810e-03,\n",
      "        -2.4181e-04,  2.4640e-03, -1.8644e-03,  1.4681e-05, -1.0731e-03,\n",
      "         6.5772e-04,  2.6342e-03,  7.7362e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([-1.1480e-03, -7.0168e-04,  8.2237e-05,  1.2426e-03, -1.2436e-04,\n",
      "        -9.3544e-04, -1.7958e-04,  2.7128e-03,  1.7829e-03, -2.3077e-04,\n",
      "         3.3957e-04,  2.8963e-03,  2.7133e-03, -7.0414e-04, -9.8282e-04,\n",
      "         8.6819e-04,  9.3206e-04, -8.6333e-04, -2.8783e-03, -5.4890e-04,\n",
      "         4.1642e-03, -1.2527e-03,  6.3929e-04,  1.5488e-03, -2.3353e-03,\n",
      "        -7.1352e-04,  1.0815e-04,  1.0895e-04,  1.5421e-03, -4.2380e-04,\n",
      "         1.3901e-03, -8.3777e-04, -1.2718e-03,  1.5989e-03,  7.1409e-04,\n",
      "        -4.2755e-03, -8.6486e-04, -4.3837e-04, -8.5579e-04,  1.2259e-03,\n",
      "        -9.9148e-04,  4.3176e-03,  1.0699e-03, -5.6379e-04,  1.6581e-03,\n",
      "        -5.0703e-03, -8.6515e-04,  6.0708e-04], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[[ 4.9940e-05,  3.7675e-05,  7.9942e-06],\n",
      "          [ 5.9443e-05,  5.6944e-05,  1.8496e-05],\n",
      "          [ 5.3779e-05,  8.4514e-05,  1.3168e-04]],\n",
      "\n",
      "         [[-2.6326e-05,  9.0885e-05,  1.4808e-04],\n",
      "          [ 4.1269e-05,  4.9059e-05,  1.0424e-04],\n",
      "          [ 2.6126e-05,  9.6225e-05,  2.2710e-04]],\n",
      "\n",
      "         [[-1.1389e-04, -1.7687e-04, -1.2370e-04],\n",
      "          [-1.7320e-05, -2.8759e-05, -5.8443e-05],\n",
      "          [ 2.3742e-05, -6.5490e-05, -2.0218e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.8047e-05,  6.6192e-05,  1.0882e-04],\n",
      "          [-1.4131e-05,  9.0113e-05,  9.5271e-05],\n",
      "          [-7.9856e-05,  5.4334e-06,  2.0050e-05]],\n",
      "\n",
      "         [[-7.9620e-07,  2.8085e-05, -1.0515e-04],\n",
      "          [ 1.4292e-05,  5.7816e-05, -2.2535e-05],\n",
      "          [-4.6133e-06, -1.6580e-05, -1.1193e-04]],\n",
      "\n",
      "         [[-2.2402e-04,  1.1666e-04,  1.3576e-04],\n",
      "          [-1.2106e-04,  1.1522e-04,  2.3248e-04],\n",
      "          [-1.5247e-04,  5.0217e-05,  2.8451e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4983e-05,  8.2821e-06,  9.0626e-06],\n",
      "          [ 4.7546e-05, -4.1692e-05, -7.8633e-07],\n",
      "          [ 1.1063e-04, -8.8576e-06,  4.3593e-05]],\n",
      "\n",
      "         [[-1.4525e-04,  7.0225e-06,  7.0209e-07],\n",
      "          [-1.8249e-04,  7.7038e-05,  2.9261e-05],\n",
      "          [-2.4825e-04,  3.9640e-05, -6.9023e-05]],\n",
      "\n",
      "         [[ 1.9993e-05, -2.9302e-05, -1.8658e-04],\n",
      "          [ 2.1120e-04,  1.0597e-04,  7.2320e-05],\n",
      "          [ 5.2284e-04,  3.3902e-04,  2.7534e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6503e-05, -5.9310e-05, -8.4219e-05],\n",
      "          [ 2.6713e-05, -4.1223e-05,  2.5784e-05],\n",
      "          [ 2.5015e-04,  1.8764e-04,  3.0825e-04]],\n",
      "\n",
      "         [[-7.4859e-05, -1.3536e-04, -7.3365e-05],\n",
      "          [ 1.2877e-04, -5.2387e-05,  1.0759e-04],\n",
      "          [ 1.4217e-04, -1.4748e-05,  1.0022e-04]],\n",
      "\n",
      "         [[-2.0380e-04,  5.7627e-05,  8.1542e-05],\n",
      "          [-2.0858e-04,  4.2012e-05,  1.5303e-04],\n",
      "          [-4.3449e-04, -4.8774e-05,  2.0781e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7474e-05,  3.3612e-05,  1.0997e-04],\n",
      "          [ 9.2565e-05,  1.7205e-04,  1.4151e-04],\n",
      "          [ 1.0649e-04,  1.3033e-04,  1.8862e-04]],\n",
      "\n",
      "         [[-9.2481e-05, -1.3974e-05, -8.2078e-06],\n",
      "          [-1.9438e-04, -1.5292e-04,  4.5567e-05],\n",
      "          [-1.1292e-04, -1.2295e-04,  1.8154e-04]],\n",
      "\n",
      "         [[-9.1854e-05,  1.4343e-05,  2.4886e-05],\n",
      "          [-2.2155e-05, -6.0609e-05, -1.0976e-04],\n",
      "          [ 1.5850e-04,  7.2731e-06,  1.2489e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6369e-05,  1.4800e-04,  1.4310e-04],\n",
      "          [ 5.9616e-05,  1.1524e-04,  3.1243e-04],\n",
      "          [ 2.2621e-04,  1.9666e-04,  3.1347e-04]],\n",
      "\n",
      "         [[-1.0717e-06,  1.3529e-04,  5.2938e-05],\n",
      "          [-2.9624e-04, -7.0505e-05, -7.9142e-05],\n",
      "          [-4.2940e-05,  2.5265e-04,  3.1264e-04]],\n",
      "\n",
      "         [[-3.7961e-04, -7.9736e-05, -1.8802e-04],\n",
      "          [-3.4304e-04, -1.0721e-04,  1.0868e-04],\n",
      "          [-3.4840e-04, -1.3585e-04,  3.5294e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.5253e-05, -5.1681e-06, -3.8711e-06],\n",
      "          [-7.9690e-05, -9.4431e-05, -7.8228e-05],\n",
      "          [-4.0422e-05, -1.7130e-04, -1.4003e-04]],\n",
      "\n",
      "         [[-1.4639e-04, -7.9710e-05, -7.7458e-05],\n",
      "          [-1.4468e-04, -1.0057e-04, -1.8797e-04],\n",
      "          [-7.6631e-05, -9.7302e-05, -1.1937e-04]],\n",
      "\n",
      "         [[-2.1213e-05, -1.9879e-05, -5.8962e-05],\n",
      "          [ 1.9042e-05, -3.1761e-05,  4.0019e-05],\n",
      "          [-1.0091e-04, -8.5421e-05, -4.7370e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5533e-04, -1.7826e-04, -1.9180e-04],\n",
      "          [-1.9261e-04, -1.8329e-04, -1.7058e-04],\n",
      "          [-2.2402e-04, -1.5523e-04, -8.0753e-05]],\n",
      "\n",
      "         [[ 1.4782e-04,  1.3827e-04,  1.3141e-04],\n",
      "          [ 2.0326e-06, -6.1337e-05,  1.2745e-04],\n",
      "          [-6.5009e-05, -1.0875e-04,  6.1566e-05]],\n",
      "\n",
      "         [[-2.3167e-05,  2.6710e-05, -7.6933e-05],\n",
      "          [-1.6653e-04, -1.1112e-04, -9.7743e-05],\n",
      "          [ 8.5722e-05, -6.2651e-05,  6.9409e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8684e-04,  3.2883e-04,  2.9120e-04],\n",
      "          [ 6.6930e-04,  4.0394e-04,  5.1940e-04],\n",
      "          [ 3.6028e-04,  1.2795e-04,  3.8751e-04]],\n",
      "\n",
      "         [[ 8.3016e-05,  6.1596e-05,  1.2157e-04],\n",
      "          [ 2.3402e-04,  6.4070e-06,  3.3511e-04],\n",
      "          [-4.9221e-05,  2.6428e-05,  2.1399e-04]],\n",
      "\n",
      "         [[ 1.7518e-04,  2.0575e-04,  1.0942e-04],\n",
      "          [ 7.0364e-04,  5.2787e-04,  5.4335e-04],\n",
      "          [ 1.9719e-04,  8.3394e-05,  3.7580e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9403e-04,  4.6101e-04,  5.1730e-04],\n",
      "          [ 5.7144e-04,  6.3749e-04,  8.3328e-04],\n",
      "          [ 1.1971e-03,  1.1594e-03,  1.3989e-03]],\n",
      "\n",
      "         [[ 2.1309e-05,  2.6063e-04,  2.9099e-04],\n",
      "          [ 2.5158e-04,  2.8217e-04,  3.7929e-04],\n",
      "          [ 3.2135e-05, -1.2537e-04,  1.1079e-04]],\n",
      "\n",
      "         [[ 1.6513e-04, -6.1569e-05,  2.4542e-04],\n",
      "          [ 3.8706e-04, -1.1716e-04,  4.9821e-04],\n",
      "          [ 4.4328e-04,  5.9371e-05,  8.9789e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3521e-04,  1.3923e-04,  1.3357e-04],\n",
      "          [ 1.0149e-05,  1.1754e-04,  8.4212e-05],\n",
      "          [ 2.0373e-04,  1.3072e-04,  1.0188e-04]],\n",
      "\n",
      "         [[-8.6965e-05,  2.3307e-06,  4.2490e-06],\n",
      "          [-6.2856e-05,  2.8541e-06, -5.7498e-05],\n",
      "          [-1.1523e-04,  4.5823e-06, -2.1334e-05]],\n",
      "\n",
      "         [[-3.8057e-05,  9.3431e-05,  1.6771e-04],\n",
      "          [ 7.1965e-05,  5.2060e-05, -1.0219e-04],\n",
      "          [ 8.9652e-05,  9.6963e-05, -4.2897e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4878e-04,  2.0390e-05, -6.8994e-06],\n",
      "          [-1.7964e-04, -9.4806e-05, -2.3553e-05],\n",
      "          [-1.1788e-04, -7.1302e-07, -1.7723e-05]],\n",
      "\n",
      "         [[ 6.3663e-05, -3.2682e-06, -2.9250e-06],\n",
      "          [-1.7206e-05,  7.1246e-05,  1.1371e-04],\n",
      "          [ 5.1580e-05,  5.6871e-05,  3.9747e-05]],\n",
      "\n",
      "         [[ 7.0572e-05,  4.6215e-05, -9.4373e-05],\n",
      "          [ 1.2937e-04,  4.6426e-05,  3.2278e-06],\n",
      "          [ 1.7299e-04,  5.9433e-05,  3.6535e-05]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 3.0665e-04, -2.4646e-04,  4.9742e-04,  1.0787e-03, -2.2177e-05,\n",
      "        -1.2527e-03,  1.6495e-03, -8.0941e-05,  1.6101e-03,  9.2381e-04,\n",
      "         1.4982e-03, -1.6287e-03,  1.8306e-04, -6.7889e-04,  1.2672e-03,\n",
      "         5.3576e-03, -2.6828e-04,  1.4009e-04, -1.1415e-05,  2.4279e-03,\n",
      "        -3.7677e-04, -8.5564e-04,  7.8570e-04,  6.3185e-04,  2.2853e-04,\n",
      "        -4.6472e-04,  4.3211e-04,  6.9074e-04, -4.4447e-05,  9.8824e-04,\n",
      "        -2.5972e-06,  1.4423e-03,  8.0603e-04, -1.3101e-03,  8.8075e-04,\n",
      "         1.8507e-03, -1.2371e-03, -2.9674e-03, -3.2447e-03, -1.3441e-03,\n",
      "         1.2032e-03, -1.8626e-03,  2.4158e-03, -6.3633e-04, -2.3417e-03,\n",
      "         6.3140e-04,  3.9360e-03, -1.2019e-03], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 4.8081e-04, -1.7292e-03,  8.8052e-04,  2.1123e-03,  6.1809e-05,\n",
      "        -3.0062e-03,  1.2107e-03,  9.9238e-05,  1.5388e-03, -6.7623e-04,\n",
      "         1.9781e-03, -1.2779e-02,  8.4539e-04, -3.7133e-04,  2.5425e-03,\n",
      "         1.5857e-02, -1.1951e-03,  1.9805e-03, -2.0061e-04,  4.7160e-03,\n",
      "        -6.5688e-04, -1.2982e-03,  1.0487e-03,  7.0981e-04, -9.6679e-04,\n",
      "        -4.1212e-04,  6.1922e-04,  1.2206e-03,  8.8029e-04, -1.0475e-03,\n",
      "        -1.3096e-03,  2.0128e-03,  2.7025e-03, -1.7087e-03,  1.8450e-03,\n",
      "         5.4070e-03, -4.7428e-03, -3.3800e-03, -7.3122e-03, -1.5948e-03,\n",
      "         2.9610e-03, -2.5122e-03,  3.5507e-03, -1.7493e-03, -4.2750e-03,\n",
      "         1.3190e-04,  5.8863e-03, -2.2431e-03], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "No inner loop params\n",
      "tensor([ 3.5894e-05,  6.1192e-05,  3.0051e-04,  1.0473e-04,  1.5659e-04,\n",
      "         7.1952e-05,  1.2491e-05, -1.9710e-04, -6.2190e-05, -3.1314e-04,\n",
      "        -1.8843e-04, -1.5285e-04,  9.5910e-06, -1.1393e-04,  1.6894e-05,\n",
      "         6.9507e-06,  2.0774e-04, -3.7402e-05,  1.1766e-05,  1.1521e-04,\n",
      "        -1.7586e-04,  2.4778e-04, -2.7955e-06,  2.1658e-04, -1.9990e-04,\n",
      "         1.1049e-04, -8.4606e-05,  1.7508e-04,  9.3944e-05, -2.5080e-07,\n",
      "        -5.0314e-05, -8.3374e-05,  1.4200e-04,  2.8363e-05, -2.7206e-04,\n",
      "         3.3162e-04,  2.5681e-04, -9.0235e-05, -2.6792e-04,  1.2826e-04,\n",
      "         9.5802e-05,  1.2027e-05, -3.2495e-05, -1.7318e-04, -2.1552e-04,\n",
      "        -5.6028e-05,  1.6789e-05,  4.7291e-05], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[[ 2.0968e-06, -1.7465e-05, -1.0427e-05],\n",
      "          [-1.9858e-05, -3.0631e-05, -2.9455e-05],\n",
      "          [-4.6024e-05, -1.7865e-05, -1.8761e-05]],\n",
      "\n",
      "         [[-1.0781e-05, -2.3944e-05, -2.8063e-05],\n",
      "          [-1.4962e-05, -8.5103e-06, -2.2414e-05],\n",
      "          [-1.4451e-05, -7.6090e-06, -1.6577e-05]],\n",
      "\n",
      "         [[-1.0369e-05, -2.4807e-05, -3.7095e-05],\n",
      "          [-3.8250e-06, -8.4358e-06, -6.6380e-06],\n",
      "          [ 2.1865e-05,  3.5169e-05,  2.6260e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4597e-05, -7.5149e-06, -6.5458e-06],\n",
      "          [-1.0587e-05, -5.2691e-06,  2.2556e-06],\n",
      "          [-2.8549e-06,  4.1683e-05,  2.4675e-05]],\n",
      "\n",
      "         [[-3.2925e-05, -4.9520e-05, -1.3356e-05],\n",
      "          [-3.3654e-06, -1.0938e-05,  1.4872e-05],\n",
      "          [ 1.7580e-05,  2.5651e-05,  4.5896e-05]],\n",
      "\n",
      "         [[ 7.3921e-06, -1.2767e-05, -8.3415e-06],\n",
      "          [ 1.8604e-05,  3.7653e-06, -2.7633e-06],\n",
      "          [ 1.9830e-05,  8.2077e-06,  1.6525e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5100e-06, -1.0606e-05, -1.9963e-05],\n",
      "          [-2.6434e-05, -2.3490e-05, -2.1639e-05],\n",
      "          [-1.8016e-05, -6.4017e-06, -3.3517e-05]],\n",
      "\n",
      "         [[-2.0480e-05, -7.6172e-06, -1.2501e-05],\n",
      "          [-7.6564e-06,  3.3550e-06, -3.7402e-06],\n",
      "          [-2.0759e-05, -6.4949e-06,  1.3002e-05]],\n",
      "\n",
      "         [[-7.9212e-06, -4.8845e-06, -1.9672e-05],\n",
      "          [-4.0438e-06, -8.9694e-07, -6.7066e-06],\n",
      "          [ 1.4125e-05,  1.3014e-05, -8.3548e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4839e-05,  8.2650e-06, -6.5835e-06],\n",
      "          [ 5.1357e-06,  2.5049e-06, -2.3293e-06],\n",
      "          [ 1.3226e-05,  2.9967e-05,  1.3941e-05]],\n",
      "\n",
      "         [[-1.4577e-05, -1.0403e-05, -9.4564e-06],\n",
      "          [-1.0046e-05, -1.3466e-05, -2.0779e-05],\n",
      "          [-1.9214e-06, -1.5381e-05, -8.4284e-06]],\n",
      "\n",
      "         [[ 7.0894e-06, -5.4302e-07, -3.1570e-05],\n",
      "          [ 9.0320e-06,  2.8491e-06, -1.8170e-05],\n",
      "          [ 4.9522e-07,  1.3259e-07, -1.2704e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6397e-06, -1.9247e-05, -5.9609e-06],\n",
      "          [-5.8314e-06, -1.8428e-05, -1.6321e-06],\n",
      "          [-7.3735e-06,  5.7221e-06, -2.5196e-05]],\n",
      "\n",
      "         [[-2.2837e-05, -2.2971e-06, -1.2927e-05],\n",
      "          [-3.9548e-05, -9.4665e-06, -2.4763e-05],\n",
      "          [-1.8915e-05, -1.7617e-05, -1.7882e-05]],\n",
      "\n",
      "         [[-3.4107e-05, -1.3884e-05,  2.1974e-06],\n",
      "          [-2.8787e-05, -8.1665e-06, -8.5299e-06],\n",
      "          [-1.4102e-05, -5.6689e-06, -1.7015e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5078e-05,  1.4576e-05, -9.0489e-06],\n",
      "          [-3.0963e-05, -1.4807e-05, -1.9383e-05],\n",
      "          [-3.9288e-05, -2.6914e-05, -9.6710e-06]],\n",
      "\n",
      "         [[-3.8115e-05,  7.2971e-06,  1.8442e-05],\n",
      "          [-3.4032e-05,  2.1480e-05,  4.0807e-06],\n",
      "          [-4.5852e-06,  3.0541e-05,  1.6639e-05]],\n",
      "\n",
      "         [[ 2.1886e-06,  1.4802e-05, -4.4873e-07],\n",
      "          [-1.1598e-06,  4.1895e-06, -1.3665e-05],\n",
      "          [ 7.9694e-06, -1.8960e-06, -9.8493e-06]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.5644e-05, -1.6678e-06, -2.7473e-06],\n",
      "          [-4.4899e-06, -5.8361e-06, -1.8733e-05],\n",
      "          [ 2.7626e-06, -1.6732e-05, -1.0177e-05]],\n",
      "\n",
      "         [[ 7.4598e-06,  1.1767e-05,  5.9243e-07],\n",
      "          [ 9.3229e-06,  7.6840e-06,  1.1524e-05],\n",
      "          [ 1.2714e-06,  1.6247e-05,  8.1968e-06]],\n",
      "\n",
      "         [[-9.1123e-06, -3.9756e-06,  2.7593e-06],\n",
      "          [-5.5953e-06, -4.1447e-06,  3.9501e-06],\n",
      "          [ 1.2016e-05,  9.0215e-06,  7.9647e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3804e-05,  3.5504e-05,  1.9343e-05],\n",
      "          [ 2.9359e-05,  3.3873e-05,  2.5043e-05],\n",
      "          [ 2.9418e-05,  3.7630e-05,  2.9004e-05]],\n",
      "\n",
      "         [[-1.8090e-05, -1.8372e-05, -8.0374e-06],\n",
      "          [-1.6948e-05, -1.6370e-05, -1.4473e-05],\n",
      "          [-2.4755e-06, -1.3359e-05,  1.6547e-06]],\n",
      "\n",
      "         [[ 1.3275e-05,  1.9618e-05, -1.7252e-05],\n",
      "          [ 1.7638e-05,  1.3117e-05, -1.1405e-05],\n",
      "          [ 2.2853e-05,  2.4568e-05,  2.7031e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.4854e-05, -2.2948e-06, -5.2453e-05],\n",
      "          [ 3.6576e-06,  1.0710e-05, -2.9358e-06],\n",
      "          [-2.0326e-05, -8.6195e-06, -2.8531e-05]],\n",
      "\n",
      "         [[-5.8132e-06,  1.1678e-06, -3.2701e-05],\n",
      "          [ 2.6447e-06, -2.7567e-05, -2.8472e-05],\n",
      "          [-6.1826e-06, -4.4116e-05, -5.8100e-05]],\n",
      "\n",
      "         [[-2.0950e-05, -2.8774e-05, -2.6378e-05],\n",
      "          [-2.7429e-05, -2.0557e-05, -2.0113e-05],\n",
      "          [-7.8241e-06,  2.0363e-05,  8.0755e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.7220e-06,  1.8108e-05,  1.7878e-05],\n",
      "          [ 2.0338e-05,  3.8756e-05,  1.8014e-06],\n",
      "          [ 2.7542e-05,  2.9745e-05,  7.6264e-06]],\n",
      "\n",
      "         [[-3.4389e-05, -1.9174e-06,  1.7658e-06],\n",
      "          [-1.3213e-05,  8.8132e-06,  3.2154e-06],\n",
      "          [ 5.1992e-06,  2.8568e-05,  2.2206e-05]],\n",
      "\n",
      "         [[ 2.8471e-05, -8.1346e-06, -4.3845e-06],\n",
      "          [ 1.2172e-05, -4.1571e-06, -3.4532e-06],\n",
      "          [ 1.7258e-05,  1.6719e-05, -2.9646e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5318e-05,  4.3745e-05,  3.4481e-05],\n",
      "          [ 4.2378e-05,  2.9988e-05,  3.7836e-06],\n",
      "          [ 2.1032e-05,  5.6861e-06,  3.5703e-05]],\n",
      "\n",
      "         [[-1.0261e-05,  6.1373e-08, -1.2854e-05],\n",
      "          [-1.0315e-05, -3.4974e-06,  5.8381e-06],\n",
      "          [-4.0582e-06, -4.4975e-06, -1.2568e-05]],\n",
      "\n",
      "         [[ 3.9319e-05,  3.5352e-05,  4.3502e-05],\n",
      "          [ 3.3565e-05,  1.4252e-05,  2.9108e-05],\n",
      "          [ 5.3366e-06,  1.3655e-05,  3.4734e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7284e-05, -4.8118e-05, -4.8936e-05],\n",
      "          [-1.7368e-05, -5.1524e-05, -7.8297e-05],\n",
      "          [-3.2403e-05, -7.2767e-05, -5.6013e-05]],\n",
      "\n",
      "         [[ 2.3215e-05,  2.4842e-05,  2.3169e-05],\n",
      "          [ 2.3519e-05,  1.7766e-05,  1.6528e-05],\n",
      "          [ 1.4880e-05,  1.6151e-05,  1.2546e-05]],\n",
      "\n",
      "         [[-1.5007e-05, -1.6873e-05,  1.2416e-05],\n",
      "          [-2.3381e-05, -1.8181e-05,  1.1468e-05],\n",
      "          [-1.7572e-05, -5.8453e-06, -6.0524e-06]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[ 1.0803e-04,  8.2241e-05,  4.1064e-04,  ...,  1.8015e-04,\n",
      "          1.1503e-04,  5.9503e-05],\n",
      "        [ 7.7367e-05,  1.4480e-04,  3.6680e-04,  ...,  7.2076e-05,\n",
      "          8.4462e-05,  2.5877e-05],\n",
      "        [ 7.4220e-06, -1.1390e-04, -7.7846e-05,  ..., -1.3516e-04,\n",
      "          5.8690e-05,  4.0860e-05],\n",
      "        [-8.9316e-05, -1.2369e-04, -6.0732e-04,  ...,  5.7096e-05,\n",
      "         -9.0517e-05, -4.6147e-05],\n",
      "        [-1.0350e-04,  1.0557e-05, -9.2280e-05,  ..., -1.7416e-04,\n",
      "         -1.6765e-04, -8.0086e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([-1.6802e-03,  1.8447e-03, -5.1422e-04, -1.8090e-05,  3.6783e-04],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5540\\2086348927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_landscape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandscape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaml_system\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_support_set_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_support_set_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mfigure_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure_idx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\MAML\\utils\\loss_landscape.py\u001b[0m in \u001b[0;36mshow_2d\u001b[1;34m(self, inputs, targets, title)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mhessian_comp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_hessian\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmy_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0mtop_eigenvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_eigenvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhessian_comp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meigenvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mlams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\MAML\\mypyhessian\\my_hessian.py\u001b[0m in \u001b[0;36meigenvalues\u001b[1;34m(self, maxIter, tol, top_n)\u001b[0m\n\u001b[0;32m    144\u001b[0m                     \u001b[0mtmp_eigenvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader_hv_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                     \u001b[0mHv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhessian_vector_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradsH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m                     \u001b[0mtmp_eigenvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\MAML\\mypyhessian\\myutils.py\u001b[0m in \u001b[0;36mhessian_vector_product\u001b[1;34m(gradsH, params, v)\u001b[0m\n\u001b[0;32m     84\u001b[0m                              \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                              \u001b[0monly_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                              retain_graph=True)\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    300\u001b[0m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    301\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = maml_system.data.get_train_batches(total_batches=int(600/2), augment_images=False)\n",
    "\n",
    "figure_idx = 0\n",
    "\n",
    "for sample_idx, train_sample in enumerate(train_data):\n",
    "    \n",
    "    x_support_set, x_target_set, y_support_set, y_target_set, seed = train_sample\n",
    "    \n",
    "    x_support_set = torch.Tensor(x_support_set).float().to(device=maml_system.model.device)\n",
    "    x_target_set = torch.Tensor(x_target_set).float().to(device=maml_system.model.device)\n",
    "    y_support_set = torch.Tensor(y_support_set).long().to(device=maml_system.model.device)\n",
    "    y_target_set = torch.Tensor(y_target_set).long().to(device=maml_system.model.device)\n",
    "    \n",
    "    for task_id, (x_support_set_task, y_support_set_task, x_target_set_task, y_target_set_task) in enumerate(zip(x_support_set,\n",
    "                              y_support_set,\n",
    "                              x_target_set,\n",
    "                              y_target_set)):\n",
    "        \n",
    "        names_weights_copy = maml_system.model.get_inner_loop_parameter_dict(maml_system.model.classifier.named_parameters())\n",
    "        \n",
    "        \n",
    "        num_devices = torch.cuda.device_count() if torch.cuda.is_available() else 1\n",
    "\n",
    "        names_weights_copy = {\n",
    "            name.replace('module.', ''): value.unsqueeze(0).repeat(\n",
    "                [num_devices] + [1 for i in range(len(value.shape))]) for\n",
    "            name, value in names_weights_copy.items()}\n",
    "        \n",
    "        n, s, c, h, w = x_target_set_task.shape\n",
    "\n",
    "        x_support_set_task = x_support_set_task.view(-1, c, h, w)\n",
    "        y_support_set_task = y_support_set_task.view(-1)\n",
    "        x_target_set_task = x_target_set_task.view(-1, c, h, w)\n",
    "        y_target_set_task = y_target_set_task.view(-1)\n",
    "        \n",
    "        # Inner-loop (Adaptation 과정을 수행한 후, loss function을 구해야하나?)\n",
    "        num_steps=5\n",
    "        for num_step in range(num_steps):            \n",
    "            support_loss, support_preds, out_feature_dict = maml_system.model.net_forward(\n",
    "                    x=x_support_set_task,\n",
    "                    y=y_support_set_task,\n",
    "                    weights=names_weights_copy,\n",
    "                    backup_running_statistics=num_step == 0,\n",
    "                    training=True,\n",
    "                    num_step=num_step,\n",
    "                )\n",
    "        \n",
    "            generated_alpha_params = {}\n",
    "\n",
    "            if maml_system.model.args.arbiter:\n",
    "                support_loss_grad = torch.autograd.grad(support_loss, names_weights_copy.values(),\n",
    "                                                        retain_graph=True)\n",
    "\n",
    "                names_grads_copy = dict(zip(names_weights_copy.keys(), support_loss_grad))\n",
    "\n",
    "                per_step_task_embedding = []\n",
    "\n",
    "                for key, weight in names_weights_copy.items():\n",
    "                    weight_norm = torch.norm(weight, p=2)\n",
    "                    per_step_task_embedding.append(weight_norm)\n",
    "\n",
    "                for key, grad in names_grads_copy.items():\n",
    "                    gradient_l2norm = torch.norm(grad, p=2)\n",
    "                    per_step_task_embedding.append(gradient_l2norm)\n",
    "\n",
    "                per_step_task_embedding = torch.stack(per_step_task_embedding)\n",
    "\n",
    "                per_step_task_embedding = (per_step_task_embedding - per_step_task_embedding.mean()) / (\n",
    "                            per_step_task_embedding.std() + 1e-12)\n",
    "\n",
    "                generated_gradient_rate = maml_system.model.arbiter(per_step_task_embedding)\n",
    "\n",
    "                g = 0\n",
    "                for key in names_weights_copy.keys():\n",
    "                    generated_alpha_params[key] = generated_gradient_rate[g]\n",
    "                    g += 1\n",
    "\n",
    "            names_weights_copy = maml_system.model.apply_inner_loop_update(loss=support_loss,\n",
    "                                                              names_weights_copy=names_weights_copy,\n",
    "                                                              out_feature_dict=out_feature_dict,\n",
    "                                                              alpha=generated_alpha_params,\n",
    "                                                              use_second_order=args.second_order,\n",
    "                                                              current_step_idx=num_step,\n",
    "                                                              current_iter=maml_system.state['current_iter'],\n",
    "                                                              training_phase='test')\n",
    "  \n",
    "        \n",
    "        for name, param in maml_system.model.classifier.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if \"norm_layer\" not in name:\n",
    "                    param.data = names_weights_copy[name].squeeze().to(device=device)    \n",
    "                \n",
    "        ls = loss_landscape.landscape(maml_system.model.classifier, args)\n",
    "        ls.show(x_support_set_task, y_support_set_task, title=str(figure_idx))\n",
    "        figure_idx = figure_idx + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
