{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1275e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# pip install easydict\n",
    "import easydict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data import MetaLearningSystemDataLoader\n",
    "from data import FewShotLearningDatasetParallel\n",
    "from utils.parser_utils import get_args\n",
    "\n",
    "\n",
    "from meta_neural_network_architectures import VGGReLUNormNetwork, ResNet12, extract_top_level_dict, MetaBatchNormLayer, MetaLinearLayer\n",
    "from inner_loop_optimizers import LSLRGradientDescentLearningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f7352263",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "{\n",
    "  \"batch_size\":2,\n",
    "  \"image_height\":84,\n",
    "  \"image_width\":84,\n",
    "  \"image_channels\":3,\n",
    "  \"gpu_to_use\":0,\n",
    "  \"num_dataprovider_workers\":4,\n",
    "  \"max_models_to_save\":5,\n",
    "  \"dataset_name\":\"mini_imagenet_full_size\",\n",
    "  \"dataset_path\":\"mini_imagenet_full_size\",\n",
    "  \"reset_stored_paths\":False,\n",
    "  \"experiment_name\":\"alfa+maml\",\n",
    "  \"train_seed\": 0, \"val_seed\": 0,\n",
    "  \"indexes_of_folders_indicating_class\": [-3, -2],\n",
    "  \"sets_are_pre_split\": True,\n",
    "  \"train_val_test_split\": [0.64, 0.16, 0.20],\n",
    "  \"evaluate_on_test_set_only\": False,\n",
    "\n",
    "  \"total_epochs\": 100,\n",
    "  \"total_iter_per_epoch\":500, \"continue_from_epoch\": -2,\n",
    "  \"num_evaluation_tasks\":600,\n",
    "  \"multi_step_loss_num_epochs\": 15,\n",
    "  \"minimum_per_task_contribution\": 0.01,\n",
    "  \"learnable_per_layer_per_step_inner_loop_learning_rate\": False,\n",
    "  \"enable_inner_loop_optimizable_bn_params\": False,\n",
    "  \"evalute_on_test_set_only\": False,\n",
    "\n",
    "  \"max_pooling\": True,\n",
    "  \"per_step_bn_statistics\": False,\n",
    "  \"learnable_batch_norm_momentum\": False,\n",
    "  \"load_into_memory\": False,\n",
    "  \"init_inner_loop_learning_rate\": 0.01,\n",
    "  \"init_inner_loop_weight_decay\": 0.0005,\n",
    "  \"learnable_bn_gamma\": True,\n",
    "  \"learnable_bn_beta\": True,\n",
    "\n",
    "  \"dropout_rate_value\":0.0,\n",
    "  \"min_learning_rate\":0.001,\n",
    "  \"meta_learning_rate\":0.001,   \"total_epochs_before_pause\": 100,\n",
    "  \"first_order_to_second_order_epoch\":-1,\n",
    "  \"weight_decay\": 0.0,\n",
    "\n",
    "  \"norm_layer\":\"batch_norm\",\n",
    "  \"cnn_num_filters\":48,\n",
    "  \"num_stages\":4,\n",
    "  \"conv_padding\": True,\n",
    "  \"number_of_training_steps_per_iter\":5,\n",
    "  \"number_of_evaluation_steps_per_iter\":5,\n",
    "  \"cnn_blocks_per_stage\":1,\n",
    "  \"num_classes_per_set\":5,\n",
    "  \"num_samples_per_class\":5,\n",
    "  \"num_target_samples\": 15,\n",
    "\n",
    "  \"second_order\": True,\n",
    "  \"use_multi_step_loss_optimization\":False,\n",
    "  \"attenuate\": False,\n",
    "  \"alfa\": True,\n",
    "  \"random_init\": False,\n",
    "  \"backbone\": \"4-CONV\"\n",
    "}\n",
    ")\n",
    "\n",
    "device = torch.cuda.current_device()\n",
    "im_shape = (2, 3, args.image_height, args.image_width)\n",
    "\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "args.seed = 104\n",
    "args.reverse_channels=False\n",
    "args.labels_as_int=False\n",
    "args.reset_stored_filepaths=False\n",
    "args.num_of_gpus=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "70edfa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MetaLearningSystemDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69137e29",
   "metadata": {},
   "source": [
    "# 1. Linear Regression으로 meta_adpative_curriculum을 구현하기 위한 시도\n",
    "### - 사용하지 않는다\n",
    "### - Linear Regression의 차원으로 인해 적용 불가하다\n",
    "### - output의 차원을 통제하기 어렵다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "252d6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 10\n",
    "input_shape = (1, input_dim)\n",
    "\n",
    "meta_linear = MetaLinearLayer(input_shape=input_shape, num_filters=input_dim, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2b9896cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights torch.Size([10, 10])\n",
      "bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in meta_linear.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "10ce21f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a len ==  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([1, 2, 3, 4])\n",
    "x2 = torch.tensor([5, 6, 7, 8])\n",
    "x3 = torch.tensor([9, 10, 11 ,12])\n",
    "\n",
    "a = []\n",
    "a.append(x1)\n",
    "a.append(x2)\n",
    "a.append(x3)\n",
    "\n",
    "print(\"a len == \",len(a))\n",
    "\n",
    "# inputs = torch.stack(a)\n",
    "inputs = torch.stack(a)\n",
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64ac23cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0548, -0.3760, -0.0344, -0.2852, -0.0900,  0.3292, -0.4537,  0.1552,\n",
       "          0.5075,  0.5171],\n",
       "        [-0.3942,  0.1571,  0.1007,  0.2596,  0.2473,  0.4311, -0.2338,  0.4221,\n",
       "          0.4029, -0.4490],\n",
       "        [ 0.0721,  0.2862, -0.5308, -0.0199, -0.5455, -0.0503, -0.1801, -0.1884,\n",
       "          0.2964,  0.4391],\n",
       "        [-0.4541, -0.1494, -0.0903,  0.2008,  0.5134,  0.1731,  0.3638,  0.4682,\n",
       "         -0.2441,  0.4088],\n",
       "        [-0.5431, -0.2243, -0.3429,  0.2121,  0.3825, -0.1407,  0.2971,  0.5402,\n",
       "          0.4813, -0.2902],\n",
       "        [-0.2602, -0.4393, -0.0885, -0.4255,  0.4029, -0.0476,  0.1118,  0.2320,\n",
       "         -0.3739,  0.2959],\n",
       "        [-0.4520,  0.4446,  0.5188, -0.1288, -0.0282,  0.2377, -0.5285,  0.3231,\n",
       "          0.3172, -0.2486],\n",
       "        [ 0.0925,  0.4461, -0.2178,  0.5254, -0.2857,  0.5168,  0.3996, -0.4742,\n",
       "          0.4068,  0.4955],\n",
       "        [-0.5432, -0.1709, -0.1184,  0.4868, -0.0915,  0.1797,  0.0129,  0.4036,\n",
       "         -0.4648, -0.4477],\n",
       "        [ 0.0807,  0.2952,  0.1830, -0.2011,  0.2398, -0.0745,  0.1356,  0.1090,\n",
       "          0.1619, -0.1083]], requires_grad=True)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 10\n",
    "input_shape = (1, input_dim)\n",
    "num_filters=input_dim\n",
    "b, c = input_shape #c=10\n",
    "\n",
    "weights1 = nn.Parameter(torch.ones(num_filters, c))\n",
    "# weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "\n",
    "nn.init.xavier_uniform_(weights1)\n",
    "#weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b29e8c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias1 = nn.Parameter(torch.zeros(num_filters))\n",
    "bias1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f8288d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0342,  0.5365, -0.5674,  1.2229,  0.6175, -0.0138, -0.0882,  0.9999,\n",
       "         -0.1395,  0.3651],\n",
       "        [-0.2281,  0.3739, -0.5908,  0.2960,  0.3007, -0.5900,  0.0173,  0.9789,\n",
       "         -0.7192,  0.5969],\n",
       "        [ 0.0985,  0.4329, -0.1373,  1.0437,  0.1756, -0.1758, -0.2531,  1.1990,\n",
       "          0.1610,  0.1259]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 10)\n",
    "\n",
    "out1 = F.linear(input=x, weight=weights1, bias=bias1)\n",
    "# y = xW^T + b\n",
    "\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d3adb0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5279, -1.2201],\n",
       "        [-0.3305, -1.5321],\n",
       "        [-0.5346, -0.6170]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2 = nn.Parameter(torch.ones(2, 10))\n",
    "nn.init.xavier_uniform_(weights2)\n",
    "out2 = F.linear(input=out1, weight=weights2)\n",
    "# y = x*W^T + b\n",
    "\n",
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42d4a1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3 = F.relu_(out2)\n",
    "out3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f94739",
   "metadata": {},
   "source": [
    "# 2. LSTM으로 시도\n",
    "### 안되면 conv1d\n",
    "### https://sanghyu.tistory.com/52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "68055807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a len ==  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  6.,  7.,  8., 11., 12., 13., 14., 15., 16.],\n",
       "        [ 9., 10., 11., 12., 16., 17., 18., 19., 20., 21.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([1, 2, 3, 4,5,6,7,8,9,10])\n",
    "x2 = torch.tensor([5, 6, 7, 8,11,12,13,14,15,16])\n",
    "x3 = torch.tensor([9, 10, 11 ,12,16,17,18,19,20,21])\n",
    "\n",
    "a = []\n",
    "a.append(x1)\n",
    "a.append(x2)\n",
    "a.append(x3)\n",
    "\n",
    "print(\"a len == \",len(a))\n",
    "inputs = torch.stack(a)\n",
    "inputs = inputs.to(torch.float32)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e0f62cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.3837e-06,  4.7783e-02],\n",
       "         [ 4.2505e-08,  9.0387e-03],\n",
       "         [-1.3919e-09,  2.9464e-03]], grad_fn=<SqueezeBackward1>),\n",
       " (tensor([[-1.3919e-09,  2.9464e-03]], grad_fn=<SqueezeBackward1>),\n",
       "  tensor([[-1.3919e-09,  1.0000e+00]], grad_fn=<SqueezeBackward1>)))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in = 10 # input_size: input의 feature dimension을 넣어주어야 한다. time step이 아니라 input feature dimension!\n",
    "H= 2     # 내부에서 어떤 feature dimension으로 바꿔주고 싶은지를 넣어주면 된다.\n",
    "D_out = 2\n",
    "\n",
    "meta_adaptive_curriculum = nn.Sequential(\n",
    "            torch.nn.LSTM(D_in, H),\n",
    "             torch.nn.ReLU(),\n",
    "             torch.nn.LSTM(H, D_out))\n",
    "\n",
    "meta_adaptive_curriculum = nn.Sequential(\n",
    "            torch.nn.LSTM(D_in, H))\n",
    "\n",
    "meta_adaptive_curriculum(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "df991f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3122,  0.5331, -0.1796, -0.8394, -0.3112, -0.0492, -0.1339,\n",
       "           0.1658,  0.3101,  1.1329],\n",
       "         [-0.1352, -0.4880,  0.5118, -0.0088,  0.2206, -0.9102, -0.5511,\n",
       "           0.4316, -0.8683, -1.0640],\n",
       "         [-0.6711, -0.7300,  1.1797,  1.0489,  1.7177, -1.0403, -0.3063,\n",
       "          -1.8115,  0.4117,  1.1906]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "sequence_length = 3\n",
    "input_features = 10\n",
    "output_features = 5\n",
    "\n",
    "# produce random data\n",
    "x = torch.randn(batch_size, sequence_length, input_features)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e90a5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0940, -0.1628, -0.0330,  0.0506, -0.1559],\n",
       "        [-0.0071, -0.3010, -0.1873,  0.0588, -0.0903],\n",
       "        [-0.0691, -0.0922,  0.1313,  0.1493,  0.0610]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_layer = nn.LSTM(\n",
    "    input_size=input_features,\n",
    "    hidden_size=output_features,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "expected_output_shape = (batch_size, sequence_length, output_features)\n",
    "\n",
    "x_out, _ = lstm_layer(x)\n",
    "\n",
    "print(x_out.shape == expected_output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29b24f",
   "metadata": {},
   "source": [
    "# 3. Conv1D\n",
    "### https://kaya-dev.tistory.com/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6b077f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a len ==  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
       "         0.1000],\n",
       "        [0.5000, 0.6000, 0.0700, 0.8000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500,\n",
       "         0.1600],\n",
       "        [0.9000, 0.1000, 0.1100, 0.1200, 0.1600, 0.1700, 0.1800, 0.1900, 0.2000,\n",
       "         0.2100]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.1])\n",
    "x2 = torch.tensor([0.5, 0.6, 0.07, 0.8,0.11,0.12,0.13,0.14,0.15,0.16])\n",
    "x3 = torch.tensor([0.9, 0.10, 0.11 , 0.12, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21])\n",
    "\n",
    "a = []\n",
    "a.append(x1)\n",
    "a.append(x2)\n",
    "a.append(x3)\n",
    "\n",
    "print(\"a len == \",len(a))\n",
    "inputs = torch.stack(a)\n",
    "inputs = inputs.to(torch.float32)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "ac37905e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0178, -0.1619,  0.0021, -0.1357,  0.0399,  0.0731,  0.1062,  0.1394,\n",
       "         -0.0681]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_adaptive_curriculum = nn.Sequential(\n",
    "    nn.Conv1d(in_channels=3, out_channels=1, kernel_size=2))\n",
    "meta_adaptive_curriculum(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "768a35f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4132]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "adaptive_curriculum = nn.Sequential(\n",
    "                    nn.Conv1d(in_channels=3, out_channels=1, kernel_size=2),\n",
    "                    nn.Linear(9,4),\n",
    "                    nn.Sigmoid())\n",
    "\n",
    "a = meta_adaptive_curriculum(inputs)\n",
    "#int(torch.argmax(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "291e8475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "meta_adaptive_curriculum = nn.Sequential(\n",
    "    nn.Conv1d(in_channels=3, out_channels=1, kernel_size=2),\n",
    "    nn.Linear(9,4),\n",
    "    nn.Linear(4,1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "#int(meta_adaptive_curriculum(inputs) * 5)\n",
    "a = meta_adaptive_curriculum(inputs)\n",
    "a = int(a * 5)\n",
    "print(a)\n",
    "#int(torch.argmax(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f090c",
   "metadata": {},
   "source": [
    "# 4. Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "093e11ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a len ==  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
       "         0.1000],\n",
       "        [0.5000, 0.6000, 0.0700, 0.8000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500,\n",
       "         0.1600],\n",
       "        [0.9000, 0.1000, 0.1100, 0.1200, 0.1600, 0.1700, 0.1800, 0.1900, 0.2000,\n",
       "         0.2100]])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.1])\n",
    "x2 = torch.tensor([0.5, 0.6, 0.07, 0.8,0.11,0.12,0.13,0.14,0.15,0.16])\n",
    "x3 = torch.tensor([0.9, 0.10, 0.11 , 0.12, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21])\n",
    "\n",
    "a = []\n",
    "a.append(x1)\n",
    "a.append(x2)\n",
    "a.append(x3)\n",
    "\n",
    "print(\"a len == \",len(a))\n",
    "inputs = torch.stack(a)\n",
    "inputs = inputs.to(torch.float32)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "4c403c49",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x8 and 9x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2908\\2724163806.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_adaptive_curriculum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x8 and 9x1)"
     ]
    }
   ],
   "source": [
    "adaptive_curriculum = nn.Sequential(\n",
    "                nn.Linear(3, 10))\n",
    "\n",
    "\n",
    "a = meta_adaptive_curriculum(inputs)\n",
    "print(a)\n",
    "int(torch.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf048e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
