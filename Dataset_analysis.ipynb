{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "a1275e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# pip install easydict\n",
    "import easydict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data import MetaLearningSystemDataLoader\n",
    "from data import FewShotLearningDatasetParallel\n",
    "from utils.parser_utils import get_args\n",
    "\n",
    "\n",
    "from meta_neural_network_architectures import VGGReLUNormNetwork, ResNet12, extract_top_level_dict, MetaBatchNormLayer, MetaLinearLayer\n",
    "from inner_loop_optimizers import LSLRGradientDescentLearningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "f7352263",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "{\n",
    "  \"batch_size\":2,\n",
    "  \"image_height\":84,\n",
    "  \"image_width\":84,\n",
    "  \"image_channels\":3,\n",
    "  \"gpu_to_use\":0,\n",
    "  \"num_dataprovider_workers\":4,\n",
    "  \"max_models_to_save\":5,\n",
    "  \"dataset_name\":\"mini_imagenet_full_size\",\n",
    "  \"dataset_path\":\"mini_imagenet_full_size\",\n",
    "  \"reset_stored_paths\":False,\n",
    "  \"experiment_name\":\"alfa+maml\",\n",
    "  \"train_seed\": 0, \"val_seed\": 0,\n",
    "  \"indexes_of_folders_indicating_class\": [-3, -2],\n",
    "  \"sets_are_pre_split\": True,\n",
    "  \"train_val_test_split\": [0.64, 0.16, 0.20],\n",
    "  \"evaluate_on_test_set_only\": False,\n",
    "\n",
    "  \"total_epochs\": 100,\n",
    "  \"total_iter_per_epoch\":500, \"continue_from_epoch\": -2,\n",
    "  \"num_evaluation_tasks\":600,\n",
    "  \"multi_step_loss_num_epochs\": 15,\n",
    "  \"minimum_per_task_contribution\": 0.01,\n",
    "  \"learnable_per_layer_per_step_inner_loop_learning_rate\": False,\n",
    "  \"enable_inner_loop_optimizable_bn_params\": False,\n",
    "  \"evalute_on_test_set_only\": False,\n",
    "\n",
    "  \"max_pooling\": True,\n",
    "  \"per_step_bn_statistics\": False,\n",
    "  \"learnable_batch_norm_momentum\": False,\n",
    "  \"load_into_memory\": False,\n",
    "  \"init_inner_loop_learning_rate\": 0.01,\n",
    "  \"init_inner_loop_weight_decay\": 0.0005,\n",
    "  \"learnable_bn_gamma\": True,\n",
    "  \"learnable_bn_beta\": True,\n",
    "\n",
    "  \"dropout_rate_value\":0.0,\n",
    "  \"min_learning_rate\":0.001,\n",
    "  \"meta_learning_rate\":0.001,   \"total_epochs_before_pause\": 100,\n",
    "  \"first_order_to_second_order_epoch\":-1,\n",
    "  \"weight_decay\": 0.0,\n",
    "\n",
    "  \"norm_layer\":\"batch_norm\",\n",
    "  \"cnn_num_filters\":48,\n",
    "  \"num_stages\":4,\n",
    "  \"conv_padding\": True,\n",
    "  \"number_of_training_steps_per_iter\":5,\n",
    "  \"number_of_evaluation_steps_per_iter\":5,\n",
    "  \"cnn_blocks_per_stage\":1,\n",
    "  \"num_classes_per_set\":5,\n",
    "  \"num_samples_per_class\":5,\n",
    "  \"num_target_samples\": 15,\n",
    "\n",
    "  \"second_order\": True,\n",
    "  \"use_multi_step_loss_optimization\":False,\n",
    "  \"attenuate\": False,\n",
    "  \"alfa\": True,\n",
    "  \"random_init\": False,\n",
    "  \"backbone\": \"4-CONV\"\n",
    "}\n",
    ")\n",
    "\n",
    "device = torch.cuda.current_device()\n",
    "im_shape = (2, 3, args.image_height, args.image_width)\n",
    "\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "args.seed = 104\n",
    "args.reverse_channels=False\n",
    "args.labels_as_int=False\n",
    "args.reset_stored_filepaths=False\n",
    "args.num_of_gpus=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "70edfa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MetaLearningSystemDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69137e29",
   "metadata": {},
   "source": [
    "# 1. Linear Regression으로 meta_adpative_curriculum을 구현하기 위한 시도\n",
    "### - 사용하지 않는다\n",
    "### - Linear Regression의 차원으로 인해 적용 불가하다\n",
    "### - output의 차원을 통제하기 어렵다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "252d6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 10\n",
    "input_shape = (1, input_dim)\n",
    "\n",
    "meta_linear = MetaLinearLayer(input_shape=input_shape, num_filters=input_dim, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "2b9896cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights torch.Size([10, 10])\n",
      "bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in meta_linear.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "10ce21f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a len ==  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([1, 2, 3, 4])\n",
    "x2 = torch.tensor([5, 6, 7, 8])\n",
    "x3 = torch.tensor([9, 10, 11 ,12])\n",
    "\n",
    "a = []\n",
    "a.append(x1)\n",
    "a.append(x2)\n",
    "a.append(x3)\n",
    "\n",
    "print(\"a len == \",len(a))\n",
    "\n",
    "# inputs = torch.stack(a)\n",
    "inputs = torch.stack(a)\n",
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "64ac23cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0364, -0.0539,  0.1909, -0.2905, -0.3656, -0.0267, -0.3022, -0.2922,\n",
       "          0.1275, -0.2587],\n",
       "        [-0.4672,  0.0126,  0.5321,  0.3353, -0.2960,  0.4450, -0.3140,  0.2775,\n",
       "         -0.2970,  0.0274],\n",
       "        [-0.3607, -0.5318,  0.3688, -0.5186, -0.5275,  0.2632, -0.4411,  0.0230,\n",
       "         -0.2560,  0.3316],\n",
       "        [ 0.3577, -0.1972, -0.3845,  0.4221,  0.4524, -0.2807, -0.2833, -0.1152,\n",
       "          0.0409, -0.1963],\n",
       "        [-0.0517, -0.4088, -0.2471,  0.3102, -0.5179,  0.3807,  0.1080,  0.4794,\n",
       "         -0.5057, -0.2270],\n",
       "        [-0.5412,  0.4166, -0.2408, -0.5284, -0.1872, -0.0149,  0.3841,  0.2630,\n",
       "         -0.4650,  0.4323],\n",
       "        [ 0.1436, -0.5149, -0.4313,  0.0863,  0.2253, -0.1602, -0.4749, -0.2412,\n",
       "          0.4612, -0.5343],\n",
       "        [-0.5359, -0.3466, -0.5199,  0.4558, -0.4525, -0.0040, -0.1630, -0.3868,\n",
       "         -0.4991,  0.4467],\n",
       "        [ 0.4961, -0.2447, -0.2916,  0.1642, -0.4376, -0.4701, -0.3763,  0.3604,\n",
       "          0.5452,  0.2580],\n",
       "        [ 0.0162,  0.2009, -0.0341, -0.2200,  0.1215, -0.1037,  0.1806, -0.0127,\n",
       "          0.2313,  0.1739]], requires_grad=True)"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 10\n",
    "input_shape = (1, input_dim)\n",
    "num_filters=input_dim\n",
    "b, c = input_shape #c=10\n",
    "\n",
    "weights1 = nn.Parameter(torch.ones(num_filters, c))\n",
    "# weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "\n",
    "nn.init.xavier_uniform_(weights1)\n",
    "#weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "b29e8c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias1 = nn.Parameter(torch.zeros(num_filters))\n",
    "bias1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "2f8288d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6641,  0.3276, -1.0046,  0.2556, -0.0299, -0.9472, -0.0665, -0.8861,\n",
       "         -0.2933,  0.0408],\n",
       "        [-0.3910,  0.0851, -0.7857,  0.2538, -0.4955, -0.4419, -0.1354, -0.8921,\n",
       "         -0.4803,  0.1269],\n",
       "        [-0.7700,  0.2488, -1.1447,  0.0998, -0.1821, -0.3008, -0.7266, -0.6806,\n",
       "          0.1875,  0.2132]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 10)\n",
    "\n",
    "out1 = F.linear(input=x, weight=weights1, bias=bias1)\n",
    "# y = xW^T + b\n",
    "\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "d3adb0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2852, 0.9372],\n",
       "        [0.8929, 0.5722],\n",
       "        [0.6433, 0.8925]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2 = nn.Parameter(torch.ones(2, 10))\n",
    "nn.init.xavier_uniform_(weights2)\n",
    "out2 = F.linear(input=out1, weight=weights2)\n",
    "# y = x*W^T + b\n",
    "\n",
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "42d4a1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2852, 0.9372],\n",
       "        [0.8929, 0.5722],\n",
       "        [0.6433, 0.8925]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3 = F.relu_(out2)\n",
    "out3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f94739",
   "metadata": {},
   "source": [
    "# 2. LSTM으로 시도\n",
    "### 안되면 conv1d\n",
    "### https://sanghyu.tistory.com/52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "68055807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a len ==  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  6.,  7.,  8., 11., 12., 13., 14., 15., 16.],\n",
       "        [ 9., 10., 11., 12., 16., 17., 18., 19., 20., 21.]])"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([1, 2, 3, 4,5,6,7,8,9,10])\n",
    "x2 = torch.tensor([5, 6, 7, 8,11,12,13,14,15,16])\n",
    "x3 = torch.tensor([9, 10, 11 ,12,16,17,18,19,20,21])\n",
    "\n",
    "a = []\n",
    "a.append(x1)\n",
    "a.append(x2)\n",
    "a.append(x3)\n",
    "\n",
    "print(\"a len == \",len(a))\n",
    "inputs = torch.stack(a)\n",
    "inputs = inputs.to(torch.float32)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "e0f62cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.4655e-05, -7.2966e-01],\n",
       "         [ 1.6548e-07, -9.5746e-01],\n",
       "         [ 7.1889e-10, -9.9282e-01]], grad_fn=<SqueezeBackward1>),\n",
       " (tensor([[ 7.1889e-10, -9.9282e-01]], grad_fn=<SqueezeBackward1>),\n",
       "  tensor([[ 0.0054, -2.9961]], grad_fn=<SqueezeBackward1>)))"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in = 10 # input_size: input의 feature dimension을 넣어주어야 한다. time step이 아니라 input feature dimension!\n",
    "H= 2     # 내부에서 어떤 feature dimension으로 바꿔주고 싶은지를 넣어주면 된다.\n",
    "D_out = 2\n",
    "\n",
    "meta_adaptive_curriculum = nn.Sequential(\n",
    "            torch.nn.LSTM(D_in, H),\n",
    "             torch.nn.ReLU(),\n",
    "             torch.nn.LSTM(H, D_out))\n",
    "\n",
    "meta_adaptive_curriculum = nn.Sequential(\n",
    "            torch.nn.LSTM(D_in, H))\n",
    "\n",
    "meta_adaptive_curriculum(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "df991f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9235, -1.5190, -0.0254,  1.8340, -0.4024,  0.0698, -0.7960,\n",
       "          -0.3041, -0.4847,  1.3663],\n",
       "         [ 0.0069,  0.7056, -1.4296,  1.1079,  0.0187, -0.3459, -1.0573,\n",
       "           1.4781, -1.3182,  0.6059],\n",
       "         [ 0.3683, -2.0391,  0.5262, -0.0336, -1.0296,  0.7878, -2.7096,\n",
       "          -0.7749, -0.6737, -0.7976]]])"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "sequence_length = 3\n",
    "input_features = 10\n",
    "output_features = 5\n",
    "\n",
    "# produce random data\n",
    "x = torch.randn(batch_size, sequence_length, input_features)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "e90a5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "lstm_layer = nn.LSTM(\n",
    "    input_size=input_features,\n",
    "    hidden_size=output_features,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "expected_output_shape = (batch_size, sequence_length, output_features)\n",
    "\n",
    "x_out, _ = lstm_layer(x)\n",
    "\n",
    "print(x_out.shape == expected_output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29b24f",
   "metadata": {},
   "source": [
    "# 3. Conv1D\n",
    "### https://kaya-dev.tistory.com/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "6b077f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a len ==  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
       "         0.1000],\n",
       "        [0.5000, 0.6000, 0.0700, 0.8000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500,\n",
       "         0.1600],\n",
       "        [0.9000, 0.1000, 0.1100, 0.1200, 0.1600, 0.1700, 0.1800, 0.1900, 0.2000,\n",
       "         0.2100]])"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.1])\n",
    "x2 = torch.tensor([0.5, 0.6, 0.07, 0.8,0.11,0.12,0.13,0.14,0.15,0.16])\n",
    "x3 = torch.tensor([0.9, 0.10, 0.11 , 0.12, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21])\n",
    "\n",
    "a = []\n",
    "a.append(x1)\n",
    "a.append(x2)\n",
    "a.append(x3)\n",
    "\n",
    "print(\"a len == \",len(a))\n",
    "inputs = torch.stack(a)\n",
    "inputs = inputs.to(torch.float32)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "ac37905e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7934,  0.3721,  0.1253,  0.3634,  0.0706,  0.0316, -0.0074, -0.0463,\n",
       "         -0.0853,  0.3074]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_adaptive_curriculum = nn.Sequential(\n",
    "    nn.Conv1d(in_channels=3, out_channels=1, kernel_size=1))\n",
    "meta_adaptive_curriculum(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "768a35f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7934,  0.3721,  0.1253,  0.3634,  0.0706,  0.0316, -0.0074, -0.0463,\n",
      "         -0.0853,  0.3074]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "adaptive_curriculum = nn.Sequential(\n",
    "                    nn.Conv1d(in_channels=3, out_channels=1, kernel_size=1),\n",
    "                    nn.Linear(10,4),\n",
    "                    nn.Sigmoid())\n",
    "\n",
    "a = meta_adaptive_curriculum(inputs)\n",
    "#int(torch.argmax(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "291e8475",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x10 and 9x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2908\\1353511887.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#int(meta_adaptive_curriculum(inputs) * 5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_adaptive_curriculum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\maml\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x10 and 9x4)"
     ]
    }
   ],
   "source": [
    "meta_adaptive_curriculum = nn.Sequential(\n",
    "    nn.Conv1d(in_channels=3, out_channels=1, kernel_size=1),\n",
    "    nn.Linear(9,4),\n",
    "    nn.Linear(4,1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "#int(meta_adaptive_curriculum(inputs) * 5)\n",
    "a = meta_adaptive_curriculum(inputs)\n",
    "a = int(a * 5)\n",
    "print(a)\n",
    "#int(torch.argmax(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f090c",
   "metadata": {},
   "source": [
    "# 4. Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "093e11ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a len ==  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
       "         0.1000],\n",
       "        [0.5000, 0.6000, 0.0700, 0.8000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500,\n",
       "         0.1600],\n",
       "        [0.9000, 0.1000, 0.1100, 0.1200, 0.1600, 0.1700, 0.1800, 0.1900, 0.2000,\n",
       "         0.2100]])"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.1])\n",
    "x2 = torch.tensor([0.5, 0.6, 0.07, 0.8,0.11,0.12,0.13,0.14,0.15,0.16])\n",
    "x3 = torch.tensor([0.9, 0.10, 0.11 , 0.12, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21])\n",
    "\n",
    "a = []\n",
    "a.append(x1)\n",
    "a.append(x2)\n",
    "a.append(x3)\n",
    "\n",
    "print(\"a len == \",len(a))\n",
    "inputs = torch.stack(a)\n",
    "inputs = inputs.to(torch.float32)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "4c403c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6672]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptive_curriculum = nn.Sequential(\n",
    "                nn.Linear(3, 10))\n",
    "\n",
    "\n",
    "a = meta_adaptive_curriculum(inputs)\n",
    "print(a)\n",
    "int(torch.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf048e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
