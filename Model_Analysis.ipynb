{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8c29a4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7b28dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from meta_neural_network_architectures import VGGReLUNormNetwork, ResNet12\n",
    "from inner_loop_optimizers import LSLRGradientDescentLearningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c7dbf56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install easydict\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "95ce8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "{\n",
    "  \"batch_size\":2,\n",
    "  \"image_height\":84,\n",
    "  \"image_width\":84,\n",
    "  \"image_channels\":3,\n",
    "  \"gpu_to_use\":0,\n",
    "  \"num_dataprovider_workers\":4,\n",
    "  \"max_models_to_save\":5,\n",
    "  \"dataset_name\":\"mini_imagenet_full_size\",\n",
    "  \"dataset_path\":\"mini_imagenet_full_size\",\n",
    "  \"reset_stored_paths\":False,\n",
    "  \"experiment_name\":\"alfa+maml\",\n",
    "  \"train_seed\": 0, \"val_seed\": 0,\n",
    "  \"indexes_of_folders_indicating_class\": [-3, -2],\n",
    "  \"sets_are_pre_split\": True,\n",
    "  \"train_val_test_split\": [0.64, 0.16, 0.20],\n",
    "  \"evaluate_on_test_set_only\": False,\n",
    "\n",
    "  \"total_epochs\": 100,\n",
    "  \"total_iter_per_epoch\":500, \"continue_from_epoch\": -2,\n",
    "  \"num_evaluation_tasks\":600,\n",
    "  \"multi_step_loss_num_epochs\": 15,\n",
    "  \"minimum_per_task_contribution\": 0.01,\n",
    "  \"learnable_per_layer_per_step_inner_loop_learning_rate\": False,\n",
    "  \"enable_inner_loop_optimizable_bn_params\": False,\n",
    "  \"evalute_on_test_set_only\": False,\n",
    "\n",
    "  \"max_pooling\": True,\n",
    "  \"per_step_bn_statistics\": False,\n",
    "  \"learnable_batch_norm_momentum\": False,\n",
    "  \"load_into_memory\": False,\n",
    "  \"init_inner_loop_learning_rate\": 0.01,\n",
    "  \"init_inner_loop_weight_decay\": 0.0005,\n",
    "  \"learnable_bn_gamma\": True,\n",
    "  \"learnable_bn_beta\": True,\n",
    "\n",
    "  \"dropout_rate_value\":0.0,\n",
    "  \"min_learning_rate\":0.001,\n",
    "  \"meta_learning_rate\":0.001,   \"total_epochs_before_pause\": 100,\n",
    "  \"first_order_to_second_order_epoch\":-1,\n",
    "  \"weight_decay\": 0.0,\n",
    "\n",
    "  \"norm_layer\":\"batch_norm\",\n",
    "  \"cnn_num_filters\":48,\n",
    "  \"num_stages\":4,\n",
    "  \"conv_padding\": True,\n",
    "  \"number_of_training_steps_per_iter\":5,\n",
    "  \"number_of_evaluation_steps_per_iter\":5,\n",
    "  \"cnn_blocks_per_stage\":1,\n",
    "  \"num_classes_per_set\":5,\n",
    "  \"num_samples_per_class\":5,\n",
    "  \"num_target_samples\": 15,\n",
    "\n",
    "  \"second_order\": True,\n",
    "  \"use_multi_step_loss_optimization\":False,\n",
    "  \"attenuate\": False,\n",
    "  \"alfa\": True,\n",
    "  \"random_init\": False,\n",
    "  \"backbone\": \"4-CONV\"\n",
    "}\n",
    ")\n",
    "\n",
    "device = torch.cuda.current_device()\n",
    "im_shape = (2, 3, args.image_height, args.image_width)\n",
    "\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "args.seed = 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "956a70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_torch_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the pytorch seeds for current experiment run\n",
    "    :param seed: The seed (int)\n",
    "    :return: A random number generator to use\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    torch_seed = rng.randint(0, 999999)\n",
    "    torch.manual_seed(seed=torch_seed)\n",
    "\n",
    "    return rng\n",
    "\n",
    "class MAMLFewShotClassifier_Test(nn.Module):\n",
    "    def __init__(self, im_shape, device, args):\n",
    "        super(MAMLFewShotClassifier_Test, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.batch_size = args.batch_size\n",
    "        self.use_cuda = args.use_cuda\n",
    "        self.im_shape = im_shape\n",
    "        self.current_epoch = 0\n",
    "\n",
    "        self.rng = set_torch_seed(seed=args.seed)\n",
    "\n",
    "        if self.args.backbone == 'ResNet12':\n",
    "            self.classifier = ResNet12(im_shape=self.im_shape, num_output_classes=self.args.\n",
    "                                                 num_classes_per_set,\n",
    "                                                 args=args, device=device, meta_classifier=True).to(device=self.device)\n",
    "        else:\n",
    "            self.classifier = VGGReLUNormNetwork(im_shape=self.im_shape, num_output_classes=self.args.\n",
    "                                                 num_classes_per_set,\n",
    "                                                 args=args, device=device, meta_classifier=True).to(device=self.device)\n",
    "            \n",
    "        self.task_learning_rate = args.init_inner_loop_learning_rate\n",
    "        \n",
    "        # Inner loop의 모든 것이 이루어지는 공간이구나\n",
    "        self.inner_loop_optimizer = LSLRGradientDescentLearningRule(device=device,\n",
    "                                                                    init_learning_rate=self.task_learning_rate,\n",
    "                                                                    init_weight_decay=args.init_inner_loop_weight_decay,\n",
    "                                                                    total_num_inner_loop_steps=self.args.number_of_training_steps_per_iter,\n",
    "                                                                    use_learnable_weight_decay=self.args.alfa,\n",
    "                                                                    use_learnable_learning_rates=self.args.alfa,\n",
    "                                                                    alfa=self.args.alfa, random_init=self.args.random_init)\n",
    "        \n",
    "        # requires_grad가 true인 parameter만 복제해 놓는다\n",
    "        names_weights_copy = self.get_inner_loop_parameter_dict(self.classifier.named_parameters())\n",
    "        ## 왜 해놓는 것일까? -> L2F 논문\n",
    "        ### 각 task를 수행하는 동안, task-conditioned network 를 통해 각 layer에 대 attenuation parameter()를 생성하여 Conflict를 상쇄\n",
    "\n",
    "        if self.args.attenuate:\n",
    "\n",
    "            num_layers = len(names_weights_copy)\n",
    "            # 각 layer에 대 attenuation parameter()를 생성하기 위해서 input의 차원을 layer의 수만큼 둔다\n",
    "            self.attenuator = nn.Sequential(\n",
    "                nn.Linear(num_layers, num_layers),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(num_layers, num_layers),\n",
    "                nn.Sigmoid() # 근데 attenuator의 output이 Sigmoid가 맞아?\n",
    "            ).to(device=self.device)\n",
    "\n",
    "        # 각 paramter에 해당하는 alpha, beta 초기값을 세팅해 loop만큼 놓는다\n",
    "        self.inner_loop_optimizer.initialise(names_weights_dict=names_weights_copy)\n",
    "        \n",
    "        # Inner loop를 확인한다\n",
    "        print(\"Inner Loop parameters\")\n",
    "        for key, value in self.inner_loop_optimizer.named_parameters():\n",
    "            print(key, value.shape)\n",
    "        \n",
    "        \n",
    "        self.use_cuda = args.use_cuda\n",
    "        self.device = device\n",
    "        self.args = args\n",
    "        self.to(device)\n",
    "\n",
    "        # outer loop를 확인한다\n",
    "        print(\"Outer Loop parameters\")\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.shape, param.device, param.requires_grad)\n",
    "        \n",
    "    def get_inner_loop_parameter_dict(self, params):\n",
    "        \"\"\"\n",
    "        Returns a dictionary with the parameters to use for inner loop updates.\n",
    "        :param params: A dictionary of the network's parameters.\n",
    "        :return: A dictionary of the parameters to use for the inner loop optimization process.\n",
    "        \"\"\"\n",
    "        param_dict = dict()\n",
    "        for name, param in params:\n",
    "            if param.requires_grad:\n",
    "                if self.args.enable_inner_loop_optimizable_bn_params:\n",
    "                    param_dict[name] = param.to(device=self.device)\n",
    "                else:\n",
    "                    if \"norm_layer\" not in name:\n",
    "                        param_dict[name] = param.to(device=self.device)\n",
    "\n",
    "        return param_dict\n",
    "        \n",
    "    def forward(self, data_batch, epoch, use_second_order, use_multi_step_loss_optimization, num_steps, training_phase):\n",
    "        print(\"MAMLFewShotClassifier_Test forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "63eb8ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max pooling\n",
      "(MetaConvNormLayerReLU build_block) out.shape==  torch.Size([2, 48, 84, 84])\n",
      "(MetaConvNormLayerReLU build_block) out.shape==  torch.Size([2, 48, 42, 42])\n",
      "(MetaConvNormLayerReLU build_block) out.shape==  torch.Size([2, 48, 21, 21])\n",
      "(MetaConvNormLayerReLU build_block) out.shape==  torch.Size([2, 48, 10, 10])\n",
      "MetaLinearLayer forward\n",
      "VGGNetwork build out.shape ===  torch.Size([2, 5])\n",
      "VGGNetwork build out ===  tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], grad_fn=<AddmmBackward0>)\n",
      "meta network params\n",
      "layer_dict.conv0.conv.weight torch.Size([48, 3, 3, 3])\n",
      "layer_dict.conv0.conv.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv0.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv1.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv1.conv.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv1.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv2.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv2.conv.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv2.norm_layer.weight torch.Size([48])\n",
      "layer_dict.conv3.conv.weight torch.Size([48, 48, 3, 3])\n",
      "layer_dict.conv3.conv.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_mean torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.running_var torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.bias torch.Size([48])\n",
      "layer_dict.conv3.norm_layer.weight torch.Size([48])\n",
      "layer_dict.linear.weights torch.Size([5, 1200])\n",
      "layer_dict.linear.bias torch.Size([5])\n",
      "0.01\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.conv0.conv.weight\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.conv0.conv.bias\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.conv1.conv.weight\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.conv1.conv.bias\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.conv2.conv.weight\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.conv2.conv.bias\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.conv3.conv.weight\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.conv3.conv.bias\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.linear.weights\n",
      "== LSLRGradientDescentLearningRule initialise ==\n",
      "key == layer_dict.linear.bias\n",
      "Inner Loop parameters\n",
      "names_alpha_dict.layer_dict-conv0-conv-weight torch.Size([6])\n",
      "names_alpha_dict.layer_dict-conv0-conv-bias torch.Size([6])\n",
      "names_alpha_dict.layer_dict-conv1-conv-weight torch.Size([6])\n",
      "names_alpha_dict.layer_dict-conv1-conv-bias torch.Size([6])\n",
      "names_alpha_dict.layer_dict-conv2-conv-weight torch.Size([6])\n",
      "names_alpha_dict.layer_dict-conv2-conv-bias torch.Size([6])\n",
      "names_alpha_dict.layer_dict-conv3-conv-weight torch.Size([6])\n",
      "names_alpha_dict.layer_dict-conv3-conv-bias torch.Size([6])\n",
      "names_alpha_dict.layer_dict-linear-weights torch.Size([6])\n",
      "names_alpha_dict.layer_dict-linear-bias torch.Size([6])\n",
      "names_beta_dict.layer_dict-conv0-conv-weight torch.Size([6])\n",
      "names_beta_dict.layer_dict-conv0-conv-bias torch.Size([6])\n",
      "names_beta_dict.layer_dict-conv1-conv-weight torch.Size([6])\n",
      "names_beta_dict.layer_dict-conv1-conv-bias torch.Size([6])\n",
      "names_beta_dict.layer_dict-conv2-conv-weight torch.Size([6])\n",
      "names_beta_dict.layer_dict-conv2-conv-bias torch.Size([6])\n",
      "names_beta_dict.layer_dict-conv3-conv-weight torch.Size([6])\n",
      "names_beta_dict.layer_dict-conv3-conv-bias torch.Size([6])\n",
      "names_beta_dict.layer_dict-linear-weights torch.Size([6])\n",
      "names_beta_dict.layer_dict-linear-bias torch.Size([6])\n",
      "Outer Loop parameters\n",
      "classifier.layer_dict.conv0.conv.weight torch.Size([48, 3, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv0.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv0.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv0.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv1.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv1.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv2.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv2.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.conv.weight torch.Size([48, 48, 3, 3]) cuda:0 True\n",
      "classifier.layer_dict.conv3.conv.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.norm_layer.bias torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.conv3.norm_layer.weight torch.Size([48]) cuda:0 True\n",
      "classifier.layer_dict.linear.weights torch.Size([5, 1200]) cuda:0 True\n",
      "classifier.layer_dict.linear.bias torch.Size([5]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-conv0-conv-weight torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-conv0-conv-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-conv1-conv-weight torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-conv1-conv-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-conv2-conv-weight torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-conv2-conv-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-conv3-conv-weight torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-conv3-conv-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-linear-weights torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_alpha_dict.layer_dict-linear-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-conv0-conv-weight torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-conv0-conv-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-conv1-conv-weight torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-conv1-conv-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-conv2-conv-weight torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-conv2-conv-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-conv3-conv-weight torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-conv3-conv-bias torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-linear-weights torch.Size([6]) cuda:0 True\n",
      "inner_loop_optimizer.names_beta_dict.layer_dict-linear-bias torch.Size([6]) cuda:0 True\n"
     ]
    }
   ],
   "source": [
    "model = MAMLFewShotClassifier_Test(args=args, device=device,im_shape=(2, 3, args.image_height, args.image_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "42e438b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ones(self.total_num_inner_loop_steps + 1) * self.init_learning_rate 확인\n",
    "torch.ones(5 + 1) * 0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
